{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ce73e07",
   "metadata": {},
   "source": [
    "# Enhanced MLP Architecture + Hyperparameter Exploration Notebook\n",
    "\n",
    "**What this notebook does**\n",
    "- Loads a CSV file that is already *categorically encoded* (user must provide path).\n",
    "- Tries a configurable range of MLP architectures and hyperparameters (hidden layers, solvers, batch sizes, learning rates, epochs, and — for PyTorch models — dropout).\n",
    "- Runs experiments using both **scikit-learn MLP** (fast, good for many grid search experiments) and an optional **PyTorch MLP** (to test dropout explicitly and obtain training loss/accuracy curves).\n",
    "- **Enhanced logging**: Comprehensive logging with TensorBoard, MLflow, progress tracking, error handling, and resource monitoring.\n",
    "- Saves several graphs (PNG files) showing how different parameters affect training/test performance and training loss curves.\n",
    "- Saves results to a CSV for later inspection.\n",
    "\n",
    "**Notes**\n",
    "- The notebook assumes the CSV includes features and a target column (default target column is `risk_level`). If your target has string labels, the notebook will attempt to map `low/medium/high` to `0/1/2`. Adjust the mapping if needed.\n",
    "- The notebook uses `StandardScaler` to scale inputs (recommended for neural nets).\n",
    "- The PyTorch implementation supports dropout and logs all metrics to TensorBoard and optionally MLflow.\n",
    "- Enhanced with comprehensive logging, error handling, and resource monitoring.\n",
    "\n",
    "You can run this notebook end-to-end; change the parameter grids near the top to expand or narrow the search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup_logging",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:06:22,313 - INFO - Starting ML experiments at 2025-08-19 20:06:22.313057\n",
      "2025-08-19 20:06:22,313 - INFO - Output directory: experiment_outputs\n",
      "2025-08-19 20:06:22,314 - INFO - PyTorch enabled: True\n",
      "2025-08-19 20:06:22,315 - INFO - MLflow enabled: True\n",
      "2025-08-19 20:06:22,315 - INFO - Cross-validation enabled: True (5 folds)\n",
      "2025-08-19 20:06:22,313 - INFO - Output directory: experiment_outputs\n",
      "2025-08-19 20:06:22,314 - INFO - PyTorch enabled: True\n",
      "2025-08-19 20:06:22,315 - INFO - MLflow enabled: True\n",
      "2025-08-19 20:06:22,315 - INFO - Cross-validation enabled: True (5 folds)\n"
     ]
    }
   ],
   "source": [
    "# Enhanced imports with logging and monitoring\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import traceback\n",
    "import psutil\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# ML imports\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix, \n",
    "                           precision_score, recall_score, f1_score, precision_recall_fscore_support)\n",
    "\n",
    "# Set up enhanced logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('experiment.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configuration\n",
    "OUTDIR = 'experiment_outputs'\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTDIR, 'models'), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTDIR, 'tb_logs'), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTDIR, 'sklearn_models'), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTDIR, 'pytorch_models'), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTDIR, 'metrics'), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTDIR, 'confusion_matrices'), exist_ok=True)\n",
    "\n",
    "# Experiment configuration\n",
    "use_pytorch = True  # Set to False to skip PyTorch experiments\n",
    "use_mlflow = True  # Set to True to enable MLflow logging\n",
    "use_cross_validation = True  # Set to True to enable 5-fold cross-validation\n",
    "n_folds = 5  # Number of cross-validation folds\n",
    "data_path = '/mnt/data/sample.csv'  # Change this to your CSV path\n",
    "\n",
    "logger.info(f\"Starting ML experiments at {datetime.now()}\")\n",
    "logger.info(f\"Output directory: {OUTDIR}\")\n",
    "logger.info(f\"PyTorch enabled: {use_pytorch}\")\n",
    "logger.info(f\"MLflow enabled: {use_mlflow}\")\n",
    "logger.info(f\"Cross-validation enabled: {use_cross_validation} ({n_folds} folds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "data_loading",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:06:22,335 - INFO - Loading data from /mnt/data/sample.csv\n",
      "2025-08-19 20:06:22,397 - INFO - Data loaded successfully. Shape: (25000, 69)\n",
      "2025-08-19 20:06:22,398 - INFO - Columns: ['has_dental_data', 'has_dietary_data', 'sa_citizen', 'special_needs', 'caregiver_treatment', 'appliance', 'plaque', 'dry_mouth', 'enamel_defects', 'fluoride_water', 'fluoride_toothpaste', 'topical_fluoride', 'regular_checkups', 'sealed_pits', 'restorative_procedures', 'enamel_change', 'dentin_discoloration', 'white_spot_lesions', 'cavitated_lesions', 'multiple_restorations', 'missing_teeth', 'total_dmft_score', 'sweet_sugary_foods', 'sweet_sugary_foods_bedtime', 'sweet_sugary_foods_daily', 'sweet_sugary_foods_weekly', 'sweet_sugary_foods_timing', 'takeaways_processed_foods', 'takeaways_processed_foods_daily', 'takeaways_processed_foods_weekly', 'fresh_fruit', 'fresh_fruit_bedtime', 'fresh_fruit_daily', 'fresh_fruit_weekly', 'fresh_fruit_timing', 'cold_drinks_juices', 'cold_drinks_juices_bedtime', 'cold_drinks_juices_daily', 'cold_drinks_juices_weekly', 'cold_drinks_juices_timing', 'processed_fruit', 'processed_fruit_bedtime', 'processed_fruit_daily', 'processed_fruit_weekly', 'processed_fruit_timing', 'spreads', 'spreads_bedtime', 'spreads_daily', 'spreads_weekly', 'spreads_timing', 'added_sugars', 'added_sugars_bedtime', 'added_sugars_daily', 'added_sugars_weekly', 'added_sugars_timing', 'salty_snacks', 'salty_snacks_daily', 'salty_snacks_weekly', 'salty_snacks_timing', 'dairy_products', 'dairy_products_daily', 'dairy_products_weekly', 'vegetables', 'vegetables_daily', 'vegetables_weekly', 'water', 'water_timing', 'water_glasses', 'risk_level']\n",
      "2025-08-19 20:06:22,406 - INFO - Converting categorical target. Unique values: ['medium' 'high' 'low']\n",
      "2025-08-19 20:06:22,409 - INFO - Mapped risk levels: low->0, medium->1, high->2\n",
      "2025-08-19 20:06:22,397 - INFO - Data loaded successfully. Shape: (25000, 69)\n",
      "2025-08-19 20:06:22,398 - INFO - Columns: ['has_dental_data', 'has_dietary_data', 'sa_citizen', 'special_needs', 'caregiver_treatment', 'appliance', 'plaque', 'dry_mouth', 'enamel_defects', 'fluoride_water', 'fluoride_toothpaste', 'topical_fluoride', 'regular_checkups', 'sealed_pits', 'restorative_procedures', 'enamel_change', 'dentin_discoloration', 'white_spot_lesions', 'cavitated_lesions', 'multiple_restorations', 'missing_teeth', 'total_dmft_score', 'sweet_sugary_foods', 'sweet_sugary_foods_bedtime', 'sweet_sugary_foods_daily', 'sweet_sugary_foods_weekly', 'sweet_sugary_foods_timing', 'takeaways_processed_foods', 'takeaways_processed_foods_daily', 'takeaways_processed_foods_weekly', 'fresh_fruit', 'fresh_fruit_bedtime', 'fresh_fruit_daily', 'fresh_fruit_weekly', 'fresh_fruit_timing', 'cold_drinks_juices', 'cold_drinks_juices_bedtime', 'cold_drinks_juices_daily', 'cold_drinks_juices_weekly', 'cold_drinks_juices_timing', 'processed_fruit', 'processed_fruit_bedtime', 'processed_fruit_daily', 'processed_fruit_weekly', 'processed_fruit_timing', 'spreads', 'spreads_bedtime', 'spreads_daily', 'spreads_weekly', 'spreads_timing', 'added_sugars', 'added_sugars_bedtime', 'added_sugars_daily', 'added_sugars_weekly', 'added_sugars_timing', 'salty_snacks', 'salty_snacks_daily', 'salty_snacks_weekly', 'salty_snacks_timing', 'dairy_products', 'dairy_products_daily', 'dairy_products_weekly', 'vegetables', 'vegetables_daily', 'vegetables_weekly', 'water', 'water_timing', 'water_glasses', 'risk_level']\n",
      "2025-08-19 20:06:22,406 - INFO - Converting categorical target. Unique values: ['medium' 'high' 'low']\n",
      "2025-08-19 20:06:22,409 - INFO - Mapped risk levels: low->0, medium->1, high->2\n",
      "2025-08-19 20:06:22,410 - INFO - Target distribution: [ 4522  9247 11231]\n",
      "2025-08-19 20:06:22,428 - INFO - Train-test split completed. Train: (20000, 68), Test: (5000, 68)\n",
      "2025-08-19 20:06:22,410 - INFO - Target distribution: [ 4522  9247 11231]\n",
      "2025-08-19 20:06:22,428 - INFO - Train-test split completed. Train: (20000, 68), Test: (5000, 68)\n",
      "2025-08-19 20:06:22,457 - INFO - Features scaled using StandardScaler\n",
      "2025-08-19 20:06:22,457 - INFO - Features scaled using StandardScaler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "Shape: (25000, 69)\n",
      "Columns: ['has_dental_data', 'has_dietary_data', 'sa_citizen', 'special_needs', 'caregiver_treatment', 'appliance', 'plaque', 'dry_mouth', 'enamel_defects', 'fluoride_water', 'fluoride_toothpaste', 'topical_fluoride', 'regular_checkups', 'sealed_pits', 'restorative_procedures', 'enamel_change', 'dentin_discoloration', 'white_spot_lesions', 'cavitated_lesions', 'multiple_restorations', 'missing_teeth', 'total_dmft_score', 'sweet_sugary_foods', 'sweet_sugary_foods_bedtime', 'sweet_sugary_foods_daily', 'sweet_sugary_foods_weekly', 'sweet_sugary_foods_timing', 'takeaways_processed_foods', 'takeaways_processed_foods_daily', 'takeaways_processed_foods_weekly', 'fresh_fruit', 'fresh_fruit_bedtime', 'fresh_fruit_daily', 'fresh_fruit_weekly', 'fresh_fruit_timing', 'cold_drinks_juices', 'cold_drinks_juices_bedtime', 'cold_drinks_juices_daily', 'cold_drinks_juices_weekly', 'cold_drinks_juices_timing', 'processed_fruit', 'processed_fruit_bedtime', 'processed_fruit_daily', 'processed_fruit_weekly', 'processed_fruit_timing', 'spreads', 'spreads_bedtime', 'spreads_daily', 'spreads_weekly', 'spreads_timing', 'added_sugars', 'added_sugars_bedtime', 'added_sugars_daily', 'added_sugars_weekly', 'added_sugars_timing', 'salty_snacks', 'salty_snacks_daily', 'salty_snacks_weekly', 'salty_snacks_timing', 'dairy_products', 'dairy_products_daily', 'dairy_products_weekly', 'vegetables', 'vegetables_daily', 'vegetables_weekly', 'water', 'water_timing', 'water_glasses', 'risk_level']\n",
      "Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Helper function for comprehensive metrics calculation\n",
    "def calculate_comprehensive_metrics(y_true, y_pred, model_name, experiment_id, model_type='sklearn'):\n",
    "    \"\"\"Calculate and save comprehensive metrics for a model\"\"\"\n",
    "    \n",
    "    # Calculate all metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    recall_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    precision_weighted = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    recall_weighted = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Per-class metrics\n",
    "    precision_per_class, recall_per_class, f1_per_class, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Create comprehensive metrics dictionary\n",
    "    metrics = {\n",
    "        'model_name': model_name,\n",
    "        'experiment_id': experiment_id,\n",
    "        'model_type': model_type,\n",
    "        'accuracy': accuracy,\n",
    "        'precision_macro': precision_macro,\n",
    "        'recall_macro': recall_macro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'precision_weighted': precision_weighted,\n",
    "        'recall_weighted': recall_weighted,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'confusion_matrix': cm.tolist(),\n",
    "        'per_class_metrics': {\n",
    "            'precision': precision_per_class.tolist(),\n",
    "            'recall': recall_per_class.tolist(),\n",
    "            'f1_score': f1_per_class.tolist(),\n",
    "            'support': support.tolist()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save metrics to JSON\n",
    "    metrics_file = os.path.join(OUTDIR, 'metrics', f'{model_type}_model_{experiment_id}_metrics.json')\n",
    "    with open(metrics_file, 'w') as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    \n",
    "    # Create and save confusion matrix plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=[f'Class {i}' for i in range(cm.shape[1])],\n",
    "                yticklabels=[f'Class {i}' for i in range(cm.shape[0])])\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    \n",
    "    cm_file = os.path.join(OUTDIR, 'confusion_matrices', f'{model_type}_model_{experiment_id}_confusion_matrix.png')\n",
    "    plt.savefig(cm_file, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "    report_file = os.path.join(OUTDIR, 'metrics', f'{model_type}_model_{experiment_id}_classification_report.json')\n",
    "    with open(report_file, 'w') as f:\n",
    "        json.dump(class_report, f, indent=2)\n",
    "    \n",
    "    logger.info(f\"Comprehensive metrics saved for {model_name} (ID: {experiment_id})\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Load and prepare data\n",
    "try:\n",
    "    logger.info(f\"Loading data from {data_path}\")\n",
    "    df = pd.read_csv(\"training_data.csv\")\n",
    "    logger.info(f\"Data loaded successfully. Shape: {df.shape}\")\n",
    "    logger.info(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Display basic info about the dataset\n",
    "    print(\"Dataset Info:\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load data: {str(e)}\")\n",
    "    logger.error(traceback.format_exc())\n",
    "    raise\n",
    "\n",
    "# Prepare features and target\n",
    "target_col = 'risk_level'  # Change this if your target column has a different name\n",
    "\n",
    "try:\n",
    "    if target_col not in df.columns:\n",
    "        logger.warning(f\"Target column '{target_col}' not found. Available columns: {list(df.columns)}\")\n",
    "        target_col = input(\"Please enter the correct target column name: \")\n",
    "    \n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    \n",
    "    # Handle categorical target if needed\n",
    "    if y.dtype == 'object':\n",
    "        logger.info(f\"Converting categorical target. Unique values: {y.unique()}\")\n",
    "        if set(y.unique()).issubset({'low', 'medium', 'high'}):\n",
    "            y = y.map({'low': 0, 'medium': 1, 'high': 2})\n",
    "            logger.info(\"Mapped risk levels: low->0, medium->1, high->2\")\n",
    "        else:\n",
    "            # Use label encoding for other categorical targets\n",
    "            from sklearn.preprocessing import LabelEncoder\n",
    "            le = LabelEncoder()\n",
    "            y = le.fit_transform(y)\n",
    "            logger.info(f\"Label encoded target. Classes: {le.classes_}\")\n",
    "    \n",
    "    logger.info(f\"Target distribution: {np.bincount(y)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error preparing target variable: {str(e)}\")\n",
    "    logger.error(traceback.format_exc())\n",
    "    raise\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "logger.info(f\"Train-test split completed. Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "logger.info(\"Features scaled using StandardScaler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b97b9e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU device: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "GPU memory: 6.0 GB\n",
      "\n",
      "Note: Scikit-learn experiments always use CPU only\n",
      "PyTorch experiments will use GPU\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "try:\n",
    "    import torch\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    print(f\"CUDA available: {gpu_available}\")\n",
    "    if gpu_available:\n",
    "        print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    else:\n",
    "        print(\"No GPU available - will use CPU for PyTorch experiments\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch not installed - only scikit-learn experiments will run (CPU only)\")\n",
    "\n",
    "print(f\"\\nNote: Scikit-learn experiments always use CPU only\")\n",
    "print(f\"PyTorch experiments will use {'GPU' if gpu_available else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889eaa61",
   "metadata": {},
   "source": [
    "## PyTorch GPU Installation\n",
    "\n",
    "Based on your NVIDIA GeForce RTX 4050 with CUDA 12.9, install PyTorch with GPU support using one of these commands:\n",
    "\n",
    "### Option 1: Latest PyTorch with CUDA 12.1 (Recommended)\n",
    "```bash\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "```\n",
    "\n",
    "### Option 2: Latest PyTorch with CUDA 11.8 (Alternative)\n",
    "```bash\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "```\n",
    "\n",
    "### Option 3: CPU-only version (if GPU setup fails)\n",
    "```bash\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "```\n",
    "\n",
    "**Note:** The CUDA 12.1 version should work with your CUDA 12.9 driver (backwards compatible).\n",
    "\n",
    "Run the cell below to check if GPU is detected after installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experiment_config",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:06:24,743 - INFO - Experiment configuration saved to experiment_outputs\\experiment_config.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sklearn combinations: 54\n",
      "Total PyTorch combinations: 72\n"
     ]
    }
   ],
   "source": [
    "# Parameter grids\n",
    "sklearn_param_grid = {\n",
    "    'hidden_layer_sizes': [(25,), (32,), (64,)],\n",
    "    'solver': ['adam', 'lbfgs', 'adamw'],\n",
    "    'learning_rate_init': [0.01, 0.1],\n",
    "    'max_iter': [200, 500, 1000]\n",
    "}\n",
    "\n",
    "pytorch_param_grid = {\n",
    "    'hidden_sizes': [[25], [32], [64]],\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'dropout': [0.2, 0.5],\n",
    "    'batch_size': [64, 128],\n",
    "    'epochs': [100, 150]\n",
    "}\n",
    "\n",
    "# Save experiment configuration\n",
    "experiment_config = {\n",
    "    'sklearn_param_grid': sklearn_param_grid,\n",
    "    'pytorch_param_grid': pytorch_param_grid,\n",
    "    'data_path': data_path,\n",
    "    'target_column': target_col,\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'train_size': X_train.shape[0],\n",
    "    'test_size': X_test.shape[0],\n",
    "    'n_features': X_train.shape[1],\n",
    "    'n_classes': len(np.unique(y)),\n",
    "    'use_pytorch': use_pytorch,\n",
    "    'use_mlflow': use_mlflow\n",
    "}\n",
    "\n",
    "with open(os.path.join(OUTDIR, 'experiment_config.yaml'), 'w') as f:\n",
    "    yaml.dump(experiment_config, f, default_flow_style=False)\n",
    "\n",
    "logger.info(f\"Experiment configuration saved to {os.path.join(OUTDIR, 'experiment_config.yaml')}\")\n",
    "print(f\"Total sklearn combinations: {len(list(product(*sklearn_param_grid.values())))}\")\n",
    "if use_pytorch:\n",
    "    print(f\"Total PyTorch combinations: {len(list(product(*pytorch_param_grid.values())))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aabc9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:06:24,754 - INFO - Selected 35 features for training\n",
      "2025-08-19 20:06:24,755 - INFO - Selected features: ['has_dental_data', 'special_needs', 'caregiver_treatment', 'plaque', 'dry_mouth', 'enamel_defects', 'fluoride_water', 'fluoride_toothpaste', 'topical_fluoride', 'regular_checkups', 'sealed_pits', 'enamel_change', 'dentin_discoloration', 'white_spot_lesions', 'cavitated_lesions', 'multiple_restorations', 'missing_teeth', 'total_dmft_score', 'sweet_sugary_foods', 'sweet_sugary_foods_bedtime', 'takeaways_processed_foods', 'fresh_fruit', 'cold_drinks_juices', 'processed_fruit', 'processed_fruit_bedtime', 'spreads', 'spreads_bedtime', 'added_sugars', 'added_sugars_bedtime', 'salty_snacks', 'dairy_products', 'vegetables', 'has_dietary_data', 'cold_drinks_juices_bedtime', 'water']\n",
      "2025-08-19 20:06:24,756 - INFO - Available features: 35/35\n",
      "2025-08-19 20:06:24,761 - INFO - Feature matrix shape after selection: (25000, 35)\n",
      "2025-08-19 20:06:24,755 - INFO - Selected features: ['has_dental_data', 'special_needs', 'caregiver_treatment', 'plaque', 'dry_mouth', 'enamel_defects', 'fluoride_water', 'fluoride_toothpaste', 'topical_fluoride', 'regular_checkups', 'sealed_pits', 'enamel_change', 'dentin_discoloration', 'white_spot_lesions', 'cavitated_lesions', 'multiple_restorations', 'missing_teeth', 'total_dmft_score', 'sweet_sugary_foods', 'sweet_sugary_foods_bedtime', 'takeaways_processed_foods', 'fresh_fruit', 'cold_drinks_juices', 'processed_fruit', 'processed_fruit_bedtime', 'spreads', 'spreads_bedtime', 'added_sugars', 'added_sugars_bedtime', 'salty_snacks', 'dairy_products', 'vegetables', 'has_dietary_data', 'cold_drinks_juices_bedtime', 'water']\n",
      "2025-08-19 20:06:24,756 - INFO - Available features: 35/35\n",
      "2025-08-19 20:06:24,761 - INFO - Feature matrix shape after selection: (25000, 35)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected: 35\n",
      "Final feature set: ['has_dental_data', 'special_needs', 'caregiver_treatment', 'plaque', 'dry_mouth', 'enamel_defects', 'fluoride_water', 'fluoride_toothpaste', 'topical_fluoride', 'regular_checkups', 'sealed_pits', 'enamel_change', 'dentin_discoloration', 'white_spot_lesions', 'cavitated_lesions', 'multiple_restorations', 'missing_teeth', 'total_dmft_score', 'sweet_sugary_foods', 'sweet_sugary_foods_bedtime', 'takeaways_processed_foods', 'fresh_fruit', 'cold_drinks_juices', 'processed_fruit', 'processed_fruit_bedtime', 'spreads', 'spreads_bedtime', 'added_sugars', 'added_sugars_bedtime', 'salty_snacks', 'dairy_products', 'vegetables', 'has_dietary_data', 'cold_drinks_juices_bedtime', 'water']\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection - Use only the selected features from feature selection analysis\n",
    "selected_features = [\n",
    "    'has_dental_data',\n",
    "    'special_needs',\n",
    "    'caregiver_treatment',#high risk\n",
    "    'plaque',#high risk\n",
    "    'dry_mouth',#high risk\n",
    "    'enamel_defects',#high risk\n",
    "    'fluoride_water',\n",
    "    'fluoride_toothpaste',\n",
    "    'topical_fluoride',\n",
    "    'regular_checkups',\n",
    "    'sealed_pits',\n",
    "    'enamel_change',\n",
    "    'dentin_discoloration',#high risk\n",
    "    'white_spot_lesions',#high risk\n",
    "    'cavitated_lesions',#high risk\n",
    "    'multiple_restorations',#high risk\n",
    "    'missing_teeth',#high risk\n",
    "    'total_dmft_score',\n",
    "    'sweet_sugary_foods', #high risk\n",
    "    'sweet_sugary_foods_bedtime',\n",
    "    'takeaways_processed_foods',#high risk\n",
    "    'fresh_fruit',\n",
    "    'cold_drinks_juices',#high risk\n",
    "    'processed_fruit',\n",
    "    'processed_fruit_bedtime',\n",
    "    'spreads',#high risk\n",
    "    'spreads_bedtime',\n",
    "    'added_sugars',#high risk\n",
    "    'added_sugars_bedtime',\n",
    "    'salty_snacks',\n",
    "    'dairy_products',\n",
    "    'vegetables',\n",
    "    'has_dietary_data',\n",
    "    'cold_drinks_juices_bedtime',\n",
    "    'water'\n",
    "]\n",
    "\n",
    "logger.info(f\"Selected {len(selected_features)} features for training\")\n",
    "logger.info(f\"Selected features: {selected_features}\")\n",
    "\n",
    "# Check which selected features are available in the dataset\n",
    "available_features = []\n",
    "missing_features = []\n",
    "\n",
    "for feature in selected_features:\n",
    "    if feature in X.columns:\n",
    "        available_features.append(feature)\n",
    "    else:\n",
    "        missing_features.append(feature)\n",
    "\n",
    "logger.info(f\"Available features: {len(available_features)}/{len(selected_features)}\")\n",
    "if missing_features:\n",
    "    logger.warning(f\"Missing features: {missing_features}\")\n",
    "\n",
    "# Filter X to only include selected features that are available\n",
    "X_selected = X[available_features].copy()\n",
    "logger.info(f\"Feature matrix shape after selection: {X_selected.shape}\")\n",
    "\n",
    "# Update X to use only selected features\n",
    "X = X_selected\n",
    "\n",
    "print(f\"Features selected: {len(available_features)}\")\n",
    "print(f\"Final feature set: {list(X.columns)}\")\n",
    "if missing_features:\n",
    "    print(f\"Warning: {len(missing_features)} features not found in dataset: {missing_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sklearn_experiments",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:06:24,782 - INFO - Starting 54 scikit-learn experiments\n",
      "2025-08-19 20:06:24,782 - INFO - Using 5-fold cross-validation (this will increase training time by ~5x)\n",
      "Scikit-learn experiments:   0%|          | 0/54 [00:00<?, ?it/s]2025-08-19 20:06:24,782 - INFO - Using 5-fold cross-validation (this will increase training time by ~5x)\n",
      "Scikit-learn experiments:   0%|          | 0/54 [00:00<?, ?it/s]2025-08-19 20:06:34,153 - INFO - Comprehensive metrics saved for sklearn_mlp_1 (ID: 1)\n",
      "2025-08-19 20:06:34,153 - INFO - Comprehensive metrics saved for sklearn_mlp_1 (ID: 1)\n",
      "2025-08-19 20:06:34,374 - INFO - Comprehensive metrics saved for sklearn_mlp_1_train (ID: 1_train)\n",
      "2025-08-19 20:06:34,377 - INFO - Sklearn experiment 1/54 completed. CV mean: 0.9917±0.0023, Test F1: 0.9979\n",
      "Scikit-learn experiments:   2%|▏         | 1/54 [00:09<08:27,  9.58s/it]2025-08-19 20:06:34,374 - INFO - Comprehensive metrics saved for sklearn_mlp_1_train (ID: 1_train)\n",
      "2025-08-19 20:06:34,377 - INFO - Sklearn experiment 1/54 completed. CV mean: 0.9917±0.0023, Test F1: 0.9979\n",
      "Scikit-learn experiments:   2%|▏         | 1/54 [00:09<08:27,  9.58s/it]2025-08-19 20:06:43,614 - INFO - Comprehensive metrics saved for sklearn_mlp_2 (ID: 2)\n",
      "2025-08-19 20:06:43,614 - INFO - Comprehensive metrics saved for sklearn_mlp_2 (ID: 2)\n",
      "2025-08-19 20:06:43,838 - INFO - Comprehensive metrics saved for sklearn_mlp_2_train (ID: 2_train)\n",
      "2025-08-19 20:06:43,840 - INFO - Sklearn experiment 2/54 completed. CV mean: 0.9917±0.0023, Test F1: 0.9979\n",
      "Scikit-learn experiments:   4%|▎         | 2/54 [00:19<08:14,  9.51s/it]2025-08-19 20:06:43,838 - INFO - Comprehensive metrics saved for sklearn_mlp_2_train (ID: 2_train)\n",
      "2025-08-19 20:06:43,840 - INFO - Sklearn experiment 2/54 completed. CV mean: 0.9917±0.0023, Test F1: 0.9979\n",
      "Scikit-learn experiments:   4%|▎         | 2/54 [00:19<08:14,  9.51s/it]2025-08-19 20:06:53,304 - INFO - Comprehensive metrics saved for sklearn_mlp_3 (ID: 3)\n",
      "2025-08-19 20:06:53,304 - INFO - Comprehensive metrics saved for sklearn_mlp_3 (ID: 3)\n",
      "2025-08-19 20:06:53,528 - INFO - Comprehensive metrics saved for sklearn_mlp_3_train (ID: 3_train)\n",
      "2025-08-19 20:06:53,531 - INFO - Sklearn experiment 3/54 completed. CV mean: 0.9917±0.0023, Test F1: 0.9979\n",
      "Scikit-learn experiments:   6%|▌         | 3/54 [00:28<08:09,  9.59s/it]2025-08-19 20:06:53,528 - INFO - Comprehensive metrics saved for sklearn_mlp_3_train (ID: 3_train)\n",
      "2025-08-19 20:06:53,531 - INFO - Sklearn experiment 3/54 completed. CV mean: 0.9917±0.0023, Test F1: 0.9979\n",
      "Scikit-learn experiments:   6%|▌         | 3/54 [00:28<08:09,  9.59s/it]2025-08-19 20:07:00,057 - INFO - Comprehensive metrics saved for sklearn_mlp_4 (ID: 4)\n",
      "2025-08-19 20:07:00,057 - INFO - Comprehensive metrics saved for sklearn_mlp_4 (ID: 4)\n",
      "2025-08-19 20:07:00,276 - INFO - Comprehensive metrics saved for sklearn_mlp_4_train (ID: 4_train)\n",
      "2025-08-19 20:07:00,279 - INFO - Sklearn experiment 4/54 completed. CV mean: 0.9825±0.0046, Test F1: 0.9783\n",
      "Scikit-learn experiments:   7%|▋         | 4/54 [00:35<07:03,  8.47s/it]2025-08-19 20:07:00,276 - INFO - Comprehensive metrics saved for sklearn_mlp_4_train (ID: 4_train)\n",
      "2025-08-19 20:07:00,279 - INFO - Sklearn experiment 4/54 completed. CV mean: 0.9825±0.0046, Test F1: 0.9783\n",
      "Scikit-learn experiments:   7%|▋         | 4/54 [00:35<07:03,  8.47s/it]2025-08-19 20:07:06,789 - INFO - Comprehensive metrics saved for sklearn_mlp_5 (ID: 5)\n",
      "2025-08-19 20:07:06,789 - INFO - Comprehensive metrics saved for sklearn_mlp_5 (ID: 5)\n",
      "2025-08-19 20:07:07,007 - INFO - Comprehensive metrics saved for sklearn_mlp_5_train (ID: 5_train)\n",
      "2025-08-19 20:07:07,010 - INFO - Sklearn experiment 5/54 completed. CV mean: 0.9825±0.0046, Test F1: 0.9783\n",
      "2025-08-19 20:07:07,007 - INFO - Comprehensive metrics saved for sklearn_mlp_5_train (ID: 5_train)\n",
      "2025-08-19 20:07:07,010 - INFO - Sklearn experiment 5/54 completed. CV mean: 0.9825±0.0046, Test F1: 0.9783\n",
      "Scikit-learn experiments:   9%|▉         | 5/54 [00:42<06:24,  7.84s/it]2025-08-19 20:07:13,566 - INFO - Comprehensive metrics saved for sklearn_mlp_6 (ID: 6)\n",
      "2025-08-19 20:07:13,566 - INFO - Comprehensive metrics saved for sklearn_mlp_6 (ID: 6)\n",
      "2025-08-19 20:07:13,783 - INFO - Comprehensive metrics saved for sklearn_mlp_6_train (ID: 6_train)\n",
      "2025-08-19 20:07:13,787 - INFO - Sklearn experiment 6/54 completed. CV mean: 0.9825±0.0046, Test F1: 0.9783\n",
      "Scikit-learn experiments:  11%|█         | 6/54 [00:48<05:59,  7.48s/it]2025-08-19 20:07:13,783 - INFO - Comprehensive metrics saved for sklearn_mlp_6_train (ID: 6_train)\n",
      "2025-08-19 20:07:13,787 - INFO - Sklearn experiment 6/54 completed. CV mean: 0.9825±0.0046, Test F1: 0.9783\n",
      "Scikit-learn experiments:  11%|█         | 6/54 [00:48<05:59,  7.48s/it]2025-08-19 20:07:19,681 - INFO - Comprehensive metrics saved for sklearn_mlp_7 (ID: 7)\n",
      "2025-08-19 20:07:19,681 - INFO - Comprehensive metrics saved for sklearn_mlp_7 (ID: 7)\n",
      "2025-08-19 20:07:19,899 - INFO - Comprehensive metrics saved for sklearn_mlp_7_train (ID: 7_train)\n",
      "2025-08-19 20:07:19,901 - INFO - Sklearn experiment 7/54 completed. CV mean: 0.9939±0.0008, Test F1: 1.0000\n",
      "Scikit-learn experiments:  13%|█▎        | 7/54 [00:55<05:30,  7.03s/it]2025-08-19 20:07:19,899 - INFO - Comprehensive metrics saved for sklearn_mlp_7_train (ID: 7_train)\n",
      "2025-08-19 20:07:19,901 - INFO - Sklearn experiment 7/54 completed. CV mean: 0.9939±0.0008, Test F1: 1.0000\n",
      "Scikit-learn experiments:  13%|█▎        | 7/54 [00:55<05:30,  7.03s/it]2025-08-19 20:07:25,771 - INFO - Comprehensive metrics saved for sklearn_mlp_8 (ID: 8)\n",
      "2025-08-19 20:07:25,771 - INFO - Comprehensive metrics saved for sklearn_mlp_8 (ID: 8)\n",
      "2025-08-19 20:07:25,985 - INFO - Comprehensive metrics saved for sklearn_mlp_8_train (ID: 8_train)\n",
      "2025-08-19 20:07:25,987 - INFO - Sklearn experiment 8/54 completed. CV mean: 0.9939±0.0008, Test F1: 1.0000\n",
      "Scikit-learn experiments:  15%|█▍        | 8/54 [01:01<05:09,  6.73s/it]2025-08-19 20:07:25,985 - INFO - Comprehensive metrics saved for sklearn_mlp_8_train (ID: 8_train)\n",
      "2025-08-19 20:07:25,987 - INFO - Sklearn experiment 8/54 completed. CV mean: 0.9939±0.0008, Test F1: 1.0000\n",
      "Scikit-learn experiments:  15%|█▍        | 8/54 [01:01<05:09,  6.73s/it]2025-08-19 20:07:31,867 - INFO - Comprehensive metrics saved for sklearn_mlp_9 (ID: 9)\n",
      "2025-08-19 20:07:31,867 - INFO - Comprehensive metrics saved for sklearn_mlp_9 (ID: 9)\n",
      "2025-08-19 20:07:32,081 - INFO - Comprehensive metrics saved for sklearn_mlp_9_train (ID: 9_train)\n",
      "2025-08-19 20:07:32,083 - INFO - Sklearn experiment 9/54 completed. CV mean: 0.9939±0.0008, Test F1: 1.0000\n",
      "Scikit-learn experiments:  17%|█▋        | 9/54 [01:07<04:54,  6.53s/it]2025-08-19 20:07:32,081 - INFO - Comprehensive metrics saved for sklearn_mlp_9_train (ID: 9_train)\n",
      "2025-08-19 20:07:32,083 - INFO - Sklearn experiment 9/54 completed. CV mean: 0.9939±0.0008, Test F1: 1.0000\n",
      "Scikit-learn experiments:  17%|█▋        | 9/54 [01:07<04:54,  6.53s/it]2025-08-19 20:07:37,980 - INFO - Comprehensive metrics saved for sklearn_mlp_10 (ID: 10)\n",
      "2025-08-19 20:07:37,980 - INFO - Comprehensive metrics saved for sklearn_mlp_10 (ID: 10)\n",
      "2025-08-19 20:07:38,194 - INFO - Comprehensive metrics saved for sklearn_mlp_10_train (ID: 10_train)\n",
      "2025-08-19 20:07:38,196 - INFO - Sklearn experiment 10/54 completed. CV mean: 0.9939±0.0008, Test F1: 1.0000\n",
      "Scikit-learn experiments:  19%|█▊        | 10/54 [01:13<04:41,  6.40s/it]2025-08-19 20:07:38,194 - INFO - Comprehensive metrics saved for sklearn_mlp_10_train (ID: 10_train)\n",
      "2025-08-19 20:07:38,196 - INFO - Sklearn experiment 10/54 completed. CV mean: 0.9939±0.0008, Test F1: 1.0000\n",
      "Scikit-learn experiments:  19%|█▊        | 10/54 [01:13<04:41,  6.40s/it]2025-08-19 20:07:44,192 - INFO - Comprehensive metrics saved for sklearn_mlp_11 (ID: 11)\n",
      "2025-08-19 20:07:44,192 - INFO - Comprehensive metrics saved for sklearn_mlp_11 (ID: 11)\n",
      "2025-08-19 20:07:44,405 - INFO - Comprehensive metrics saved for sklearn_mlp_11_train (ID: 11_train)\n",
      "2025-08-19 20:07:44,408 - INFO - Sklearn experiment 11/54 completed. CV mean: 0.9939±0.0008, Test F1: 1.0000\n",
      "Scikit-learn experiments:  20%|██        | 11/54 [01:19<04:32,  6.34s/it]2025-08-19 20:07:44,405 - INFO - Comprehensive metrics saved for sklearn_mlp_11_train (ID: 11_train)\n",
      "2025-08-19 20:07:44,408 - INFO - Sklearn experiment 11/54 completed. CV mean: 0.9939±0.0008, Test F1: 1.0000\n",
      "Scikit-learn experiments:  20%|██        | 11/54 [01:19<04:32,  6.34s/it]2025-08-19 20:07:50,295 - INFO - Comprehensive metrics saved for sklearn_mlp_12 (ID: 12)\n",
      "2025-08-19 20:07:50,295 - INFO - Comprehensive metrics saved for sklearn_mlp_12 (ID: 12)\n",
      "2025-08-19 20:07:50,516 - INFO - Comprehensive metrics saved for sklearn_mlp_12_train (ID: 12_train)\n",
      "2025-08-19 20:07:50,518 - INFO - Sklearn experiment 12/54 completed. CV mean: 0.9939±0.0008, Test F1: 1.0000\n",
      "Scikit-learn experiments:  22%|██▏       | 12/54 [01:25<04:23,  6.27s/it]2025-08-19 20:07:50,516 - INFO - Comprehensive metrics saved for sklearn_mlp_12_train (ID: 12_train)\n",
      "2025-08-19 20:07:50,518 - INFO - Sklearn experiment 12/54 completed. CV mean: 0.9939±0.0008, Test F1: 1.0000\n",
      "Scikit-learn experiments:  22%|██▏       | 12/54 [01:25<04:23,  6.27s/it]2025-08-19 20:07:51,566 - ERROR - Sklearn experiment 13 failed with params {'hidden_layer_sizes': (25,), 'solver': 'adamw', 'learning_rate_init': 0.01, 'max_iter': 200}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:07:51,568 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  24%|██▍       | 13/54 [01:26<03:12,  4.69s/it]2025-08-19 20:07:51,566 - ERROR - Sklearn experiment 13 failed with params {'hidden_layer_sizes': (25,), 'solver': 'adamw', 'learning_rate_init': 0.01, 'max_iter': 200}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:07:51,568 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  24%|██▍       | 13/54 [01:26<03:12,  4.69s/it]2025-08-19 20:07:52,614 - ERROR - Sklearn experiment 14 failed with params {'hidden_layer_sizes': (25,), 'solver': 'adamw', 'learning_rate_init': 0.01, 'max_iter': 500}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:07:52,616 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  26%|██▌       | 14/54 [01:27<02:23,  3.59s/it]2025-08-19 20:07:52,614 - ERROR - Sklearn experiment 14 failed with params {'hidden_layer_sizes': (25,), 'solver': 'adamw', 'learning_rate_init': 0.01, 'max_iter': 500}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:07:52,616 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  26%|██▌       | 14/54 [01:27<02:23,  3.59s/it]2025-08-19 20:07:53,663 - ERROR - Sklearn experiment 15 failed with params {'hidden_layer_sizes': (25,), 'solver': 'adamw', 'learning_rate_init': 0.01, 'max_iter': 1000}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:07:53,664 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  28%|██▊       | 15/54 [01:28<01:50,  2.82s/it]2025-08-19 20:07:53,663 - ERROR - Sklearn experiment 15 failed with params {'hidden_layer_sizes': (25,), 'solver': 'adamw', 'learning_rate_init': 0.01, 'max_iter': 1000}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:07:53,664 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  28%|██▊       | 15/54 [01:28<01:50,  2.82s/it]2025-08-19 20:07:54,711 - ERROR - Sklearn experiment 16 failed with params {'hidden_layer_sizes': (25,), 'solver': 'adamw', 'learning_rate_init': 0.1, 'max_iter': 200}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:07:54,713 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  30%|██▉       | 16/54 [01:29<01:27,  2.29s/it]2025-08-19 20:07:54,711 - ERROR - Sklearn experiment 16 failed with params {'hidden_layer_sizes': (25,), 'solver': 'adamw', 'learning_rate_init': 0.1, 'max_iter': 200}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:07:54,713 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  30%|██▉       | 16/54 [01:29<01:27,  2.29s/it]2025-08-19 20:07:55,759 - ERROR - Sklearn experiment 17 failed with params {'hidden_layer_sizes': (25,), 'solver': 'adamw', 'learning_rate_init': 0.1, 'max_iter': 500}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:07:55,761 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  31%|███▏      | 17/54 [01:30<01:10,  1.92s/it]2025-08-19 20:07:55,759 - ERROR - Sklearn experiment 17 failed with params {'hidden_layer_sizes': (25,), 'solver': 'adamw', 'learning_rate_init': 0.1, 'max_iter': 500}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:07:55,761 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  31%|███▏      | 17/54 [01:30<01:10,  1.92s/it]2025-08-19 20:07:56,807 - ERROR - Sklearn experiment 18 failed with params {'hidden_layer_sizes': (25,), 'solver': 'adamw', 'learning_rate_init': 0.1, 'max_iter': 1000}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:07:56,809 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  33%|███▎      | 18/54 [01:32<00:59,  1.66s/it]2025-08-19 20:07:56,807 - ERROR - Sklearn experiment 18 failed with params {'hidden_layer_sizes': (25,), 'solver': 'adamw', 'learning_rate_init': 0.1, 'max_iter': 1000}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:07:56,809 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  33%|███▎      | 18/54 [01:32<00:59,  1.66s/it]2025-08-19 20:08:05,385 - INFO - Comprehensive metrics saved for sklearn_mlp_19 (ID: 19)\n",
      "2025-08-19 20:08:05,385 - INFO - Comprehensive metrics saved for sklearn_mlp_19 (ID: 19)\n",
      "2025-08-19 20:08:05,603 - INFO - Comprehensive metrics saved for sklearn_mlp_19_train (ID: 19_train)\n",
      "2025-08-19 20:08:05,606 - INFO - Sklearn experiment 19/54 completed. CV mean: 0.9906±0.0016, Test F1: 0.9997\n",
      "Scikit-learn experiments:  35%|███▌      | 19/54 [01:40<02:13,  3.80s/it]2025-08-19 20:08:05,603 - INFO - Comprehensive metrics saved for sklearn_mlp_19_train (ID: 19_train)\n",
      "2025-08-19 20:08:05,606 - INFO - Sklearn experiment 19/54 completed. CV mean: 0.9906±0.0016, Test F1: 0.9997\n",
      "Scikit-learn experiments:  35%|███▌      | 19/54 [01:40<02:13,  3.80s/it]2025-08-19 20:08:14,248 - INFO - Comprehensive metrics saved for sklearn_mlp_20 (ID: 20)\n",
      "2025-08-19 20:08:14,248 - INFO - Comprehensive metrics saved for sklearn_mlp_20 (ID: 20)\n",
      "2025-08-19 20:08:14,464 - INFO - Comprehensive metrics saved for sklearn_mlp_20_train (ID: 20_train)\n",
      "2025-08-19 20:08:14,467 - INFO - Sklearn experiment 20/54 completed. CV mean: 0.9906±0.0016, Test F1: 0.9997\n",
      "Scikit-learn experiments:  37%|███▋      | 20/54 [01:49<03:00,  5.32s/it]2025-08-19 20:08:14,464 - INFO - Comprehensive metrics saved for sklearn_mlp_20_train (ID: 20_train)\n",
      "2025-08-19 20:08:14,467 - INFO - Sklearn experiment 20/54 completed. CV mean: 0.9906±0.0016, Test F1: 0.9997\n",
      "Scikit-learn experiments:  37%|███▋      | 20/54 [01:49<03:00,  5.32s/it]2025-08-19 20:08:23,095 - INFO - Comprehensive metrics saved for sklearn_mlp_21 (ID: 21)\n",
      "2025-08-19 20:08:23,095 - INFO - Comprehensive metrics saved for sklearn_mlp_21 (ID: 21)\n",
      "2025-08-19 20:08:23,308 - INFO - Comprehensive metrics saved for sklearn_mlp_21_train (ID: 21_train)\n",
      "2025-08-19 20:08:23,311 - INFO - Sklearn experiment 21/54 completed. CV mean: 0.9906±0.0016, Test F1: 0.9997\n",
      "Scikit-learn experiments:  39%|███▉      | 21/54 [01:58<03:30,  6.38s/it]2025-08-19 20:08:23,308 - INFO - Comprehensive metrics saved for sklearn_mlp_21_train (ID: 21_train)\n",
      "2025-08-19 20:08:23,311 - INFO - Sklearn experiment 21/54 completed. CV mean: 0.9906±0.0016, Test F1: 0.9997\n",
      "Scikit-learn experiments:  39%|███▉      | 21/54 [01:58<03:30,  6.38s/it]2025-08-19 20:08:31,387 - INFO - Comprehensive metrics saved for sklearn_mlp_22 (ID: 22)\n",
      "2025-08-19 20:08:31,387 - INFO - Comprehensive metrics saved for sklearn_mlp_22 (ID: 22)\n",
      "2025-08-19 20:08:31,605 - INFO - Comprehensive metrics saved for sklearn_mlp_22_train (ID: 22_train)\n",
      "2025-08-19 20:08:31,608 - INFO - Sklearn experiment 22/54 completed. CV mean: 0.9822±0.0045, Test F1: 0.9848\n",
      "Scikit-learn experiments:  41%|████      | 22/54 [02:06<03:42,  6.95s/it]2025-08-19 20:08:31,605 - INFO - Comprehensive metrics saved for sklearn_mlp_22_train (ID: 22_train)\n",
      "2025-08-19 20:08:31,608 - INFO - Sklearn experiment 22/54 completed. CV mean: 0.9822±0.0045, Test F1: 0.9848\n",
      "Scikit-learn experiments:  41%|████      | 22/54 [02:06<03:42,  6.95s/it]2025-08-19 20:08:39,993 - INFO - Comprehensive metrics saved for sklearn_mlp_23 (ID: 23)\n",
      "2025-08-19 20:08:39,993 - INFO - Comprehensive metrics saved for sklearn_mlp_23 (ID: 23)\n",
      "2025-08-19 20:08:40,236 - INFO - Comprehensive metrics saved for sklearn_mlp_23_train (ID: 23_train)\n",
      "2025-08-19 20:08:40,239 - INFO - Sklearn experiment 23/54 completed. CV mean: 0.9822±0.0045, Test F1: 0.9848\n",
      "Scikit-learn experiments:  43%|████▎     | 23/54 [02:15<03:51,  7.46s/it]2025-08-19 20:08:40,236 - INFO - Comprehensive metrics saved for sklearn_mlp_23_train (ID: 23_train)\n",
      "2025-08-19 20:08:40,239 - INFO - Sklearn experiment 23/54 completed. CV mean: 0.9822±0.0045, Test F1: 0.9848\n",
      "Scikit-learn experiments:  43%|████▎     | 23/54 [02:15<03:51,  7.46s/it]2025-08-19 20:08:48,635 - INFO - Comprehensive metrics saved for sklearn_mlp_24 (ID: 24)\n",
      "2025-08-19 20:08:48,635 - INFO - Comprehensive metrics saved for sklearn_mlp_24 (ID: 24)\n",
      "2025-08-19 20:08:49,027 - INFO - Comprehensive metrics saved for sklearn_mlp_24_train (ID: 24_train)\n",
      "2025-08-19 20:08:49,030 - INFO - Sklearn experiment 24/54 completed. CV mean: 0.9822±0.0045, Test F1: 0.9848\n",
      "Scikit-learn experiments:  44%|████▍     | 24/54 [02:24<03:55,  7.86s/it]2025-08-19 20:08:49,027 - INFO - Comprehensive metrics saved for sklearn_mlp_24_train (ID: 24_train)\n",
      "2025-08-19 20:08:49,030 - INFO - Sklearn experiment 24/54 completed. CV mean: 0.9822±0.0045, Test F1: 0.9848\n",
      "Scikit-learn experiments:  44%|████▍     | 24/54 [02:24<03:55,  7.86s/it]2025-08-19 20:08:55,417 - INFO - Comprehensive metrics saved for sklearn_mlp_25 (ID: 25)\n",
      "2025-08-19 20:08:55,417 - INFO - Comprehensive metrics saved for sklearn_mlp_25 (ID: 25)\n",
      "2025-08-19 20:08:55,641 - INFO - Comprehensive metrics saved for sklearn_mlp_25_train (ID: 25_train)\n",
      "2025-08-19 20:08:55,643 - INFO - Sklearn experiment 25/54 completed. CV mean: 0.9920±0.0015, Test F1: 1.0000\n",
      "Scikit-learn experiments:  46%|████▋     | 25/54 [02:30<03:37,  7.48s/it]2025-08-19 20:08:55,641 - INFO - Comprehensive metrics saved for sklearn_mlp_25_train (ID: 25_train)\n",
      "2025-08-19 20:08:55,643 - INFO - Sklearn experiment 25/54 completed. CV mean: 0.9920±0.0015, Test F1: 1.0000\n",
      "Scikit-learn experiments:  46%|████▋     | 25/54 [02:30<03:37,  7.48s/it]2025-08-19 20:09:02,134 - INFO - Comprehensive metrics saved for sklearn_mlp_26 (ID: 26)\n",
      "2025-08-19 20:09:02,134 - INFO - Comprehensive metrics saved for sklearn_mlp_26 (ID: 26)\n",
      "2025-08-19 20:09:02,357 - INFO - Comprehensive metrics saved for sklearn_mlp_26_train (ID: 26_train)\n",
      "2025-08-19 20:09:02,360 - INFO - Sklearn experiment 26/54 completed. CV mean: 0.9920±0.0015, Test F1: 1.0000\n",
      "Scikit-learn experiments:  48%|████▊     | 26/54 [02:37<03:23,  7.25s/it]2025-08-19 20:09:02,357 - INFO - Comprehensive metrics saved for sklearn_mlp_26_train (ID: 26_train)\n",
      "2025-08-19 20:09:02,360 - INFO - Sklearn experiment 26/54 completed. CV mean: 0.9920±0.0015, Test F1: 1.0000\n",
      "Scikit-learn experiments:  48%|████▊     | 26/54 [02:37<03:23,  7.25s/it]2025-08-19 20:09:08,775 - INFO - Comprehensive metrics saved for sklearn_mlp_27 (ID: 27)\n",
      "2025-08-19 20:09:08,775 - INFO - Comprehensive metrics saved for sklearn_mlp_27 (ID: 27)\n",
      "2025-08-19 20:09:08,992 - INFO - Comprehensive metrics saved for sklearn_mlp_27_train (ID: 27_train)\n",
      "2025-08-19 20:09:08,994 - INFO - Sklearn experiment 27/54 completed. CV mean: 0.9920±0.0015, Test F1: 1.0000\n",
      "Scikit-learn experiments:  50%|█████     | 27/54 [02:44<03:10,  7.07s/it]2025-08-19 20:09:08,992 - INFO - Comprehensive metrics saved for sklearn_mlp_27_train (ID: 27_train)\n",
      "2025-08-19 20:09:08,994 - INFO - Sklearn experiment 27/54 completed. CV mean: 0.9920±0.0015, Test F1: 1.0000\n",
      "Scikit-learn experiments:  50%|█████     | 27/54 [02:44<03:10,  7.07s/it]2025-08-19 20:09:15,426 - INFO - Comprehensive metrics saved for sklearn_mlp_28 (ID: 28)\n",
      "2025-08-19 20:09:15,426 - INFO - Comprehensive metrics saved for sklearn_mlp_28 (ID: 28)\n",
      "2025-08-19 20:09:15,643 - INFO - Comprehensive metrics saved for sklearn_mlp_28_train (ID: 28_train)\n",
      "2025-08-19 20:09:15,646 - INFO - Sklearn experiment 28/54 completed. CV mean: 0.9920±0.0015, Test F1: 1.0000\n",
      "Scikit-learn experiments:  52%|█████▏    | 28/54 [02:50<03:00,  6.94s/it]2025-08-19 20:09:15,643 - INFO - Comprehensive metrics saved for sklearn_mlp_28_train (ID: 28_train)\n",
      "2025-08-19 20:09:15,646 - INFO - Sklearn experiment 28/54 completed. CV mean: 0.9920±0.0015, Test F1: 1.0000\n",
      "Scikit-learn experiments:  52%|█████▏    | 28/54 [02:50<03:00,  6.94s/it]2025-08-19 20:09:22,062 - INFO - Comprehensive metrics saved for sklearn_mlp_29 (ID: 29)\n",
      "2025-08-19 20:09:22,062 - INFO - Comprehensive metrics saved for sklearn_mlp_29 (ID: 29)\n",
      "2025-08-19 20:09:22,283 - INFO - Comprehensive metrics saved for sklearn_mlp_29_train (ID: 29_train)\n",
      "2025-08-19 20:09:22,285 - INFO - Sklearn experiment 29/54 completed. CV mean: 0.9920±0.0015, Test F1: 1.0000\n",
      "Scikit-learn experiments:  54%|█████▎    | 29/54 [02:57<02:51,  6.85s/it]2025-08-19 20:09:22,283 - INFO - Comprehensive metrics saved for sklearn_mlp_29_train (ID: 29_train)\n",
      "2025-08-19 20:09:22,285 - INFO - Sklearn experiment 29/54 completed. CV mean: 0.9920±0.0015, Test F1: 1.0000\n",
      "Scikit-learn experiments:  54%|█████▎    | 29/54 [02:57<02:51,  6.85s/it]2025-08-19 20:09:28,732 - INFO - Comprehensive metrics saved for sklearn_mlp_30 (ID: 30)\n",
      "2025-08-19 20:09:28,732 - INFO - Comprehensive metrics saved for sklearn_mlp_30 (ID: 30)\n",
      "2025-08-19 20:09:28,953 - INFO - Comprehensive metrics saved for sklearn_mlp_30_train (ID: 30_train)\n",
      "2025-08-19 20:09:28,956 - INFO - Sklearn experiment 30/54 completed. CV mean: 0.9920±0.0015, Test F1: 1.0000\n",
      "Scikit-learn experiments:  56%|█████▌    | 30/54 [03:04<02:43,  6.80s/it]2025-08-19 20:09:28,953 - INFO - Comprehensive metrics saved for sklearn_mlp_30_train (ID: 30_train)\n",
      "2025-08-19 20:09:28,956 - INFO - Sklearn experiment 30/54 completed. CV mean: 0.9920±0.0015, Test F1: 1.0000\n",
      "Scikit-learn experiments:  56%|█████▌    | 30/54 [03:04<02:43,  6.80s/it]2025-08-19 20:09:30,004 - ERROR - Sklearn experiment 31 failed with params {'hidden_layer_sizes': (32,), 'solver': 'adamw', 'learning_rate_init': 0.01, 'max_iter': 200}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:09:30,006 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  57%|█████▋    | 31/54 [03:05<01:56,  5.07s/it]2025-08-19 20:09:30,004 - ERROR - Sklearn experiment 31 failed with params {'hidden_layer_sizes': (32,), 'solver': 'adamw', 'learning_rate_init': 0.01, 'max_iter': 200}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:09:30,006 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  57%|█████▋    | 31/54 [03:05<01:56,  5.07s/it]2025-08-19 20:09:31,052 - ERROR - Sklearn experiment 32 failed with params {'hidden_layer_sizes': (32,), 'solver': 'adamw', 'learning_rate_init': 0.01, 'max_iter': 500}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:09:31,054 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  59%|█████▉    | 32/54 [03:06<01:25,  3.87s/it]2025-08-19 20:09:31,052 - ERROR - Sklearn experiment 32 failed with params {'hidden_layer_sizes': (32,), 'solver': 'adamw', 'learning_rate_init': 0.01, 'max_iter': 500}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:09:31,054 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  59%|█████▉    | 32/54 [03:06<01:25,  3.87s/it]2025-08-19 20:09:32,100 - ERROR - Sklearn experiment 33 failed with params {'hidden_layer_sizes': (32,), 'solver': 'adamw', 'learning_rate_init': 0.01, 'max_iter': 1000}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:09:32,105 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  61%|██████    | 33/54 [03:07<01:03,  3.02s/it]2025-08-19 20:09:32,100 - ERROR - Sklearn experiment 33 failed with params {'hidden_layer_sizes': (32,), 'solver': 'adamw', 'learning_rate_init': 0.01, 'max_iter': 1000}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:09:32,105 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  61%|██████    | 33/54 [03:07<01:03,  3.02s/it]2025-08-19 20:09:33,154 - ERROR - Sklearn experiment 34 failed with params {'hidden_layer_sizes': (32,), 'solver': 'adamw', 'learning_rate_init': 0.1, 'max_iter': 200}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:09:33,155 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  63%|██████▎   | 34/54 [03:08<00:48,  2.43s/it]2025-08-19 20:09:33,154 - ERROR - Sklearn experiment 34 failed with params {'hidden_layer_sizes': (32,), 'solver': 'adamw', 'learning_rate_init': 0.1, 'max_iter': 200}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:09:33,155 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  63%|██████▎   | 34/54 [03:08<00:48,  2.43s/it]2025-08-19 20:09:34,202 - ERROR - Sklearn experiment 35 failed with params {'hidden_layer_sizes': (32,), 'solver': 'adamw', 'learning_rate_init': 0.1, 'max_iter': 500}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:09:34,204 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  65%|██████▍   | 35/54 [03:09<00:38,  2.02s/it]2025-08-19 20:09:34,202 - ERROR - Sklearn experiment 35 failed with params {'hidden_layer_sizes': (32,), 'solver': 'adamw', 'learning_rate_init': 0.1, 'max_iter': 500}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:09:34,204 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  65%|██████▍   | 35/54 [03:09<00:38,  2.02s/it]2025-08-19 20:09:35,250 - ERROR - Sklearn experiment 36 failed with params {'hidden_layer_sizes': (32,), 'solver': 'adamw', 'learning_rate_init': 0.1, 'max_iter': 1000}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:09:35,252 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  67%|██████▋   | 36/54 [03:10<00:31,  1.73s/it]2025-08-19 20:09:35,250 - ERROR - Sklearn experiment 36 failed with params {'hidden_layer_sizes': (32,), 'solver': 'adamw', 'learning_rate_init': 0.1, 'max_iter': 1000}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:09:35,252 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  67%|██████▋   | 36/54 [03:10<00:31,  1.73s/it]2025-08-19 20:09:47,730 - INFO - Comprehensive metrics saved for sklearn_mlp_37 (ID: 37)\n",
      "2025-08-19 20:09:47,730 - INFO - Comprehensive metrics saved for sklearn_mlp_37 (ID: 37)\n",
      "2025-08-19 20:09:47,949 - INFO - Comprehensive metrics saved for sklearn_mlp_37_train (ID: 37_train)\n",
      "2025-08-19 20:09:47,953 - INFO - Sklearn experiment 37/54 completed. CV mean: 0.9874±0.0030, Test F1: 1.0000\n",
      "Scikit-learn experiments:  69%|██████▊   | 37/54 [03:23<01:25,  5.02s/it]2025-08-19 20:09:47,949 - INFO - Comprehensive metrics saved for sklearn_mlp_37_train (ID: 37_train)\n",
      "2025-08-19 20:09:47,953 - INFO - Sklearn experiment 37/54 completed. CV mean: 0.9874±0.0030, Test F1: 1.0000\n",
      "Scikit-learn experiments:  69%|██████▊   | 37/54 [03:23<01:25,  5.02s/it]2025-08-19 20:10:00,083 - INFO - Comprehensive metrics saved for sklearn_mlp_38 (ID: 38)\n",
      "2025-08-19 20:10:00,083 - INFO - Comprehensive metrics saved for sklearn_mlp_38 (ID: 38)\n",
      "2025-08-19 20:10:00,296 - INFO - Comprehensive metrics saved for sklearn_mlp_38_train (ID: 38_train)\n",
      "2025-08-19 20:10:00,299 - INFO - Sklearn experiment 38/54 completed. CV mean: 0.9874±0.0030, Test F1: 1.0000\n",
      "Scikit-learn experiments:  70%|███████   | 38/54 [03:35<01:55,  7.22s/it]2025-08-19 20:10:00,296 - INFO - Comprehensive metrics saved for sklearn_mlp_38_train (ID: 38_train)\n",
      "2025-08-19 20:10:00,299 - INFO - Sklearn experiment 38/54 completed. CV mean: 0.9874±0.0030, Test F1: 1.0000\n",
      "Scikit-learn experiments:  70%|███████   | 38/54 [03:35<01:55,  7.22s/it]2025-08-19 20:10:12,532 - INFO - Comprehensive metrics saved for sklearn_mlp_39 (ID: 39)\n",
      "2025-08-19 20:10:12,532 - INFO - Comprehensive metrics saved for sklearn_mlp_39 (ID: 39)\n",
      "2025-08-19 20:10:12,751 - INFO - Comprehensive metrics saved for sklearn_mlp_39_train (ID: 39_train)\n",
      "2025-08-19 20:10:12,755 - INFO - Sklearn experiment 39/54 completed. CV mean: 0.9874±0.0030, Test F1: 1.0000\n",
      "Scikit-learn experiments:  72%|███████▏  | 39/54 [03:47<02:11,  8.79s/it]2025-08-19 20:10:12,751 - INFO - Comprehensive metrics saved for sklearn_mlp_39_train (ID: 39_train)\n",
      "2025-08-19 20:10:12,755 - INFO - Sklearn experiment 39/54 completed. CV mean: 0.9874±0.0030, Test F1: 1.0000\n",
      "Scikit-learn experiments:  72%|███████▏  | 39/54 [03:47<02:11,  8.79s/it]2025-08-19 20:10:22,805 - INFO - Comprehensive metrics saved for sklearn_mlp_40 (ID: 40)\n",
      "2025-08-19 20:10:22,805 - INFO - Comprehensive metrics saved for sklearn_mlp_40 (ID: 40)\n",
      "2025-08-19 20:10:23,019 - INFO - Comprehensive metrics saved for sklearn_mlp_40_train (ID: 40_train)\n",
      "2025-08-19 20:10:23,022 - INFO - Sklearn experiment 40/54 completed. CV mean: 0.9796±0.0042, Test F1: 0.9766\n",
      "Scikit-learn experiments:  74%|███████▍  | 40/54 [03:58<02:09,  9.23s/it]2025-08-19 20:10:23,019 - INFO - Comprehensive metrics saved for sklearn_mlp_40_train (ID: 40_train)\n",
      "2025-08-19 20:10:23,022 - INFO - Sklearn experiment 40/54 completed. CV mean: 0.9796±0.0042, Test F1: 0.9766\n",
      "Scikit-learn experiments:  74%|███████▍  | 40/54 [03:58<02:09,  9.23s/it]2025-08-19 20:10:33,144 - INFO - Comprehensive metrics saved for sklearn_mlp_41 (ID: 41)\n",
      "2025-08-19 20:10:33,144 - INFO - Comprehensive metrics saved for sklearn_mlp_41 (ID: 41)\n",
      "2025-08-19 20:10:33,359 - INFO - Comprehensive metrics saved for sklearn_mlp_41_train (ID: 41_train)\n",
      "2025-08-19 20:10:33,362 - INFO - Sklearn experiment 41/54 completed. CV mean: 0.9796±0.0042, Test F1: 0.9766\n",
      "Scikit-learn experiments:  76%|███████▌  | 41/54 [04:08<02:04,  9.56s/it]2025-08-19 20:10:33,359 - INFO - Comprehensive metrics saved for sklearn_mlp_41_train (ID: 41_train)\n",
      "2025-08-19 20:10:33,362 - INFO - Sklearn experiment 41/54 completed. CV mean: 0.9796±0.0042, Test F1: 0.9766\n",
      "Scikit-learn experiments:  76%|███████▌  | 41/54 [04:08<02:04,  9.56s/it]2025-08-19 20:10:43,786 - INFO - Comprehensive metrics saved for sklearn_mlp_42 (ID: 42)\n",
      "2025-08-19 20:10:43,786 - INFO - Comprehensive metrics saved for sklearn_mlp_42 (ID: 42)\n",
      "2025-08-19 20:10:44,004 - INFO - Comprehensive metrics saved for sklearn_mlp_42_train (ID: 42_train)\n",
      "2025-08-19 20:10:44,007 - INFO - Sklearn experiment 42/54 completed. CV mean: 0.9796±0.0042, Test F1: 0.9766\n",
      "Scikit-learn experiments:  78%|███████▊  | 42/54 [04:19<01:58,  9.89s/it]2025-08-19 20:10:44,004 - INFO - Comprehensive metrics saved for sklearn_mlp_42_train (ID: 42_train)\n",
      "2025-08-19 20:10:44,007 - INFO - Sklearn experiment 42/54 completed. CV mean: 0.9796±0.0042, Test F1: 0.9766\n",
      "Scikit-learn experiments:  78%|███████▊  | 42/54 [04:19<01:58,  9.89s/it]2025-08-19 20:10:52,496 - INFO - Comprehensive metrics saved for sklearn_mlp_43 (ID: 43)\n",
      "2025-08-19 20:10:52,496 - INFO - Comprehensive metrics saved for sklearn_mlp_43 (ID: 43)\n",
      "2025-08-19 20:10:52,721 - INFO - Comprehensive metrics saved for sklearn_mlp_43_train (ID: 43_train)\n",
      "2025-08-19 20:10:52,724 - INFO - Sklearn experiment 43/54 completed. CV mean: 0.9904±0.0013, Test F1: 1.0000\n",
      "Scikit-learn experiments:  80%|███████▉  | 43/54 [04:27<01:44,  9.54s/it]2025-08-19 20:10:52,721 - INFO - Comprehensive metrics saved for sklearn_mlp_43_train (ID: 43_train)\n",
      "2025-08-19 20:10:52,724 - INFO - Sklearn experiment 43/54 completed. CV mean: 0.9904±0.0013, Test F1: 1.0000\n",
      "Scikit-learn experiments:  80%|███████▉  | 43/54 [04:27<01:44,  9.54s/it]2025-08-19 20:11:00,794 - INFO - Comprehensive metrics saved for sklearn_mlp_44 (ID: 44)\n",
      "2025-08-19 20:11:00,794 - INFO - Comprehensive metrics saved for sklearn_mlp_44 (ID: 44)\n",
      "2025-08-19 20:11:01,010 - INFO - Comprehensive metrics saved for sklearn_mlp_44_train (ID: 44_train)\n",
      "2025-08-19 20:11:01,012 - INFO - Sklearn experiment 44/54 completed. CV mean: 0.9904±0.0013, Test F1: 1.0000\n",
      "Scikit-learn experiments:  81%|████████▏ | 44/54 [04:36<01:31,  9.16s/it]2025-08-19 20:11:01,010 - INFO - Comprehensive metrics saved for sklearn_mlp_44_train (ID: 44_train)\n",
      "2025-08-19 20:11:01,012 - INFO - Sklearn experiment 44/54 completed. CV mean: 0.9904±0.0013, Test F1: 1.0000\n",
      "Scikit-learn experiments:  81%|████████▏ | 44/54 [04:36<01:31,  9.16s/it]2025-08-19 20:11:09,176 - INFO - Comprehensive metrics saved for sklearn_mlp_45 (ID: 45)\n",
      "2025-08-19 20:11:09,176 - INFO - Comprehensive metrics saved for sklearn_mlp_45 (ID: 45)\n",
      "2025-08-19 20:11:09,390 - INFO - Comprehensive metrics saved for sklearn_mlp_45_train (ID: 45_train)\n",
      "2025-08-19 20:11:09,392 - INFO - Sklearn experiment 45/54 completed. CV mean: 0.9904±0.0013, Test F1: 1.0000\n",
      "Scikit-learn experiments:  83%|████████▎ | 45/54 [04:44<01:20,  8.93s/it]2025-08-19 20:11:09,390 - INFO - Comprehensive metrics saved for sklearn_mlp_45_train (ID: 45_train)\n",
      "2025-08-19 20:11:09,392 - INFO - Sklearn experiment 45/54 completed. CV mean: 0.9904±0.0013, Test F1: 1.0000\n",
      "Scikit-learn experiments:  83%|████████▎ | 45/54 [04:44<01:20,  8.93s/it]2025-08-19 20:11:17,624 - INFO - Comprehensive metrics saved for sklearn_mlp_46 (ID: 46)\n",
      "2025-08-19 20:11:17,624 - INFO - Comprehensive metrics saved for sklearn_mlp_46 (ID: 46)\n",
      "2025-08-19 20:11:17,839 - INFO - Comprehensive metrics saved for sklearn_mlp_46_train (ID: 46_train)\n",
      "2025-08-19 20:11:17,841 - INFO - Sklearn experiment 46/54 completed. CV mean: 0.9904±0.0013, Test F1: 1.0000\n",
      "Scikit-learn experiments:  85%|████████▌ | 46/54 [04:53<01:10,  8.78s/it]2025-08-19 20:11:17,839 - INFO - Comprehensive metrics saved for sklearn_mlp_46_train (ID: 46_train)\n",
      "2025-08-19 20:11:17,841 - INFO - Sklearn experiment 46/54 completed. CV mean: 0.9904±0.0013, Test F1: 1.0000\n",
      "Scikit-learn experiments:  85%|████████▌ | 46/54 [04:53<01:10,  8.78s/it]2025-08-19 20:11:25,948 - INFO - Comprehensive metrics saved for sklearn_mlp_47 (ID: 47)\n",
      "2025-08-19 20:11:25,948 - INFO - Comprehensive metrics saved for sklearn_mlp_47 (ID: 47)\n",
      "2025-08-19 20:11:26,164 - INFO - Comprehensive metrics saved for sklearn_mlp_47_train (ID: 47_train)\n",
      "2025-08-19 20:11:26,166 - INFO - Sklearn experiment 47/54 completed. CV mean: 0.9904±0.0013, Test F1: 1.0000\n",
      "Scikit-learn experiments:  87%|████████▋ | 47/54 [05:01<01:00,  8.65s/it]2025-08-19 20:11:26,164 - INFO - Comprehensive metrics saved for sklearn_mlp_47_train (ID: 47_train)\n",
      "2025-08-19 20:11:26,166 - INFO - Sklearn experiment 47/54 completed. CV mean: 0.9904±0.0013, Test F1: 1.0000\n",
      "Scikit-learn experiments:  87%|████████▋ | 47/54 [05:01<01:00,  8.65s/it]2025-08-19 20:11:34,320 - INFO - Comprehensive metrics saved for sklearn_mlp_48 (ID: 48)\n",
      "2025-08-19 20:11:34,320 - INFO - Comprehensive metrics saved for sklearn_mlp_48 (ID: 48)\n",
      "2025-08-19 20:11:34,536 - INFO - Comprehensive metrics saved for sklearn_mlp_48_train (ID: 48_train)\n",
      "2025-08-19 20:11:34,539 - INFO - Sklearn experiment 48/54 completed. CV mean: 0.9904±0.0013, Test F1: 1.0000\n",
      "Scikit-learn experiments:  89%|████████▉ | 48/54 [05:09<00:51,  8.56s/it]2025-08-19 20:11:34,536 - INFO - Comprehensive metrics saved for sklearn_mlp_48_train (ID: 48_train)\n",
      "2025-08-19 20:11:34,539 - INFO - Sklearn experiment 48/54 completed. CV mean: 0.9904±0.0013, Test F1: 1.0000\n",
      "Scikit-learn experiments:  89%|████████▉ | 48/54 [05:09<00:51,  8.56s/it]2025-08-19 20:11:35,586 - ERROR - Sklearn experiment 49 failed with params {'hidden_layer_sizes': (64,), 'solver': 'adamw', 'learning_rate_init': 0.01, 'max_iter': 200}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:11:35,588 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  91%|█████████ | 49/54 [05:10<00:31,  6.31s/it]2025-08-19 20:11:35,586 - ERROR - Sklearn experiment 49 failed with params {'hidden_layer_sizes': (64,), 'solver': 'adamw', 'learning_rate_init': 0.01, 'max_iter': 200}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:11:35,588 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  91%|█████████ | 49/54 [05:10<00:31,  6.31s/it]2025-08-19 20:11:36,634 - ERROR - Sklearn experiment 50 failed with params {'hidden_layer_sizes': (64,), 'solver': 'adamw', 'learning_rate_init': 0.01, 'max_iter': 500}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:11:36,636 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  93%|█████████▎| 50/54 [05:11<00:18,  4.73s/it]2025-08-19 20:11:36,634 - ERROR - Sklearn experiment 50 failed with params {'hidden_layer_sizes': (64,), 'solver': 'adamw', 'learning_rate_init': 0.01, 'max_iter': 500}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:11:36,636 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  93%|█████████▎| 50/54 [05:11<00:18,  4.73s/it]2025-08-19 20:11:37,690 - ERROR - Sklearn experiment 51 failed with params {'hidden_layer_sizes': (64,), 'solver': 'adamw', 'learning_rate_init': 0.01, 'max_iter': 1000}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:11:37,692 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  94%|█████████▍| 51/54 [05:12<00:10,  3.63s/it]2025-08-19 20:11:37,690 - ERROR - Sklearn experiment 51 failed with params {'hidden_layer_sizes': (64,), 'solver': 'adamw', 'learning_rate_init': 0.01, 'max_iter': 1000}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:11:37,692 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  94%|█████████▍| 51/54 [05:12<00:10,  3.63s/it]2025-08-19 20:11:38,739 - ERROR - Sklearn experiment 52 failed with params {'hidden_layer_sizes': (64,), 'solver': 'adamw', 'learning_rate_init': 0.1, 'max_iter': 200}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:11:38,741 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  96%|█████████▋| 52/54 [05:13<00:05,  2.85s/it]2025-08-19 20:11:38,739 - ERROR - Sklearn experiment 52 failed with params {'hidden_layer_sizes': (64,), 'solver': 'adamw', 'learning_rate_init': 0.1, 'max_iter': 200}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:11:38,741 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  96%|█████████▋| 52/54 [05:13<00:05,  2.85s/it]2025-08-19 20:11:39,794 - ERROR - Sklearn experiment 53 failed with params {'hidden_layer_sizes': (64,), 'solver': 'adamw', 'learning_rate_init': 0.1, 'max_iter': 500}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:11:39,796 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "2025-08-19 20:11:39,794 - ERROR - Sklearn experiment 53 failed with params {'hidden_layer_sizes': (64,), 'solver': 'adamw', 'learning_rate_init': 0.1, 'max_iter': 500}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:11:39,796 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments:  98%|█████████▊| 53/54 [05:15<00:02,  2.31s/it]2025-08-19 20:11:40,859 - ERROR - Sklearn experiment 54 failed with params {'hidden_layer_sizes': (64,), 'solver': 'adamw', 'learning_rate_init': 0.1, 'max_iter': 1000}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:11:40,860 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments: 100%|██████████| 54/54 [05:16<00:00,  5.85s/it]\n",
      "2025-08-19 20:11:40,862 - INFO - Completed 36 successful scikit-learn experiments\n",
      "2025-08-19 20:11:40,859 - ERROR - Sklearn experiment 54 failed with params {'hidden_layer_sizes': (64,), 'solver': 'adamw', 'learning_rate_init': 0.1, 'max_iter': 1000}: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "2025-08-19 20:11:40,860 - ERROR - Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vhuta\\AppData\\Local\\Temp\\ipykernel_38836\\963565606.py\", line 36, in <module>\n",
      "    cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 677, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "        estimator=estimator,\n",
      "    ...<9 lines>...\n",
      "        error_score=error_score,\n",
      "    )\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 218, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 419, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 505, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1358, in wrapper\n",
      "    estimator._validate_params()\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 471, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        self._parameter_constraints,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.get_params(deep=False),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        caller_name=self.__class__.__name__,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vhuta\\Desktop\\OralSmart - Data Analysis\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of MLPClassifier must be a str among {'adam', 'sgd', 'lbfgs'}. Got 'adamw' instead.\n",
      "\n",
      "\n",
      "Scikit-learn experiments: 100%|██████████| 54/54 [05:16<00:00,  5.85s/it]\n",
      "2025-08-19 20:11:40,862 - INFO - Completed 36 successful scikit-learn experiments\n",
      "2025-08-19 20:11:41,091 - INFO - Comprehensive metrics saved for BEST_sklearn_model (ID: BEST)\n",
      "2025-08-19 20:11:41,093 - INFO - Best sklearn model saved (Experiment 7) with score: 0.9939\n",
      "2025-08-19 20:11:41,097 - INFO - Scikit-learn results saved to sklearn_results_summary.csv\n",
      "2025-08-19 20:11:41,091 - INFO - Comprehensive metrics saved for BEST_sklearn_model (ID: BEST)\n",
      "2025-08-19 20:11:41,093 - INFO - Best sklearn model saved (Experiment 7) with score: 0.9939\n",
      "2025-08-19 20:11:41,097 - INFO - Scikit-learn results saved to sklearn_results_summary.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best scikit-learn result (by CV score):\n",
      "CV accuracy: 0.9939±0.0008\n",
      "Test accuracy: 1.0000\n",
      "Test F1-macro: 1.0000\n",
      "Test Precision-macro: 1.0000\n",
      "Test Recall-macro: 1.0000\n",
      "Parameters: hidden_sizes=(25,), solver=lbfgs, lr=0.01\n"
     ]
    }
   ],
   "source": [
    "# Scikit-learn MLP experiments with Cross-Validation and Comprehensive Metrics\n",
    "sklearn_results = []\n",
    "combos = list(product(*sklearn_param_grid.values()))\n",
    "keys = list(sklearn_param_grid.keys())\n",
    "\n",
    "logger.info(f\"Starting {len(combos)} scikit-learn experiments\")\n",
    "if use_cross_validation:\n",
    "    logger.info(f\"Using {n_folds}-fold cross-validation (this will increase training time by ~{n_folds}x)\")\n",
    "\n",
    "# Combine train and test data for cross-validation\n",
    "X_full = np.vstack([X_train_s, X_test_s])\n",
    "y_full = np.concatenate([y_train, y_test])\n",
    "\n",
    "# Set up cross-validation\n",
    "if use_cross_validation:\n",
    "    cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    cv_splits = list(cv.split(X_full, y_full))\n",
    "\n",
    "best_sklearn_model = None\n",
    "best_sklearn_score = 0.0\n",
    "\n",
    "for i, combo in enumerate(tqdm(combos, desc=\"Scikit-learn experiments\")):\n",
    "    try:\n",
    "        params = dict(zip(keys, combo))\n",
    "        logger.debug(f\"Testing sklearn params: {params}\")\n",
    "        \n",
    "        # Log system resources\n",
    "        memory_usage = psutil.virtual_memory().percent\n",
    "        cpu_usage = psutil.cpu_percent(interval=1)\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        if use_cross_validation:\n",
    "            # Cross-validation approach\n",
    "            clf = MLPClassifier(**params, random_state=42)\n",
    "            cv_scores = cross_val_score(clf, X_full, y_full, cv=cv, scoring='accuracy')\n",
    "            \n",
    "            # Train on full dataset to get other metrics\n",
    "            clf.fit(X_full, y_full)\n",
    "            \n",
    "            # Calculate metrics on original train/test split for comparison\n",
    "            train_pred = clf.predict(X_train_s)\n",
    "            test_pred = clf.predict(X_test_s)\n",
    "            train_acc = accuracy_score(y_train, train_pred)\n",
    "            test_acc = accuracy_score(y_test, test_pred)\n",
    "            \n",
    "            cv_mean = cv_scores.mean()\n",
    "            cv_std = cv_scores.std()\n",
    "            \n",
    "        else:\n",
    "            # Original single train/test split approach\n",
    "            clf = MLPClassifier(**params, random_state=42)\n",
    "            clf.fit(X_train_s, y_train)\n",
    "            \n",
    "            train_pred = clf.predict(X_train_s)\n",
    "            test_pred = clf.predict(X_test_s)\n",
    "            train_acc = accuracy_score(y_train, train_pred)\n",
    "            test_acc = accuracy_score(y_test, test_pred)\n",
    "            \n",
    "            cv_mean = None\n",
    "            cv_std = None\n",
    "        \n",
    "        end_time = datetime.now()\n",
    "        duration = (end_time - start_time).total_seconds()\n",
    "        \n",
    "        # Calculate comprehensive metrics for test set\n",
    "        model_name = f\"sklearn_mlp_{i+1}\"\n",
    "        test_metrics = calculate_comprehensive_metrics(\n",
    "            y_test, test_pred, model_name, i+1, 'sklearn'\n",
    "        )\n",
    "        \n",
    "        # Calculate comprehensive metrics for training set\n",
    "        train_metrics = calculate_comprehensive_metrics(\n",
    "            y_train, train_pred, f\"{model_name}_train\", f\"{i+1}_train\", 'sklearn'\n",
    "        )\n",
    "        \n",
    "        # Save model\n",
    "        import joblib\n",
    "        model_path = os.path.join(OUTDIR, 'sklearn_models', f'sklearn_model_{i+1}.joblib')\n",
    "        joblib.dump(clf, model_path)\n",
    "        \n",
    "        # Track best model\n",
    "        score_for_comparison = cv_mean if use_cross_validation else test_acc\n",
    "        if score_for_comparison > best_sklearn_score:\n",
    "            best_sklearn_score = score_for_comparison\n",
    "            best_sklearn_model = {\n",
    "                'model': clf,\n",
    "                'experiment_id': i+1,\n",
    "                'params': params,\n",
    "                'test_metrics': test_metrics,\n",
    "                'train_metrics': train_metrics,\n",
    "                'model_path': model_path\n",
    "            }\n",
    "        \n",
    "        result = {\n",
    "            'experiment_id': i + 1,\n",
    "            'params': params,\n",
    "            'train_acc': train_acc,\n",
    "            'test_acc': test_acc,\n",
    "            'train_precision_macro': train_metrics['precision_macro'],\n",
    "            'train_recall_macro': train_metrics['recall_macro'],\n",
    "            'train_f1_macro': train_metrics['f1_macro'],\n",
    "            'test_precision_macro': test_metrics['precision_macro'],\n",
    "            'test_recall_macro': test_metrics['recall_macro'],\n",
    "            'test_f1_macro': test_metrics['f1_macro'],\n",
    "            'test_precision_weighted': test_metrics['precision_weighted'],\n",
    "            'test_recall_weighted': test_metrics['recall_weighted'],\n",
    "            'test_f1_weighted': test_metrics['f1_weighted'],\n",
    "            'cv_mean_acc': cv_mean,\n",
    "            'cv_std_acc': cv_std,\n",
    "            'n_iter': clf.n_iter_,\n",
    "            'loss_curve': clf.loss_curve_ if hasattr(clf, 'loss_curve_') else None,\n",
    "            'duration_seconds': duration,\n",
    "            'memory_usage_percent': memory_usage,\n",
    "            'cpu_usage_percent': cpu_usage,\n",
    "            'timestamp': start_time.isoformat(),\n",
    "            'model_path': model_path\n",
    "        }\n",
    "        \n",
    "        sklearn_results.append(result)\n",
    "        \n",
    "        if use_cross_validation:\n",
    "            logger.info(f\"Sklearn experiment {i+1}/{len(combos)} completed. CV mean: {cv_mean:.4f}±{cv_std:.4f}, Test F1: {test_metrics['f1_macro']:.4f}\")\n",
    "        else:\n",
    "            logger.info(f\"Sklearn experiment {i+1}/{len(combos)} completed. Train acc: {train_acc:.4f}, Test F1: {test_metrics['f1_macro']:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Sklearn experiment {i+1} failed with params {params}: {str(e)}\")\n",
    "        logger.error(traceback.format_exc())\n",
    "        continue\n",
    "\n",
    "logger.info(f\"Completed {len(sklearn_results)} successful scikit-learn experiments\")\n",
    "\n",
    "# Save best sklearn model with special designation\n",
    "if best_sklearn_model:\n",
    "    best_model_dir = os.path.join(OUTDIR, 'best_models')\n",
    "    os.makedirs(best_model_dir, exist_ok=True)\n",
    "    \n",
    "    # Save best model\n",
    "    best_model_path = os.path.join(best_model_dir, 'best_sklearn_model.joblib')\n",
    "    joblib.dump(best_sklearn_model['model'], best_model_path)\n",
    "    \n",
    "    # Save best model metrics with special naming\n",
    "    best_test_metrics = calculate_comprehensive_metrics(\n",
    "        y_test, best_sklearn_model['model'].predict(X_test_s), \n",
    "        'BEST_sklearn_model', 'BEST', 'sklearn_best'\n",
    "    )\n",
    "    \n",
    "    # Save best model info\n",
    "    best_info = {\n",
    "        'experiment_id': best_sklearn_model['experiment_id'],\n",
    "        'params': best_sklearn_model['params'],\n",
    "        'metrics': best_test_metrics,\n",
    "        'model_path': best_model_path,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(best_model_dir, 'best_sklearn_model_info.json'), 'w') as f:\n",
    "        json.dump(best_info, f, indent=2)\n",
    "    \n",
    "    logger.info(f\"Best sklearn model saved (Experiment {best_sklearn_model['experiment_id']}) with score: {best_sklearn_score:.4f}\")\n",
    "\n",
    "# Save sklearn results\n",
    "if sklearn_results:\n",
    "    sklearn_df = pd.DataFrame([\n",
    "        {\n",
    "            'experiment_id': r['experiment_id'],\n",
    "            'hidden_layer_sizes': str(r['params']['hidden_layer_sizes']),\n",
    "            'solver': r['params']['solver'],\n",
    "            'learning_rate_init': r['params']['learning_rate_init'],\n",
    "            'max_iter': r['params']['max_iter'],\n",
    "            'train_acc': r['train_acc'],\n",
    "            'test_acc': r['test_acc'],\n",
    "            'train_f1_macro': r['train_f1_macro'],\n",
    "            'test_f1_macro': r['test_f1_macro'],\n",
    "            'test_precision_macro': r['test_precision_macro'],\n",
    "            'test_recall_macro': r['test_recall_macro'],\n",
    "            'test_f1_weighted': r['test_f1_weighted'],\n",
    "            'cv_mean_acc': r['cv_mean_acc'],\n",
    "            'cv_std_acc': r['cv_std_acc'],\n",
    "            'n_iter': r['n_iter'],\n",
    "            'duration_seconds': r['duration_seconds'],\n",
    "            'memory_usage_percent': r['memory_usage_percent'],\n",
    "            'cpu_usage_percent': r['cpu_usage_percent'],\n",
    "            'timestamp': r['timestamp'],\n",
    "            'model_path': r['model_path']\n",
    "        } for r in sklearn_results\n",
    "    ])\n",
    "    sklearn_df.to_csv(os.path.join(OUTDIR, 'sklearn_results_summary.csv'), index=False)\n",
    "    logger.info(\"Scikit-learn results saved to sklearn_results_summary.csv\")\n",
    "    \n",
    "    # Display best results\n",
    "    if use_cross_validation:\n",
    "        best_sklearn = sklearn_df.loc[sklearn_df['cv_mean_acc'].idxmax()]\n",
    "        print(f\"\\nBest scikit-learn result (by CV score):\")\n",
    "        print(f\"CV accuracy: {best_sklearn['cv_mean_acc']:.4f}±{best_sklearn['cv_std_acc']:.4f}\")\n",
    "        print(f\"Test accuracy: {best_sklearn['test_acc']:.4f}\")\n",
    "        print(f\"Test F1-macro: {best_sklearn['test_f1_macro']:.4f}\")\n",
    "        print(f\"Test Precision-macro: {best_sklearn['test_precision_macro']:.4f}\")\n",
    "        print(f\"Test Recall-macro: {best_sklearn['test_recall_macro']:.4f}\")\n",
    "        print(f\"Parameters: hidden_sizes={best_sklearn['hidden_layer_sizes']}, solver={best_sklearn['solver']}, lr={best_sklearn['learning_rate_init']}\")\n",
    "    else:\n",
    "        best_sklearn = sklearn_df.loc[sklearn_df['test_acc'].idxmax()]\n",
    "        print(f\"\\nBest scikit-learn result:\")\n",
    "        print(f\"Test accuracy: {best_sklearn['test_acc']:.4f}\")\n",
    "        print(f\"Test F1-macro: {best_sklearn['test_f1_macro']:.4f}\")\n",
    "        print(f\"Test Precision-macro: {best_sklearn['test_precision_macro']:.4f}\")\n",
    "        print(f\"Test Recall-macro: {best_sklearn['test_recall_macro']:.4f}\")\n",
    "        print(f\"Parameters: hidden_sizes={best_sklearn['hidden_layer_sizes']}, solver={best_sklearn['solver']}, lr={best_sklearn['learning_rate_init']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68a938d6-eee8-4cb8-b78c-9114b8374f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in c:\\users\\vhuta\\desktop\\oralsmart - data analysis\\venv\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\vhuta\\desktop\\oralsmart - data analysis\\venv\\lib\\site-packages (from tensorboard) (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\vhuta\\desktop\\oralsmart - data analysis\\venv\\lib\\site-packages (from tensorboard) (1.74.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\vhuta\\desktop\\oralsmart - data analysis\\venv\\lib\\site-packages (from tensorboard) (3.8.2)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\vhuta\\desktop\\oralsmart - data analysis\\venv\\lib\\site-packages (from tensorboard) (2.3.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\vhuta\\desktop\\oralsmart - data analysis\\venv\\lib\\site-packages (from tensorboard) (25.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\vhuta\\desktop\\oralsmart - data analysis\\venv\\lib\\site-packages (from tensorboard) (11.3.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\vhuta\\desktop\\oralsmart - data analysis\\venv\\lib\\site-packages (from tensorboard) (6.31.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\vhuta\\desktop\\oralsmart - data analysis\\venv\\lib\\site-packages (from tensorboard) (80.9.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\vhuta\\desktop\\oralsmart - data analysis\\venv\\lib\\site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\vhuta\\desktop\\oralsmart - data analysis\\venv\\lib\\site-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\vhuta\\desktop\\oralsmart - data analysis\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e90270f4-a097-4f5f-b1a9-740f7be89339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PyTorch installed: 2.8.0+cu128\n",
      "✅ CUDA available: True\n",
      "✅ GPU device: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Add this cell to check PyTorch installation\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"✅ PyTorch installed: {torch.__version__}\")\n",
    "    print(f\"✅ CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"✅ GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"⚠️  CUDA not available - will use CPU\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ PyTorch not installed: {e}\")\n",
    "    print(\"Install with: pip install torch torchvision torchaudio\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ PyTorch error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pytorch_setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:11:44,157 - INFO - MLflow experiment tracking enabled\n",
      "2025-08-19 20:11:44,158 - INFO - PyTorch device: cuda\n",
      "2025-08-19 20:11:44,158 - INFO - CUDA device: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "2025-08-19 20:11:44,159 - INFO - CUDA memory: 6.0 GB\n",
      "2025-08-19 20:11:44,162 - INFO - PyTorch setup completed successfully\n",
      "2025-08-19 20:11:44,158 - INFO - PyTorch device: cuda\n",
      "2025-08-19 20:11:44,158 - INFO - CUDA device: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "2025-08-19 20:11:44,159 - INFO - CUDA memory: 6.0 GB\n",
      "2025-08-19 20:11:44,162 - INFO - PyTorch setup completed successfully\n"
     ]
    }
   ],
   "source": [
    "# PyTorch experiments setup\n",
    "if use_pytorch:\n",
    "    try:\n",
    "        import torch\n",
    "        import torch.nn as nn\n",
    "        import torch.optim as optim\n",
    "        from torch.utils.data import TensorDataset, DataLoader\n",
    "        from torch.utils.tensorboard import SummaryWriter\n",
    "        \n",
    "        # MLflow setup (optional)\n",
    "        if use_mlflow:\n",
    "            import mlflow\n",
    "            import mlflow.pytorch\n",
    "            mlflow.set_experiment(\"MLP_Hyperparameter_Search\")\n",
    "            logger.info(\"MLflow experiment tracking enabled\")\n",
    "        \n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        logger.info(f'PyTorch device: {device}')\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            logger.info(f'CUDA device: {torch.cuda.get_device_name(0)}')\n",
    "            logger.info(f'CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')\n",
    "        \n",
    "        def build_pytorch_model(input_size, hidden_sizes, dropout=0.0, n_classes=None):\n",
    "            layers = []\n",
    "            in_size = input_size\n",
    "            for h in hidden_sizes:\n",
    "                layers.append(nn.Linear(in_size, h))\n",
    "                layers.append(nn.ReLU())\n",
    "                if dropout and dropout > 0.0:\n",
    "                    layers.append(nn.Dropout(dropout))\n",
    "                in_size = h\n",
    "            layers.append(nn.Linear(in_size, n_classes))\n",
    "            return nn.Sequential(*layers)\n",
    "        \n",
    "        # Prepare PyTorch tensors\n",
    "        X_train_t = torch.FloatTensor(X_train_s)\n",
    "        y_train_t = torch.LongTensor(y_train.values if hasattr(y_train, 'values') else y_train)\n",
    "        X_test_t = torch.FloatTensor(X_test_s)\n",
    "        y_test_t = torch.LongTensor(y_test.values if hasattr(y_test, 'values') else y_test)\n",
    "        \n",
    "        logger.info(\"PyTorch setup completed successfully\")\n",
    "        \n",
    "    except ImportError as e:\n",
    "        logger.error(f\"PyTorch import failed: {str(e)}\")\n",
    "        use_pytorch = False\n",
    "    except Exception as e:\n",
    "        logger.error(f\"PyTorch setup failed: {str(e)}\")\n",
    "        logger.error(traceback.format_exc())\n",
    "        use_pytorch = False\n",
    "else:\n",
    "    logger.info(\"PyTorch experiments disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1743f9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:11:44,173 - INFO - Early stopping configured with patience=10, min_delta=0.0001\n"
     ]
    }
   ],
   "source": [
    "# Early Stopping Class for PyTorch Training\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, min_delta=0.0001, restore_best_weights=True, verbose=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                          Default: 7\n",
    "            min_delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                              Default: 0.0001\n",
    "            restore_best_weights (bool): Whether to restore model weights from the epoch with the best value.\n",
    "                                       Default: True\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                          Default: True\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                logger.debug(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            logger.debug(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model checkpoint...')\n",
    "        self.val_loss_min = val_loss\n",
    "        if self.restore_best_weights:\n",
    "            self.best_model_state = model.state_dict().copy()\n",
    "\n",
    "    def restore_best_model(self, model):\n",
    "        \"\"\"Restore the best model weights if available\"\"\"\n",
    "        if self.restore_best_weights and self.best_model_state is not None:\n",
    "            model.load_state_dict(self.best_model_state)\n",
    "            if self.verbose:\n",
    "                logger.info(f'Restored model to best validation loss: {self.val_loss_min:.6f}')\n",
    "\n",
    "# Early stopping configuration\n",
    "EARLY_STOPPING_PATIENCE = 10  # Stop if no improvement for 10 epochs\n",
    "EARLY_STOPPING_MIN_DELTA = 0.0001  # Minimum improvement threshold\n",
    "\n",
    "logger.info(f\"Early stopping configured with patience={EARLY_STOPPING_PATIENCE}, min_delta={EARLY_STOPPING_MIN_DELTA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91646e8",
   "metadata": {},
   "source": [
    "## Early Stopping Implementation ✅\n",
    "\n",
    "**Early stopping has been successfully implemented** with the following features:\n",
    "\n",
    "### **Configuration:**\n",
    "- **Patience**: 10 epochs (stops training if no improvement for 10 consecutive epochs)\n",
    "- **Minimum Delta**: 0.0001 (minimum improvement threshold to be considered significant)\n",
    "- **Restore Best Weights**: Automatically restores model to the best validation loss checkpoint\n",
    "\n",
    "### **Benefits:**\n",
    "1. **Prevents Overfitting**: Stops training when validation loss stops improving\n",
    "2. **Saves Training Time**: Automatically stops when further training won't help\n",
    "3. **Optimal Performance**: Returns the model with the best validation performance\n",
    "4. **Literature Recommended**: Early stopping is a standard best practice\n",
    "\n",
    "### **Training Process:**\n",
    "- **Cross-validation**: Uses reduced patience (5 epochs) for faster fold training\n",
    "- **Final model**: Uses full patience (10 epochs) for optimal performance\n",
    "- **Validation frequency**: Every epoch (required for effective early stopping)\n",
    "\n",
    "### **Result Tracking:**\n",
    "The results now include early stopping metrics:\n",
    "- `early_stopped`: Whether early stopping was triggered\n",
    "- `epochs_trained`: Actual epochs trained (may be less than specified)\n",
    "- `best_val_loss`: Best validation loss achieved\n",
    "- `early_stop_epoch`: Epoch where early stopping occurred\n",
    "\n",
    "### **Plotting Fix:**\n",
    "- **Issue**: Validation plotting error due to dimension mismatch\n",
    "- **Solution**: Updated plotting to handle per-epoch validation data\n",
    "- **Status**: ✅ **FIXED** - Plotting now works correctly with early stopping\n",
    "\n",
    "### **Example Results:**\n",
    "```\n",
    "Early stopping triggered at epoch 92/100 (patience=10)\n",
    "Best validation loss: 0.012756\n",
    "Model weights restored to best validation loss checkpoint\n",
    "```\n",
    "\n",
    "This implementation follows **literature best practices** and is especially beneficial for synthetic data where clear patterns allow for early convergence.\n",
    "\n",
    "**You can now continue with the PyTorch experiments!** 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dfe1ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:22:01,362 - INFO - Previous MLflow run ended successfully\n",
      "2025-08-19 20:22:01,363 - INFO - MLflow status: Enabled\n"
     ]
    }
   ],
   "source": [
    "# MLflow Cleanup - Fix Active Run Issue\n",
    "try:\n",
    "    import mlflow\n",
    "    # End any active MLflow run\n",
    "    if mlflow.active_run():\n",
    "        mlflow.end_run()\n",
    "        logger.info(\"Previous MLflow run ended successfully\")\n",
    "    else:\n",
    "        logger.info(\"No active MLflow run found\")\n",
    "        \n",
    "    # Optionally disable MLflow if there are persistent issues\n",
    "    # use_mlflow = False  # Uncomment this line to disable MLflow temporarily\n",
    "    \n",
    "    logger.info(f\"MLflow status: {'Enabled' if use_mlflow else 'Disabled'}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.warning(f\"MLflow cleanup failed: {str(e)}\")\n",
    "    logger.info(\"Disabling MLflow for this session to prevent errors\")\n",
    "    use_mlflow = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "pytorch_experiments",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 20:24:01,996 - INFO - Starting 72 PyTorch experiments\n",
      "2025-08-19 20:24:01,996 - INFO - Using 5-fold cross-validation (this will increase training time by ~5x)\n",
      "PyTorch experiments:   0%|          | 0/72 [00:00<?, ?it/s]2025-08-19 20:24:01,996 - INFO - Using 5-fold cross-validation (this will increase training time by ~5x)\n",
      "PyTorch experiments:   0%|          | 0/72 [00:00<?, ?it/s]2025-08-19 20:24:02,000 - INFO - \n",
      "PyTorch experiment 1/72: {'hidden_sizes': [25], 'learning_rate': 0.001, 'dropout': 0.2, 'batch_size': 64, 'epochs': 100}\n",
      "2025-08-19 20:24:02,000 - INFO - \n",
      "PyTorch experiment 1/72: {'hidden_sizes': [25], 'learning_rate': 0.001, 'dropout': 0.2, 'batch_size': 64, 'epochs': 100}\n",
      "2025-08-19 20:26:51,183 - INFO - Early stopping triggered at epoch 62/100 (patience=10)\n",
      "2025-08-19 20:26:51,184 - INFO - Best validation loss: 0.017867\n",
      "2025-08-19 20:26:51,185 - INFO - Restored model to best validation loss: 0.017867\n",
      "2025-08-19 20:26:51,185 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:26:51,398 - INFO - Comprehensive metrics saved for pytorch_mlp_1 (ID: 1)\n",
      "2025-08-19 20:26:51,611 - INFO - Comprehensive metrics saved for pytorch_mlp_1_train (ID: 1_train)\n",
      "2025-08-19 20:26:52,207 - INFO - PyTorch experiment 1/72 completed. CV val: 0.9938±0.0007, Test F1: 0.9935\n",
      "PyTorch experiments:   1%|▏         | 1/72 [02:50<3:21:25, 170.21s/it]2025-08-19 20:26:52,213 - INFO - \n",
      "PyTorch experiment 2/72: {'hidden_sizes': [25], 'learning_rate': 0.001, 'dropout': 0.2, 'batch_size': 64, 'epochs': 150}\n",
      "2025-08-19 20:29:23,086 - INFO - Early stopping triggered at epoch 67/150 (patience=10)\n",
      "2025-08-19 20:29:23,087 - INFO - Best validation loss: 0.016164\n",
      "2025-08-19 20:29:23,088 - INFO - Restored model to best validation loss: 0.016164\n",
      "2025-08-19 20:29:23,089 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:29:23,297 - INFO - Comprehensive metrics saved for pytorch_mlp_2 (ID: 2)\n",
      "2025-08-19 20:29:23,511 - INFO - Comprehensive metrics saved for pytorch_mlp_2_train (ID: 2_train)\n",
      "2025-08-19 20:29:24,121 - INFO - PyTorch experiment 2/72 completed. CV val: 0.9928±0.0017, Test F1: 0.9926\n",
      "PyTorch experiments:   3%|▎         | 2/72 [05:22<3:06:01, 159.45s/it]2025-08-19 20:29:24,128 - INFO - \n",
      "PyTorch experiment 3/72: {'hidden_sizes': [25], 'learning_rate': 0.001, 'dropout': 0.2, 'batch_size': 128, 'epochs': 100}\n",
      "2025-08-19 20:31:33,089 - INFO - Early stopping triggered at epoch 96/100 (patience=10)\n",
      "2025-08-19 20:31:33,089 - INFO - Best validation loss: 0.015227\n",
      "2025-08-19 20:31:33,090 - INFO - Restored model to best validation loss: 0.015227\n",
      "2025-08-19 20:31:33,091 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:31:33,302 - INFO - Comprehensive metrics saved for pytorch_mlp_3 (ID: 3)\n",
      "2025-08-19 20:31:33,514 - INFO - Comprehensive metrics saved for pytorch_mlp_3_train (ID: 3_train)\n",
      "2025-08-19 20:31:34,129 - INFO - PyTorch experiment 3/72 completed. CV val: 0.9926±0.0017, Test F1: 0.9957\n",
      "PyTorch experiments:   4%|▍         | 3/72 [07:32<2:47:54, 146.01s/it]2025-08-19 20:31:34,136 - INFO - \n",
      "PyTorch experiment 4/72: {'hidden_sizes': [25], 'learning_rate': 0.001, 'dropout': 0.2, 'batch_size': 128, 'epochs': 150}\n",
      "2025-08-19 20:33:39,898 - INFO - Early stopping triggered at epoch 81/150 (patience=10)\n",
      "2025-08-19 20:33:39,899 - INFO - Best validation loss: 0.017135\n",
      "2025-08-19 20:33:39,900 - INFO - Restored model to best validation loss: 0.017135\n",
      "2025-08-19 20:33:39,901 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:33:40,118 - INFO - Comprehensive metrics saved for pytorch_mlp_4 (ID: 4)\n",
      "2025-08-19 20:33:40,352 - INFO - Comprehensive metrics saved for pytorch_mlp_4_train (ID: 4_train)\n",
      "2025-08-19 20:33:40,973 - INFO - PyTorch experiment 4/72 completed. CV val: 0.9930±0.0019, Test F1: 0.9953\n",
      "PyTorch experiments:   6%|▌         | 4/72 [09:38<2:36:54, 138.44s/it]2025-08-19 20:33:40,981 - INFO - \n",
      "PyTorch experiment 5/72: {'hidden_sizes': [25], 'learning_rate': 0.001, 'dropout': 0.5, 'batch_size': 64, 'epochs': 100}\n",
      "2025-08-19 20:36:39,755 - INFO - Restored model to best validation loss: 0.015963\n",
      "2025-08-19 20:36:39,756 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:36:39,983 - INFO - Comprehensive metrics saved for pytorch_mlp_5 (ID: 5)\n",
      "2025-08-19 20:36:40,202 - INFO - Comprehensive metrics saved for pytorch_mlp_5_train (ID: 5_train)\n",
      "2025-08-19 20:36:40,821 - INFO - PyTorch experiment 5/72 completed. CV val: 0.9895±0.0014, Test F1: 0.9936\n",
      "PyTorch experiments:   7%|▋         | 5/72 [12:38<2:51:15, 153.37s/it]2025-08-19 20:36:40,828 - INFO - \n",
      "PyTorch experiment 6/72: {'hidden_sizes': [25], 'learning_rate': 0.001, 'dropout': 0.5, 'batch_size': 64, 'epochs': 150}\n",
      "2025-08-19 20:39:28,726 - INFO - Early stopping triggered at epoch 86/150 (patience=10)\n",
      "2025-08-19 20:39:28,727 - INFO - Best validation loss: 0.015221\n",
      "2025-08-19 20:39:28,727 - INFO - Restored model to best validation loss: 0.015221\n",
      "2025-08-19 20:39:28,728 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:39:28,940 - INFO - Comprehensive metrics saved for pytorch_mlp_6 (ID: 6)\n",
      "2025-08-19 20:39:29,154 - INFO - Comprehensive metrics saved for pytorch_mlp_6_train (ID: 6_train)\n",
      "2025-08-19 20:39:30,016 - INFO - PyTorch experiment 6/72 completed. CV val: 0.9888±0.0029, Test F1: 0.9921\n",
      "PyTorch experiments:   8%|▊         | 6/72 [15:28<2:54:37, 158.75s/it]2025-08-19 20:39:30,023 - INFO - \n",
      "PyTorch experiment 7/72: {'hidden_sizes': [25], 'learning_rate': 0.001, 'dropout': 0.5, 'batch_size': 128, 'epochs': 100}\n",
      "2025-08-19 20:41:41,747 - INFO - Restored model to best validation loss: 0.017262\n",
      "2025-08-19 20:41:41,748 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:41:41,970 - INFO - Comprehensive metrics saved for pytorch_mlp_7 (ID: 7)\n",
      "2025-08-19 20:41:42,189 - INFO - Comprehensive metrics saved for pytorch_mlp_7_train (ID: 7_train)\n",
      "2025-08-19 20:41:42,772 - INFO - PyTorch experiment 7/72 completed. CV val: 0.9883±0.0033, Test F1: 0.9937\n",
      "PyTorch experiments:  10%|▉         | 7/72 [17:40<2:42:46, 150.25s/it]2025-08-19 20:41:42,779 - INFO - \n",
      "PyTorch experiment 8/72: {'hidden_sizes': [25], 'learning_rate': 0.001, 'dropout': 0.5, 'batch_size': 128, 'epochs': 150}\n",
      "2025-08-19 20:43:56,789 - INFO - Early stopping triggered at epoch 111/150 (patience=10)\n",
      "2025-08-19 20:43:56,790 - INFO - Best validation loss: 0.018736\n",
      "2025-08-19 20:43:56,791 - INFO - Restored model to best validation loss: 0.018736\n",
      "2025-08-19 20:43:56,791 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:43:57,028 - INFO - Comprehensive metrics saved for pytorch_mlp_8 (ID: 8)\n",
      "2025-08-19 20:43:57,242 - INFO - Comprehensive metrics saved for pytorch_mlp_8_train (ID: 8_train)\n",
      "2025-08-19 20:43:57,829 - INFO - PyTorch experiment 8/72 completed. CV val: 0.9888±0.0018, Test F1: 0.9926\n",
      "PyTorch experiments:  11%|█         | 8/72 [19:55<2:35:06, 145.42s/it]2025-08-19 20:43:57,836 - INFO - \n",
      "PyTorch experiment 9/72: {'hidden_sizes': [25], 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 64, 'epochs': 100}\n",
      "2025-08-19 20:45:23,136 - INFO - Early stopping triggered at epoch 64/100 (patience=10)\n",
      "2025-08-19 20:45:23,137 - INFO - Best validation loss: 0.022366\n",
      "2025-08-19 20:45:23,138 - INFO - Restored model to best validation loss: 0.022366\n",
      "2025-08-19 20:45:23,139 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:45:23,369 - INFO - Comprehensive metrics saved for pytorch_mlp_9 (ID: 9)\n",
      "2025-08-19 20:45:23,584 - INFO - Comprehensive metrics saved for pytorch_mlp_9_train (ID: 9_train)\n",
      "2025-08-19 20:45:24,219 - INFO - PyTorch experiment 9/72 completed. CV val: 0.9844±0.0035, Test F1: 0.9894\n",
      "PyTorch experiments:  12%|█▎        | 9/72 [21:22<2:13:18, 126.96s/it]2025-08-19 20:45:24,226 - INFO - \n",
      "PyTorch experiment 10/72: {'hidden_sizes': [25], 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 64, 'epochs': 150}\n",
      "2025-08-19 20:46:52,495 - INFO - Early stopping triggered at epoch 47/150 (patience=10)\n",
      "2025-08-19 20:46:52,496 - INFO - Best validation loss: 0.026740\n",
      "2025-08-19 20:46:52,497 - INFO - Restored model to best validation loss: 0.026740\n",
      "2025-08-19 20:46:52,498 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:46:52,710 - INFO - Comprehensive metrics saved for pytorch_mlp_10 (ID: 10)\n",
      "2025-08-19 20:46:52,923 - INFO - Comprehensive metrics saved for pytorch_mlp_10_train (ID: 10_train)\n",
      "2025-08-19 20:46:53,514 - INFO - PyTorch experiment 10/72 completed. CV val: 0.9850±0.0067, Test F1: 0.9892\n",
      "PyTorch experiments:  14%|█▍        | 10/72 [22:51<1:59:10, 115.33s/it]2025-08-19 20:46:53,521 - INFO - \n",
      "PyTorch experiment 11/72: {'hidden_sizes': [25], 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'epochs': 100}\n",
      "2025-08-19 20:47:40,087 - INFO - Early stopping triggered at epoch 58/100 (patience=10)\n",
      "2025-08-19 20:47:40,088 - INFO - Best validation loss: 0.023011\n",
      "2025-08-19 20:47:40,088 - INFO - Restored model to best validation loss: 0.023011\n",
      "2025-08-19 20:47:40,089 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:47:40,322 - INFO - Comprehensive metrics saved for pytorch_mlp_11 (ID: 11)\n",
      "2025-08-19 20:47:40,554 - INFO - Comprehensive metrics saved for pytorch_mlp_11_train (ID: 11_train)\n",
      "2025-08-19 20:47:41,183 - INFO - PyTorch experiment 11/72 completed. CV val: 0.9854±0.0027, Test F1: 0.9902\n",
      "PyTorch experiments:  15%|█▌        | 11/72 [23:39<1:36:12, 94.63s/it] 2025-08-19 20:47:41,190 - INFO - \n",
      "PyTorch experiment 12/72: {'hidden_sizes': [25], 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'epochs': 150}\n",
      "2025-08-19 20:48:24,697 - INFO - Early stopping triggered at epoch 34/150 (patience=10)\n",
      "2025-08-19 20:48:24,698 - INFO - Best validation loss: 0.032512\n",
      "2025-08-19 20:48:24,699 - INFO - Restored model to best validation loss: 0.032512\n",
      "2025-08-19 20:48:24,699 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:48:24,914 - INFO - Comprehensive metrics saved for pytorch_mlp_12 (ID: 12)\n",
      "2025-08-19 20:48:25,126 - INFO - Comprehensive metrics saved for pytorch_mlp_12_train (ID: 12_train)\n",
      "2025-08-19 20:48:25,743 - INFO - PyTorch experiment 12/72 completed. CV val: 0.9850±0.0021, Test F1: 0.9872\n",
      "PyTorch experiments:  17%|█▋        | 12/72 [24:23<1:19:23, 79.39s/it]2025-08-19 20:48:25,750 - INFO - \n",
      "PyTorch experiment 13/72: {'hidden_sizes': [25], 'learning_rate': 0.01, 'dropout': 0.5, 'batch_size': 64, 'epochs': 100}\n",
      "2025-08-19 20:49:33,318 - INFO - Early stopping triggered at epoch 29/100 (patience=10)\n",
      "2025-08-19 20:49:33,319 - INFO - Best validation loss: 0.041250\n",
      "2025-08-19 20:49:33,320 - INFO - Restored model to best validation loss: 0.041250\n",
      "2025-08-19 20:49:33,320 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:49:33,534 - INFO - Comprehensive metrics saved for pytorch_mlp_13 (ID: 13)\n",
      "2025-08-19 20:49:33,751 - INFO - Comprehensive metrics saved for pytorch_mlp_13_train (ID: 13_train)\n",
      "2025-08-19 20:49:34,354 - INFO - PyTorch experiment 13/72 completed. CV val: 0.9811±0.0067, Test F1: 0.9845\n",
      "PyTorch experiments:  18%|█▊        | 13/72 [25:32<1:14:51, 76.13s/it]2025-08-19 20:49:34,362 - INFO - \n",
      "PyTorch experiment 14/72: {'hidden_sizes': [25], 'learning_rate': 0.01, 'dropout': 0.5, 'batch_size': 64, 'epochs': 150}\n",
      "2025-08-19 20:51:16,640 - INFO - Early stopping triggered at epoch 88/150 (patience=10)\n",
      "2025-08-19 20:51:16,641 - INFO - Best validation loss: 0.021134\n",
      "2025-08-19 20:51:16,642 - INFO - Restored model to best validation loss: 0.021134\n",
      "2025-08-19 20:51:16,642 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:51:16,858 - INFO - Comprehensive metrics saved for pytorch_mlp_14 (ID: 14)\n",
      "2025-08-19 20:51:17,077 - INFO - Comprehensive metrics saved for pytorch_mlp_14_train (ID: 14_train)\n",
      "2025-08-19 20:51:17,689 - INFO - PyTorch experiment 14/72 completed. CV val: 0.9808±0.0043, Test F1: 0.9908\n",
      "PyTorch experiments:  19%|█▉        | 14/72 [27:15<1:21:32, 84.35s/it]2025-08-19 20:51:17,696 - INFO - \n",
      "PyTorch experiment 15/72: {'hidden_sizes': [25], 'learning_rate': 0.01, 'dropout': 0.5, 'batch_size': 128, 'epochs': 100}\n",
      "2025-08-19 20:52:21,974 - INFO - Early stopping triggered at epoch 72/100 (patience=10)\n",
      "2025-08-19 20:52:21,975 - INFO - Best validation loss: 0.025321\n",
      "2025-08-19 20:52:21,976 - INFO - Restored model to best validation loss: 0.025321\n",
      "2025-08-19 20:52:21,976 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:52:22,187 - INFO - Comprehensive metrics saved for pytorch_mlp_15 (ID: 15)\n",
      "2025-08-19 20:52:22,405 - INFO - Comprehensive metrics saved for pytorch_mlp_15_train (ID: 15_train)\n",
      "2025-08-19 20:52:23,388 - INFO - PyTorch experiment 15/72 completed. CV val: 0.9832±0.0024, Test F1: 0.9875\n",
      "PyTorch experiments:  21%|██        | 15/72 [28:21<1:14:47, 78.73s/it]2025-08-19 20:52:23,396 - INFO - \n",
      "PyTorch experiment 16/72: {'hidden_sizes': [25], 'learning_rate': 0.01, 'dropout': 0.5, 'batch_size': 128, 'epochs': 150}\n",
      "2025-08-19 20:53:26,363 - INFO - Early stopping triggered at epoch 44/150 (patience=10)\n",
      "2025-08-19 20:53:26,364 - INFO - Best validation loss: 0.028625\n",
      "2025-08-19 20:53:26,365 - INFO - Restored model to best validation loss: 0.028625\n",
      "2025-08-19 20:53:26,366 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:53:26,580 - INFO - Comprehensive metrics saved for pytorch_mlp_16 (ID: 16)\n",
      "2025-08-19 20:53:26,791 - INFO - Comprehensive metrics saved for pytorch_mlp_16_train (ID: 16_train)\n",
      "2025-08-19 20:53:27,411 - INFO - PyTorch experiment 16/72 completed. CV val: 0.9850±0.0039, Test F1: 0.9885\n",
      "PyTorch experiments:  22%|██▏       | 16/72 [29:25<1:09:20, 74.30s/it]2025-08-19 20:53:27,418 - INFO - \n",
      "PyTorch experiment 17/72: {'hidden_sizes': [25], 'learning_rate': 0.1, 'dropout': 0.2, 'batch_size': 64, 'epochs': 100}\n",
      "2025-08-19 20:54:05,472 - INFO - Early stopping triggered at epoch 22/100 (patience=10)\n",
      "2025-08-19 20:54:05,473 - INFO - Best validation loss: 0.131709\n",
      "2025-08-19 20:54:05,474 - INFO - Restored model to best validation loss: 0.131709\n",
      "2025-08-19 20:54:05,474 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:54:05,683 - INFO - Comprehensive metrics saved for pytorch_mlp_17 (ID: 17)\n",
      "2025-08-19 20:54:05,895 - INFO - Comprehensive metrics saved for pytorch_mlp_17_train (ID: 17_train)\n",
      "2025-08-19 20:54:06,506 - INFO - PyTorch experiment 17/72 completed. CV val: 0.9602±0.0073, Test F1: 0.9523\n",
      "PyTorch experiments:  24%|██▎       | 17/72 [30:04<58:24, 63.71s/it]  2025-08-19 20:54:06,513 - INFO - \n",
      "PyTorch experiment 18/72: {'hidden_sizes': [25], 'learning_rate': 0.1, 'dropout': 0.2, 'batch_size': 64, 'epochs': 150}\n",
      "2025-08-19 20:54:43,619 - INFO - Early stopping triggered at epoch 22/150 (patience=10)\n",
      "2025-08-19 20:54:43,620 - INFO - Best validation loss: 0.105094\n",
      "2025-08-19 20:54:43,621 - INFO - Restored model to best validation loss: 0.105094\n",
      "2025-08-19 20:54:43,621 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:54:43,831 - INFO - Comprehensive metrics saved for pytorch_mlp_18 (ID: 18)\n",
      "2025-08-19 20:54:44,051 - INFO - Comprehensive metrics saved for pytorch_mlp_18_train (ID: 18_train)\n",
      "2025-08-19 20:54:44,674 - INFO - PyTorch experiment 18/72 completed. CV val: 0.9538±0.0060, Test F1: 0.9693\n",
      "PyTorch experiments:  25%|██▌       | 18/72 [30:42<50:26, 56.04s/it]2025-08-19 20:54:44,682 - INFO - \n",
      "PyTorch experiment 19/72: {'hidden_sizes': [25], 'learning_rate': 0.1, 'dropout': 0.2, 'batch_size': 128, 'epochs': 100}\n",
      "2025-08-19 20:55:20,830 - INFO - Early stopping triggered at epoch 33/100 (patience=10)\n",
      "2025-08-19 20:55:20,831 - INFO - Best validation loss: 0.080722\n",
      "2025-08-19 20:55:20,832 - INFO - Restored model to best validation loss: 0.080722\n",
      "2025-08-19 20:55:20,833 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:55:21,046 - INFO - Comprehensive metrics saved for pytorch_mlp_19 (ID: 19)\n",
      "2025-08-19 20:55:21,262 - INFO - Comprehensive metrics saved for pytorch_mlp_19_train (ID: 19_train)\n",
      "2025-08-19 20:55:21,885 - INFO - PyTorch experiment 19/72 completed. CV val: 0.9698±0.0064, Test F1: 0.9569\n",
      "PyTorch experiments:  26%|██▋       | 19/72 [31:19<44:30, 50.38s/it]2025-08-19 20:55:21,893 - INFO - \n",
      "PyTorch experiment 20/72: {'hidden_sizes': [25], 'learning_rate': 0.1, 'dropout': 0.2, 'batch_size': 128, 'epochs': 150}\n",
      "2025-08-19 20:55:47,668 - INFO - Early stopping triggered at epoch 24/150 (patience=10)\n",
      "2025-08-19 20:55:47,669 - INFO - Best validation loss: 0.099228\n",
      "2025-08-19 20:55:47,670 - INFO - Restored model to best validation loss: 0.099228\n",
      "2025-08-19 20:55:47,670 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:55:47,880 - INFO - Comprehensive metrics saved for pytorch_mlp_20 (ID: 20)\n",
      "2025-08-19 20:55:48,097 - INFO - Comprehensive metrics saved for pytorch_mlp_20_train (ID: 20_train)\n",
      "2025-08-19 20:55:48,708 - INFO - PyTorch experiment 20/72 completed. CV val: 0.9674±0.0020, Test F1: 0.9711\n",
      "PyTorch experiments:  28%|██▊       | 20/72 [31:46<37:32, 43.31s/it]2025-08-19 20:55:48,716 - INFO - \n",
      "PyTorch experiment 21/72: {'hidden_sizes': [25], 'learning_rate': 0.1, 'dropout': 0.5, 'batch_size': 64, 'epochs': 100}\n",
      "2025-08-19 20:56:23,399 - INFO - Early stopping triggered at epoch 16/100 (patience=10)\n",
      "2025-08-19 20:56:23,400 - INFO - Best validation loss: 0.195213\n",
      "2025-08-19 20:56:23,400 - INFO - Restored model to best validation loss: 0.195213\n",
      "2025-08-19 20:56:23,401 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:56:23,608 - INFO - Comprehensive metrics saved for pytorch_mlp_21 (ID: 21)\n",
      "2025-08-19 20:56:23,822 - INFO - Comprehensive metrics saved for pytorch_mlp_21_train (ID: 21_train)\n",
      "2025-08-19 20:56:24,429 - INFO - PyTorch experiment 21/72 completed. CV val: 0.9344±0.0108, Test F1: 0.8968\n",
      "PyTorch experiments:  29%|██▉       | 21/72 [32:22<34:52, 41.03s/it]2025-08-19 20:56:24,437 - INFO - \n",
      "PyTorch experiment 22/72: {'hidden_sizes': [25], 'learning_rate': 0.1, 'dropout': 0.5, 'batch_size': 64, 'epochs': 150}\n",
      "2025-08-19 20:56:52,531 - INFO - Early stopping triggered at epoch 16/150 (patience=10)\n",
      "2025-08-19 20:56:52,532 - INFO - Best validation loss: 0.277198\n",
      "2025-08-19 20:56:52,533 - INFO - Restored model to best validation loss: 0.277198\n",
      "2025-08-19 20:56:52,533 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:56:52,911 - INFO - Comprehensive metrics saved for pytorch_mlp_22 (ID: 22)\n",
      "2025-08-19 20:56:53,362 - INFO - Comprehensive metrics saved for pytorch_mlp_22_train (ID: 22_train)\n",
      "2025-08-19 20:56:54,378 - INFO - PyTorch experiment 22/72 completed. CV val: 0.9299±0.0138, Test F1: 0.9196\n",
      "PyTorch experiments:  31%|███       | 22/72 [32:52<31:25, 37.71s/it]2025-08-19 20:56:54,388 - INFO - \n",
      "PyTorch experiment 23/72: {'hidden_sizes': [25], 'learning_rate': 0.1, 'dropout': 0.5, 'batch_size': 128, 'epochs': 100}\n",
      "2025-08-19 20:57:26,672 - INFO - Early stopping triggered at epoch 23/100 (patience=10)\n",
      "2025-08-19 20:57:26,673 - INFO - Best validation loss: 0.145591\n",
      "2025-08-19 20:57:26,674 - INFO - Restored model to best validation loss: 0.145591\n",
      "2025-08-19 20:57:26,674 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:57:26,898 - INFO - Comprehensive metrics saved for pytorch_mlp_23 (ID: 23)\n",
      "2025-08-19 20:57:27,129 - INFO - Comprehensive metrics saved for pytorch_mlp_23_train (ID: 23_train)\n",
      "2025-08-19 20:57:27,756 - INFO - PyTorch experiment 23/72 completed. CV val: 0.9479±0.0057, Test F1: 0.9523\n",
      "PyTorch experiments:  32%|███▏      | 23/72 [33:25<29:43, 36.41s/it]2025-08-19 20:57:27,764 - INFO - \n",
      "PyTorch experiment 24/72: {'hidden_sizes': [25], 'learning_rate': 0.1, 'dropout': 0.5, 'batch_size': 128, 'epochs': 150}\n",
      "2025-08-19 20:57:55,264 - INFO - Early stopping triggered at epoch 15/150 (patience=10)\n",
      "2025-08-19 20:57:55,264 - INFO - Best validation loss: 0.154432\n",
      "2025-08-19 20:57:55,265 - INFO - Restored model to best validation loss: 0.154432\n",
      "2025-08-19 20:57:55,266 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 20:57:55,487 - INFO - Comprehensive metrics saved for pytorch_mlp_24 (ID: 24)\n",
      "2025-08-19 20:57:55,705 - INFO - Comprehensive metrics saved for pytorch_mlp_24_train (ID: 24_train)\n",
      "2025-08-19 20:57:56,337 - INFO - PyTorch experiment 24/72 completed. CV val: 0.9241±0.0411, Test F1: 0.9451\n",
      "PyTorch experiments:  33%|███▎      | 24/72 [33:54<27:14, 34.06s/it]2025-08-19 20:57:56,345 - INFO - \n",
      "PyTorch experiment 25/72: {'hidden_sizes': [32], 'learning_rate': 0.001, 'dropout': 0.2, 'batch_size': 64, 'epochs': 100}\n",
      "2025-08-19 21:00:37,506 - INFO - Early stopping triggered at epoch 82/100 (patience=10)\n",
      "2025-08-19 21:00:37,507 - INFO - Best validation loss: 0.016797\n",
      "2025-08-19 21:00:37,507 - INFO - Restored model to best validation loss: 0.016797\n",
      "2025-08-19 21:00:37,508 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:00:37,733 - INFO - Comprehensive metrics saved for pytorch_mlp_25 (ID: 25)\n",
      "2025-08-19 21:00:37,947 - INFO - Comprehensive metrics saved for pytorch_mlp_25_train (ID: 25_train)\n",
      "2025-08-19 21:00:38,997 - INFO - PyTorch experiment 25/72 completed. CV val: 0.9922±0.0022, Test F1: 0.9938\n",
      "PyTorch experiments:  35%|███▍      | 25/72 [36:37<56:54, 72.64s/it]2025-08-19 21:00:39,004 - INFO - \n",
      "PyTorch experiment 26/72: {'hidden_sizes': [32], 'learning_rate': 0.001, 'dropout': 0.2, 'batch_size': 64, 'epochs': 150}\n",
      "2025-08-19 21:03:31,022 - INFO - Early stopping triggered at epoch 90/150 (patience=10)\n",
      "2025-08-19 21:03:31,023 - INFO - Best validation loss: 0.010877\n",
      "2025-08-19 21:03:31,024 - INFO - Restored model to best validation loss: 0.010877\n",
      "2025-08-19 21:03:31,025 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:03:31,256 - INFO - Comprehensive metrics saved for pytorch_mlp_26 (ID: 26)\n",
      "2025-08-19 21:03:31,492 - INFO - Comprehensive metrics saved for pytorch_mlp_26_train (ID: 26_train)\n",
      "2025-08-19 21:03:32,194 - INFO - PyTorch experiment 26/72 completed. CV val: 0.9925±0.0021, Test F1: 0.9946\n",
      "PyTorch experiments:  36%|███▌      | 26/72 [39:30<1:18:49, 102.81s/it]2025-08-19 21:03:32,202 - INFO - \n",
      "PyTorch experiment 27/72: {'hidden_sizes': [32], 'learning_rate': 0.001, 'dropout': 0.2, 'batch_size': 128, 'epochs': 100}\n",
      "2025-08-19 21:05:48,338 - INFO - Restored model to best validation loss: 0.013759\n",
      "2025-08-19 21:05:48,339 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:05:48,581 - INFO - Comprehensive metrics saved for pytorch_mlp_27 (ID: 27)\n",
      "2025-08-19 21:05:48,804 - INFO - Comprehensive metrics saved for pytorch_mlp_27_train (ID: 27_train)\n",
      "2025-08-19 21:05:49,493 - INFO - PyTorch experiment 27/72 completed. CV val: 0.9935±0.0010, Test F1: 0.9934\n",
      "PyTorch experiments:  38%|███▊      | 27/72 [41:47<1:24:52, 113.16s/it]2025-08-19 21:05:49,503 - INFO - \n",
      "PyTorch experiment 28/72: {'hidden_sizes': [32], 'learning_rate': 0.001, 'dropout': 0.2, 'batch_size': 128, 'epochs': 150}\n",
      "2025-08-19 21:07:34,915 - INFO - Early stopping triggered at epoch 84/150 (patience=10)\n",
      "2025-08-19 21:07:34,916 - INFO - Best validation loss: 0.015842\n",
      "2025-08-19 21:07:34,917 - INFO - Restored model to best validation loss: 0.015842\n",
      "2025-08-19 21:07:34,917 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:07:35,133 - INFO - Comprehensive metrics saved for pytorch_mlp_28 (ID: 28)\n",
      "2025-08-19 21:07:35,346 - INFO - Comprehensive metrics saved for pytorch_mlp_28_train (ID: 28_train)\n",
      "2025-08-19 21:07:35,964 - INFO - PyTorch experiment 28/72 completed. CV val: 0.9916±0.0011, Test F1: 0.9942\n",
      "PyTorch experiments:  39%|███▉      | 28/72 [43:33<1:21:30, 111.15s/it]2025-08-19 21:07:35,972 - INFO - \n",
      "PyTorch experiment 29/72: {'hidden_sizes': [32], 'learning_rate': 0.001, 'dropout': 0.5, 'batch_size': 64, 'epochs': 100}\n",
      "2025-08-19 21:09:55,490 - INFO - Early stopping triggered at epoch 70/100 (patience=10)\n",
      "2025-08-19 21:09:55,491 - INFO - Best validation loss: 0.019500\n",
      "2025-08-19 21:09:55,492 - INFO - Restored model to best validation loss: 0.019500\n",
      "2025-08-19 21:09:55,492 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:09:55,712 - INFO - Comprehensive metrics saved for pytorch_mlp_29 (ID: 29)\n",
      "2025-08-19 21:09:55,924 - INFO - Comprehensive metrics saved for pytorch_mlp_29_train (ID: 29_train)\n",
      "2025-08-19 21:09:56,521 - INFO - PyTorch experiment 29/72 completed. CV val: 0.9901±0.0024, Test F1: 0.9934\n",
      "PyTorch experiments:  40%|████      | 29/72 [45:54<1:25:58, 119.97s/it]2025-08-19 21:09:56,528 - INFO - \n",
      "PyTorch experiment 30/72: {'hidden_sizes': [32], 'learning_rate': 0.001, 'dropout': 0.5, 'batch_size': 64, 'epochs': 150}\n",
      "2025-08-19 21:12:29,315 - INFO - Early stopping triggered at epoch 79/150 (patience=10)\n",
      "2025-08-19 21:12:29,316 - INFO - Best validation loss: 0.019955\n",
      "2025-08-19 21:12:29,317 - INFO - Restored model to best validation loss: 0.019955\n",
      "2025-08-19 21:12:29,317 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:12:29,539 - INFO - Comprehensive metrics saved for pytorch_mlp_30 (ID: 30)\n",
      "2025-08-19 21:12:29,772 - INFO - Comprehensive metrics saved for pytorch_mlp_30_train (ID: 30_train)\n",
      "2025-08-19 21:12:30,413 - INFO - PyTorch experiment 30/72 completed. CV val: 0.9897±0.0016, Test F1: 0.9926\n",
      "PyTorch experiments:  42%|████▏     | 30/72 [48:28<1:31:06, 130.15s/it]2025-08-19 21:12:30,421 - INFO - \n",
      "PyTorch experiment 31/72: {'hidden_sizes': [32], 'learning_rate': 0.001, 'dropout': 0.5, 'batch_size': 128, 'epochs': 100}\n",
      "2025-08-19 21:14:50,158 - INFO - Restored model to best validation loss: 0.016480\n",
      "2025-08-19 21:14:50,159 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:14:50,382 - INFO - Comprehensive metrics saved for pytorch_mlp_31 (ID: 31)\n",
      "2025-08-19 21:14:50,600 - INFO - Comprehensive metrics saved for pytorch_mlp_31_train (ID: 31_train)\n",
      "2025-08-19 21:14:51,215 - INFO - PyTorch experiment 31/72 completed. CV val: 0.9916±0.0016, Test F1: 0.9934\n",
      "PyTorch experiments:  43%|████▎     | 31/72 [50:49<1:31:07, 133.35s/it]2025-08-19 21:14:51,223 - INFO - \n",
      "PyTorch experiment 32/72: {'hidden_sizes': [32], 'learning_rate': 0.001, 'dropout': 0.5, 'batch_size': 128, 'epochs': 150}\n",
      "2025-08-19 21:17:13,078 - INFO - Early stopping triggered at epoch 127/150 (patience=10)\n",
      "2025-08-19 21:17:13,078 - INFO - Best validation loss: 0.011453\n",
      "2025-08-19 21:17:13,079 - INFO - Restored model to best validation loss: 0.011453\n",
      "2025-08-19 21:17:13,080 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:17:13,311 - INFO - Comprehensive metrics saved for pytorch_mlp_32 (ID: 32)\n",
      "2025-08-19 21:17:13,528 - INFO - Comprehensive metrics saved for pytorch_mlp_32_train (ID: 32_train)\n",
      "2025-08-19 21:17:14,130 - INFO - PyTorch experiment 32/72 completed. CV val: 0.9902±0.0025, Test F1: 0.9958\n",
      "PyTorch experiments:  44%|████▍     | 32/72 [53:12<1:30:48, 136.22s/it]2025-08-19 21:17:14,137 - INFO - \n",
      "PyTorch experiment 33/72: {'hidden_sizes': [32], 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 64, 'epochs': 100}\n",
      "2025-08-19 21:18:20,901 - INFO - Early stopping triggered at epoch 17/100 (patience=10)\n",
      "2025-08-19 21:18:20,902 - INFO - Best validation loss: 0.053519\n",
      "2025-08-19 21:18:20,903 - INFO - Restored model to best validation loss: 0.053519\n",
      "2025-08-19 21:18:20,903 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:18:21,123 - INFO - Comprehensive metrics saved for pytorch_mlp_33 (ID: 33)\n",
      "2025-08-19 21:18:21,332 - INFO - Comprehensive metrics saved for pytorch_mlp_33_train (ID: 33_train)\n",
      "2025-08-19 21:18:21,927 - INFO - PyTorch experiment 33/72 completed. CV val: 0.9872±0.0023, Test F1: 0.9721\n",
      "PyTorch experiments:  46%|████▌     | 33/72 [54:19<1:15:11, 115.69s/it]2025-08-19 21:18:21,935 - INFO - \n",
      "PyTorch experiment 34/72: {'hidden_sizes': [32], 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 64, 'epochs': 150}\n",
      "2025-08-19 21:19:30,359 - INFO - Early stopping triggered at epoch 38/150 (patience=10)\n",
      "2025-08-19 21:19:30,360 - INFO - Best validation loss: 0.032462\n",
      "2025-08-19 21:19:30,361 - INFO - Restored model to best validation loss: 0.032462\n",
      "2025-08-19 21:19:30,361 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:19:30,573 - INFO - Comprehensive metrics saved for pytorch_mlp_34 (ID: 34)\n",
      "2025-08-19 21:19:30,785 - INFO - Comprehensive metrics saved for pytorch_mlp_34_train (ID: 34_train)\n",
      "2025-08-19 21:19:31,398 - INFO - PyTorch experiment 34/72 completed. CV val: 0.9849±0.0034, Test F1: 0.9882\n",
      "PyTorch experiments:  47%|████▋     | 34/72 [55:29<1:04:29, 101.82s/it]2025-08-19 21:19:31,405 - INFO - \n",
      "PyTorch experiment 35/72: {'hidden_sizes': [32], 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'epochs': 100}\n",
      "2025-08-19 21:20:10,677 - INFO - Early stopping triggered at epoch 34/100 (patience=10)\n",
      "2025-08-19 21:20:10,678 - INFO - Best validation loss: 0.031373\n",
      "2025-08-19 21:20:10,679 - INFO - Restored model to best validation loss: 0.031373\n",
      "2025-08-19 21:20:10,679 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:20:10,894 - INFO - Comprehensive metrics saved for pytorch_mlp_35 (ID: 35)\n",
      "2025-08-19 21:20:11,108 - INFO - Comprehensive metrics saved for pytorch_mlp_35_train (ID: 35_train)\n",
      "2025-08-19 21:20:11,723 - INFO - PyTorch experiment 35/72 completed. CV val: 0.9843±0.0037, Test F1: 0.9874\n",
      "PyTorch experiments:  49%|████▊     | 35/72 [56:09<51:24, 83.37s/it]   2025-08-19 21:20:11,730 - INFO - \n",
      "PyTorch experiment 36/72: {'hidden_sizes': [32], 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'epochs': 150}\n",
      "2025-08-19 21:20:49,915 - INFO - Early stopping triggered at epoch 32/150 (patience=10)\n",
      "2025-08-19 21:20:49,916 - INFO - Best validation loss: 0.034075\n",
      "2025-08-19 21:20:49,917 - INFO - Restored model to best validation loss: 0.034075\n",
      "2025-08-19 21:20:49,918 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:20:50,141 - INFO - Comprehensive metrics saved for pytorch_mlp_36 (ID: 36)\n",
      "2025-08-19 21:20:50,368 - INFO - Comprehensive metrics saved for pytorch_mlp_36_train (ID: 36_train)\n",
      "2025-08-19 21:20:51,014 - INFO - PyTorch experiment 36/72 completed. CV val: 0.9866±0.0015, Test F1: 0.9859\n",
      "PyTorch experiments:  50%|█████     | 36/72 [56:49<42:05, 70.15s/it]2025-08-19 21:20:51,021 - INFO - \n",
      "PyTorch experiment 37/72: {'hidden_sizes': [32], 'learning_rate': 0.01, 'dropout': 0.5, 'batch_size': 64, 'epochs': 100}\n",
      "2025-08-19 21:22:31,540 - INFO - Early stopping triggered at epoch 67/100 (patience=10)\n",
      "2025-08-19 21:22:31,541 - INFO - Best validation loss: 0.022842\n",
      "2025-08-19 21:22:31,542 - INFO - Restored model to best validation loss: 0.022842\n",
      "2025-08-19 21:22:31,543 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:22:31,751 - INFO - Comprehensive metrics saved for pytorch_mlp_37 (ID: 37)\n",
      "2025-08-19 21:22:32,460 - INFO - Comprehensive metrics saved for pytorch_mlp_37_train (ID: 37_train)\n",
      "2025-08-19 21:22:33,088 - INFO - PyTorch experiment 37/72 completed. CV val: 0.9836±0.0046, Test F1: 0.9906\n",
      "PyTorch experiments:  51%|█████▏    | 37/72 [58:31<46:30, 79.73s/it]2025-08-19 21:22:33,096 - INFO - \n",
      "PyTorch experiment 38/72: {'hidden_sizes': [32], 'learning_rate': 0.01, 'dropout': 0.5, 'batch_size': 64, 'epochs': 150}\n",
      "2025-08-19 21:24:07,890 - INFO - Early stopping triggered at epoch 40/150 (patience=10)\n",
      "2025-08-19 21:24:07,891 - INFO - Best validation loss: 0.033589\n",
      "2025-08-19 21:24:07,892 - INFO - Restored model to best validation loss: 0.033589\n",
      "2025-08-19 21:24:07,893 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:24:08,259 - INFO - Comprehensive metrics saved for pytorch_mlp_38 (ID: 38)\n",
      "2025-08-19 21:24:08,589 - INFO - Comprehensive metrics saved for pytorch_mlp_38_train (ID: 38_train)\n",
      "2025-08-19 21:24:09,553 - INFO - PyTorch experiment 38/72 completed. CV val: 0.9830±0.0043, Test F1: 0.9882\n",
      "PyTorch experiments:  53%|█████▎    | 38/72 [1:00:07<48:01, 84.75s/it]2025-08-19 21:24:09,563 - INFO - \n",
      "PyTorch experiment 39/72: {'hidden_sizes': [32], 'learning_rate': 0.01, 'dropout': 0.5, 'batch_size': 128, 'epochs': 100}\n",
      "2025-08-19 21:25:36,147 - INFO - Early stopping triggered at epoch 39/100 (patience=10)\n",
      "2025-08-19 21:25:36,149 - INFO - Best validation loss: 0.031022\n",
      "2025-08-19 21:25:36,151 - INFO - Restored model to best validation loss: 0.031022\n",
      "2025-08-19 21:25:36,151 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:25:36,489 - INFO - Comprehensive metrics saved for pytorch_mlp_39 (ID: 39)\n",
      "2025-08-19 21:25:36,833 - INFO - Comprehensive metrics saved for pytorch_mlp_39_train (ID: 39_train)\n",
      "2025-08-19 21:25:37,836 - INFO - PyTorch experiment 39/72 completed. CV val: 0.9838±0.0038, Test F1: 0.9860\n",
      "PyTorch experiments:  54%|█████▍    | 39/72 [1:01:35<47:11, 85.81s/it]2025-08-19 21:25:37,846 - INFO - \n",
      "PyTorch experiment 40/72: {'hidden_sizes': [32], 'learning_rate': 0.01, 'dropout': 0.5, 'batch_size': 128, 'epochs': 150}\n",
      "2025-08-19 21:27:18,840 - INFO - Early stopping triggered at epoch 54/150 (patience=10)\n",
      "2025-08-19 21:27:18,841 - INFO - Best validation loss: 0.024285\n",
      "2025-08-19 21:27:18,841 - INFO - Restored model to best validation loss: 0.024285\n",
      "2025-08-19 21:27:18,842 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:27:19,051 - INFO - Comprehensive metrics saved for pytorch_mlp_40 (ID: 40)\n",
      "2025-08-19 21:27:19,276 - INFO - Comprehensive metrics saved for pytorch_mlp_40_train (ID: 40_train)\n",
      "2025-08-19 21:27:19,920 - INFO - PyTorch experiment 40/72 completed. CV val: 0.9841±0.0035, Test F1: 0.9901\n",
      "PyTorch experiments:  56%|█████▌    | 40/72 [1:03:17<48:22, 90.69s/it]2025-08-19 21:27:19,927 - INFO - \n",
      "PyTorch experiment 41/72: {'hidden_sizes': [32], 'learning_rate': 0.1, 'dropout': 0.2, 'batch_size': 64, 'epochs': 100}\n",
      "2025-08-19 21:27:51,260 - INFO - Early stopping triggered at epoch 12/100 (patience=10)\n",
      "2025-08-19 21:27:51,261 - INFO - Best validation loss: 0.163566\n",
      "2025-08-19 21:27:51,263 - INFO - Restored model to best validation loss: 0.163566\n",
      "2025-08-19 21:27:51,263 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:27:51,605 - INFO - Comprehensive metrics saved for pytorch_mlp_41 (ID: 41)\n",
      "2025-08-19 21:27:51,986 - INFO - Comprehensive metrics saved for pytorch_mlp_41_train (ID: 41_train)\n",
      "2025-08-19 21:27:53,001 - INFO - PyTorch experiment 41/72 completed. CV val: 0.9578±0.0049, Test F1: 0.9511\n",
      "PyTorch experiments:  57%|█████▋    | 41/72 [1:03:51<37:55, 73.41s/it]2025-08-19 21:27:53,011 - INFO - \n",
      "PyTorch experiment 42/72: {'hidden_sizes': [32], 'learning_rate': 0.1, 'dropout': 0.2, 'batch_size': 64, 'epochs': 150}\n",
      "2025-08-19 21:28:52,670 - INFO - Early stopping triggered at epoch 15/150 (patience=10)\n",
      "2025-08-19 21:28:52,671 - INFO - Best validation loss: 0.117642\n",
      "2025-08-19 21:28:52,672 - INFO - Restored model to best validation loss: 0.117642\n",
      "2025-08-19 21:28:52,673 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:28:53,007 - INFO - Comprehensive metrics saved for pytorch_mlp_42 (ID: 42)\n",
      "2025-08-19 21:28:53,346 - INFO - Comprehensive metrics saved for pytorch_mlp_42_train (ID: 42_train)\n",
      "2025-08-19 21:28:54,275 - INFO - PyTorch experiment 42/72 completed. CV val: 0.9566±0.0021, Test F1: 0.9551\n",
      "PyTorch experiments:  58%|█████▊    | 42/72 [1:04:52<34:53, 69.77s/it]2025-08-19 21:28:54,284 - INFO - \n",
      "PyTorch experiment 43/72: {'hidden_sizes': [32], 'learning_rate': 0.1, 'dropout': 0.2, 'batch_size': 128, 'epochs': 100}\n",
      "2025-08-19 21:29:55,934 - INFO - Early stopping triggered at epoch 34/100 (patience=10)\n",
      "2025-08-19 21:29:55,935 - INFO - Best validation loss: 0.086326\n",
      "2025-08-19 21:29:55,936 - INFO - Restored model to best validation loss: 0.086326\n",
      "2025-08-19 21:29:55,937 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:29:56,278 - INFO - Comprehensive metrics saved for pytorch_mlp_43 (ID: 43)\n",
      "2025-08-19 21:29:56,621 - INFO - Comprehensive metrics saved for pytorch_mlp_43_train (ID: 43_train)\n",
      "2025-08-19 21:29:57,588 - INFO - PyTorch experiment 43/72 completed. CV val: 0.9672±0.0044, Test F1: 0.9705\n",
      "PyTorch experiments:  60%|█████▉    | 43/72 [1:05:55<32:47, 67.83s/it]2025-08-19 21:29:57,597 - INFO - \n",
      "PyTorch experiment 44/72: {'hidden_sizes': [32], 'learning_rate': 0.1, 'dropout': 0.2, 'batch_size': 128, 'epochs': 150}\n",
      "2025-08-19 21:30:52,594 - INFO - Early stopping triggered at epoch 25/150 (patience=10)\n",
      "2025-08-19 21:30:52,596 - INFO - Best validation loss: 0.087635\n",
      "2025-08-19 21:30:52,597 - INFO - Restored model to best validation loss: 0.087635\n",
      "2025-08-19 21:30:52,598 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:30:52,931 - INFO - Comprehensive metrics saved for pytorch_mlp_44 (ID: 44)\n",
      "2025-08-19 21:30:53,271 - INFO - Comprehensive metrics saved for pytorch_mlp_44_train (ID: 44_train)\n",
      "2025-08-19 21:30:54,233 - INFO - PyTorch experiment 44/72 completed. CV val: 0.9688±0.0065, Test F1: 0.9769\n",
      "PyTorch experiments:  61%|██████    | 44/72 [1:06:52<30:05, 64.48s/it]2025-08-19 21:30:54,242 - INFO - \n",
      "PyTorch experiment 45/72: {'hidden_sizes': [32], 'learning_rate': 0.1, 'dropout': 0.5, 'batch_size': 64, 'epochs': 100}\n",
      "2025-08-19 21:32:03,071 - INFO - Early stopping triggered at epoch 31/100 (patience=10)\n",
      "2025-08-19 21:32:03,072 - INFO - Best validation loss: 0.214423\n",
      "2025-08-19 21:32:03,073 - INFO - Restored model to best validation loss: 0.214423\n",
      "2025-08-19 21:32:03,074 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:32:03,393 - INFO - Comprehensive metrics saved for pytorch_mlp_45 (ID: 45)\n",
      "2025-08-19 21:32:03,721 - INFO - Comprehensive metrics saved for pytorch_mlp_45_train (ID: 45_train)\n",
      "2025-08-19 21:32:04,666 - INFO - PyTorch experiment 45/72 completed. CV val: 0.9304±0.0066, Test F1: 0.9531\n",
      "PyTorch experiments:  62%|██████▎   | 45/72 [1:08:02<29:49, 66.26s/it]2025-08-19 21:32:04,676 - INFO - \n",
      "PyTorch experiment 46/72: {'hidden_sizes': [32], 'learning_rate': 0.1, 'dropout': 0.5, 'batch_size': 64, 'epochs': 150}\n",
      "2025-08-19 21:32:55,259 - INFO - Early stopping triggered at epoch 14/150 (patience=10)\n",
      "2025-08-19 21:32:55,260 - INFO - Best validation loss: 0.247456\n",
      "2025-08-19 21:32:55,262 - INFO - Restored model to best validation loss: 0.247456\n",
      "2025-08-19 21:32:55,262 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:32:55,556 - INFO - Comprehensive metrics saved for pytorch_mlp_46 (ID: 46)\n",
      "2025-08-19 21:32:55,855 - INFO - Comprehensive metrics saved for pytorch_mlp_46_train (ID: 46_train)\n",
      "2025-08-19 21:32:56,747 - INFO - PyTorch experiment 46/72 completed. CV val: 0.9328±0.0153, Test F1: 0.9153\n",
      "PyTorch experiments:  64%|██████▍   | 46/72 [1:08:54<26:52, 62.01s/it]2025-08-19 21:32:56,757 - INFO - \n",
      "PyTorch experiment 47/72: {'hidden_sizes': [32], 'learning_rate': 0.1, 'dropout': 0.5, 'batch_size': 128, 'epochs': 100}\n",
      "2025-08-19 21:33:34,604 - INFO - Early stopping triggered at epoch 16/100 (patience=10)\n",
      "2025-08-19 21:33:34,605 - INFO - Best validation loss: 0.138912\n",
      "2025-08-19 21:33:34,606 - INFO - Restored model to best validation loss: 0.138912\n",
      "2025-08-19 21:33:34,607 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:33:34,923 - INFO - Comprehensive metrics saved for pytorch_mlp_47 (ID: 47)\n",
      "2025-08-19 21:33:35,246 - INFO - Comprehensive metrics saved for pytorch_mlp_47_train (ID: 47_train)\n",
      "2025-08-19 21:33:36,203 - INFO - PyTorch experiment 47/72 completed. CV val: 0.9529±0.0058, Test F1: 0.9552\n",
      "PyTorch experiments:  65%|██████▌   | 47/72 [1:09:34<23:01, 55.24s/it]2025-08-19 21:33:36,212 - INFO - \n",
      "PyTorch experiment 48/72: {'hidden_sizes': [32], 'learning_rate': 0.1, 'dropout': 0.5, 'batch_size': 128, 'epochs': 150}\n",
      "2025-08-19 21:34:13,790 - INFO - Early stopping triggered at epoch 15/150 (patience=10)\n",
      "2025-08-19 21:34:13,791 - INFO - Best validation loss: 0.154758\n",
      "2025-08-19 21:34:13,793 - INFO - Restored model to best validation loss: 0.154758\n",
      "2025-08-19 21:34:13,794 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:34:14,126 - INFO - Comprehensive metrics saved for pytorch_mlp_48 (ID: 48)\n",
      "2025-08-19 21:34:14,454 - INFO - Comprehensive metrics saved for pytorch_mlp_48_train (ID: 48_train)\n",
      "2025-08-19 21:34:15,362 - INFO - PyTorch experiment 48/72 completed. CV val: 0.9513±0.0044, Test F1: 0.9469\n",
      "PyTorch experiments:  67%|██████▋   | 48/72 [1:10:13<20:10, 50.42s/it]2025-08-19 21:34:15,371 - INFO - \n",
      "PyTorch experiment 49/72: {'hidden_sizes': [64], 'learning_rate': 0.001, 'dropout': 0.2, 'batch_size': 64, 'epochs': 100}\n",
      "2025-08-19 21:37:10,047 - INFO - Early stopping triggered at epoch 58/100 (patience=10)\n",
      "2025-08-19 21:37:10,048 - INFO - Best validation loss: 0.016537\n",
      "2025-08-19 21:37:10,049 - INFO - Restored model to best validation loss: 0.016537\n",
      "2025-08-19 21:37:10,049 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:37:10,289 - INFO - Comprehensive metrics saved for pytorch_mlp_49 (ID: 49)\n",
      "2025-08-19 21:37:10,501 - INFO - Comprehensive metrics saved for pytorch_mlp_49_train (ID: 49_train)\n",
      "2025-08-19 21:37:11,097 - INFO - PyTorch experiment 49/72 completed. CV val: 0.9927±0.0018, Test F1: 0.9929\n",
      "PyTorch experiments:  68%|██████▊   | 49/72 [1:13:09<33:44, 88.01s/it]2025-08-19 21:37:11,105 - INFO - \n",
      "PyTorch experiment 50/72: {'hidden_sizes': [64], 'learning_rate': 0.001, 'dropout': 0.2, 'batch_size': 64, 'epochs': 150}\n",
      "2025-08-19 21:39:49,912 - INFO - Early stopping triggered at epoch 87/150 (patience=10)\n",
      "2025-08-19 21:39:49,913 - INFO - Best validation loss: 0.015976\n",
      "2025-08-19 21:39:49,914 - INFO - Restored model to best validation loss: 0.015976\n",
      "2025-08-19 21:39:49,915 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:39:50,173 - INFO - Comprehensive metrics saved for pytorch_mlp_50 (ID: 50)\n",
      "2025-08-19 21:39:50,439 - INFO - Comprehensive metrics saved for pytorch_mlp_50_train (ID: 50_train)\n",
      "2025-08-19 21:39:51,169 - INFO - PyTorch experiment 50/72 completed. CV val: 0.9938±0.0018, Test F1: 0.9911\n",
      "PyTorch experiments:  69%|██████▉   | 50/72 [1:15:49<40:11, 109.63s/it]2025-08-19 21:39:51,177 - INFO - \n",
      "PyTorch experiment 51/72: {'hidden_sizes': [64], 'learning_rate': 0.001, 'dropout': 0.2, 'batch_size': 128, 'epochs': 100}\n",
      "2025-08-19 21:41:39,378 - INFO - Early stopping triggered at epoch 78/100 (patience=10)\n",
      "2025-08-19 21:41:39,378 - INFO - Best validation loss: 0.018454\n",
      "2025-08-19 21:41:39,379 - INFO - Restored model to best validation loss: 0.018454\n",
      "2025-08-19 21:41:39,380 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:41:39,605 - INFO - Comprehensive metrics saved for pytorch_mlp_51 (ID: 51)\n",
      "2025-08-19 21:41:39,832 - INFO - Comprehensive metrics saved for pytorch_mlp_51_train (ID: 51_train)\n",
      "2025-08-19 21:41:40,456 - INFO - PyTorch experiment 51/72 completed. CV val: 0.9930±0.0008, Test F1: 0.9934\n",
      "PyTorch experiments:  71%|███████   | 51/72 [1:17:38<38:20, 109.53s/it]2025-08-19 21:41:40,463 - INFO - \n",
      "PyTorch experiment 52/72: {'hidden_sizes': [64], 'learning_rate': 0.001, 'dropout': 0.2, 'batch_size': 128, 'epochs': 150}\n",
      "2025-08-19 21:43:44,151 - INFO - Early stopping triggered at epoch 88/150 (patience=10)\n",
      "2025-08-19 21:43:44,152 - INFO - Best validation loss: 0.018678\n",
      "2025-08-19 21:43:44,153 - INFO - Restored model to best validation loss: 0.018678\n",
      "2025-08-19 21:43:44,153 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:43:45,031 - INFO - Comprehensive metrics saved for pytorch_mlp_52 (ID: 52)\n",
      "2025-08-19 21:43:45,255 - INFO - Comprehensive metrics saved for pytorch_mlp_52_train (ID: 52_train)\n",
      "2025-08-19 21:43:45,936 - INFO - PyTorch experiment 52/72 completed. CV val: 0.9928±0.0018, Test F1: 0.9938\n",
      "PyTorch experiments:  72%|███████▏  | 52/72 [1:19:43<38:06, 114.31s/it]2025-08-19 21:43:45,943 - INFO - \n",
      "PyTorch experiment 53/72: {'hidden_sizes': [64], 'learning_rate': 0.001, 'dropout': 0.5, 'batch_size': 64, 'epochs': 100}\n",
      "2025-08-19 21:46:20,812 - INFO - Early stopping triggered at epoch 58/100 (patience=10)\n",
      "2025-08-19 21:46:20,813 - INFO - Best validation loss: 0.018904\n",
      "2025-08-19 21:46:20,814 - INFO - Restored model to best validation loss: 0.018904\n",
      "2025-08-19 21:46:20,815 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:46:21,078 - INFO - Comprehensive metrics saved for pytorch_mlp_53 (ID: 53)\n",
      "2025-08-19 21:46:21,336 - INFO - Comprehensive metrics saved for pytorch_mlp_53_train (ID: 53_train)\n",
      "2025-08-19 21:46:21,989 - INFO - PyTorch experiment 53/72 completed. CV val: 0.9915±0.0017, Test F1: 0.9930\n",
      "PyTorch experiments:  74%|███████▎  | 53/72 [1:22:19<40:09, 126.84s/it]2025-08-19 21:46:21,997 - INFO - \n",
      "PyTorch experiment 54/72: {'hidden_sizes': [64], 'learning_rate': 0.001, 'dropout': 0.5, 'batch_size': 64, 'epochs': 150}\n",
      "2025-08-19 21:49:09,160 - INFO - Early stopping triggered at epoch 83/150 (patience=10)\n",
      "2025-08-19 21:49:09,160 - INFO - Best validation loss: 0.014726\n",
      "2025-08-19 21:49:09,161 - INFO - Restored model to best validation loss: 0.014726\n",
      "2025-08-19 21:49:09,161 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:49:09,377 - INFO - Comprehensive metrics saved for pytorch_mlp_54 (ID: 54)\n",
      "2025-08-19 21:49:09,596 - INFO - Comprehensive metrics saved for pytorch_mlp_54_train (ID: 54_train)\n",
      "2025-08-19 21:49:10,201 - INFO - PyTorch experiment 54/72 completed. CV val: 0.9922±0.0012, Test F1: 0.9932\n",
      "PyTorch experiments:  75%|███████▌  | 54/72 [1:25:08<41:46, 139.25s/it]2025-08-19 21:49:10,209 - INFO - \n",
      "PyTorch experiment 55/72: {'hidden_sizes': [64], 'learning_rate': 0.001, 'dropout': 0.5, 'batch_size': 128, 'epochs': 100}\n",
      "2025-08-19 21:51:19,030 - INFO - Restored model to best validation loss: 0.014487\n",
      "2025-08-19 21:51:19,031 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:51:19,250 - INFO - Comprehensive metrics saved for pytorch_mlp_55 (ID: 55)\n",
      "2025-08-19 21:51:19,463 - INFO - Comprehensive metrics saved for pytorch_mlp_55_train (ID: 55_train)\n",
      "2025-08-19 21:51:20,062 - INFO - PyTorch experiment 55/72 completed. CV val: 0.9929±0.0022, Test F1: 0.9941\n",
      "PyTorch experiments:  76%|███████▋  | 55/72 [1:27:18<38:39, 136.43s/it]2025-08-19 21:51:20,070 - INFO - \n",
      "PyTorch experiment 56/72: {'hidden_sizes': [64], 'learning_rate': 0.001, 'dropout': 0.5, 'batch_size': 128, 'epochs': 150}\n",
      "2025-08-19 21:53:10,179 - INFO - Early stopping triggered at epoch 74/150 (patience=10)\n",
      "2025-08-19 21:53:10,180 - INFO - Best validation loss: 0.017795\n",
      "2025-08-19 21:53:10,181 - INFO - Restored model to best validation loss: 0.017795\n",
      "2025-08-19 21:53:10,181 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:53:10,396 - INFO - Comprehensive metrics saved for pytorch_mlp_56 (ID: 56)\n",
      "2025-08-19 21:53:10,612 - INFO - Comprehensive metrics saved for pytorch_mlp_56_train (ID: 56_train)\n",
      "2025-08-19 21:53:11,240 - INFO - PyTorch experiment 56/72 completed. CV val: 0.9924±0.0018, Test F1: 0.9941\n",
      "PyTorch experiments:  78%|███████▊  | 56/72 [1:29:09<34:21, 128.86s/it]2025-08-19 21:53:11,248 - INFO - \n",
      "PyTorch experiment 57/72: {'hidden_sizes': [64], 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 64, 'epochs': 100}\n",
      "2025-08-19 21:54:08,516 - INFO - Early stopping triggered at epoch 30/100 (patience=10)\n",
      "2025-08-19 21:54:08,517 - INFO - Best validation loss: 0.042663\n",
      "2025-08-19 21:54:08,518 - INFO - Restored model to best validation loss: 0.042663\n",
      "2025-08-19 21:54:08,518 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:54:08,742 - INFO - Comprehensive metrics saved for pytorch_mlp_57 (ID: 57)\n",
      "2025-08-19 21:54:08,971 - INFO - Comprehensive metrics saved for pytorch_mlp_57_train (ID: 57_train)\n",
      "2025-08-19 21:54:09,632 - INFO - PyTorch experiment 57/72 completed. CV val: 0.9803±0.0043, Test F1: 0.9826\n",
      "PyTorch experiments:  79%|███████▉  | 57/72 [1:30:07<26:55, 107.72s/it]2025-08-19 21:54:09,640 - INFO - \n",
      "PyTorch experiment 58/72: {'hidden_sizes': [64], 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 64, 'epochs': 150}\n",
      "2025-08-19 21:55:08,646 - INFO - Early stopping triggered at epoch 24/150 (patience=10)\n",
      "2025-08-19 21:55:08,647 - INFO - Best validation loss: 0.048509\n",
      "2025-08-19 21:55:08,648 - INFO - Restored model to best validation loss: 0.048509\n",
      "2025-08-19 21:55:08,649 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:55:08,908 - INFO - Comprehensive metrics saved for pytorch_mlp_58 (ID: 58)\n",
      "2025-08-19 21:55:09,150 - INFO - Comprehensive metrics saved for pytorch_mlp_58_train (ID: 58_train)\n",
      "2025-08-19 21:55:09,797 - INFO - PyTorch experiment 58/72 completed. CV val: 0.9825±0.0024, Test F1: 0.9815\n",
      "PyTorch experiments:  81%|████████  | 58/72 [1:31:07<21:48, 93.45s/it] 2025-08-19 21:55:09,805 - INFO - \n",
      "PyTorch experiment 59/72: {'hidden_sizes': [64], 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'epochs': 100}\n",
      "2025-08-19 21:55:42,893 - INFO - Early stopping triggered at epoch 20/100 (patience=10)\n",
      "2025-08-19 21:55:42,894 - INFO - Best validation loss: 0.042499\n",
      "2025-08-19 21:55:42,895 - INFO - Restored model to best validation loss: 0.042499\n",
      "2025-08-19 21:55:42,895 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:55:43,129 - INFO - Comprehensive metrics saved for pytorch_mlp_59 (ID: 59)\n",
      "2025-08-19 21:55:43,357 - INFO - Comprehensive metrics saved for pytorch_mlp_59_train (ID: 59_train)\n",
      "2025-08-19 21:55:43,999 - INFO - PyTorch experiment 59/72 completed. CV val: 0.9821±0.0026, Test F1: 0.9847\n",
      "PyTorch experiments:  82%|████████▏ | 59/72 [1:31:42<16:23, 75.68s/it]2025-08-19 21:55:44,006 - INFO - \n",
      "PyTorch experiment 60/72: {'hidden_sizes': [64], 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'epochs': 150}\n",
      "2025-08-19 21:56:29,154 - INFO - Early stopping triggered at epoch 24/150 (patience=10)\n",
      "2025-08-19 21:56:29,155 - INFO - Best validation loss: 0.042883\n",
      "2025-08-19 21:56:29,156 - INFO - Restored model to best validation loss: 0.042883\n",
      "2025-08-19 21:56:29,156 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:56:29,428 - INFO - Comprehensive metrics saved for pytorch_mlp_60 (ID: 60)\n",
      "2025-08-19 21:56:29,674 - INFO - Comprehensive metrics saved for pytorch_mlp_60_train (ID: 60_train)\n",
      "2025-08-19 21:56:30,310 - INFO - PyTorch experiment 60/72 completed. CV val: 0.9863±0.0023, Test F1: 0.9852\n",
      "PyTorch experiments:  83%|████████▎ | 60/72 [1:32:28<13:22, 66.87s/it]2025-08-19 21:56:30,318 - INFO - \n",
      "PyTorch experiment 61/72: {'hidden_sizes': [64], 'learning_rate': 0.01, 'dropout': 0.5, 'batch_size': 64, 'epochs': 100}\n",
      "2025-08-19 21:58:47,673 - INFO - Early stopping triggered at epoch 61/100 (patience=10)\n",
      "2025-08-19 21:58:47,674 - INFO - Best validation loss: 0.026989\n",
      "2025-08-19 21:58:47,676 - INFO - Restored model to best validation loss: 0.026989\n",
      "2025-08-19 21:58:47,676 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 21:58:47,990 - INFO - Comprehensive metrics saved for pytorch_mlp_61 (ID: 61)\n",
      "2025-08-19 21:58:48,335 - INFO - Comprehensive metrics saved for pytorch_mlp_61_train (ID: 61_train)\n",
      "2025-08-19 21:58:49,247 - INFO - PyTorch experiment 61/72 completed. CV val: 0.9803±0.0044, Test F1: 0.9886\n",
      "PyTorch experiments:  85%|████████▍ | 61/72 [1:34:47<16:13, 88.49s/it]2025-08-19 21:58:49,257 - INFO - \n",
      "PyTorch experiment 62/72: {'hidden_sizes': [64], 'learning_rate': 0.01, 'dropout': 0.5, 'batch_size': 64, 'epochs': 150}\n",
      "2025-08-19 22:00:37,532 - INFO - Early stopping triggered at epoch 41/150 (patience=10)\n",
      "2025-08-19 22:00:37,533 - INFO - Best validation loss: 0.037467\n",
      "2025-08-19 22:00:37,534 - INFO - Restored model to best validation loss: 0.037467\n",
      "2025-08-19 22:00:37,535 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 22:00:37,852 - INFO - Comprehensive metrics saved for pytorch_mlp_62 (ID: 62)\n",
      "2025-08-19 22:00:38,183 - INFO - Comprehensive metrics saved for pytorch_mlp_62_train (ID: 62_train)\n",
      "2025-08-19 22:00:39,162 - INFO - PyTorch experiment 62/72 completed. CV val: 0.9808±0.0031, Test F1: 0.9863\n",
      "PyTorch experiments:  86%|████████▌ | 62/72 [1:36:37<15:49, 94.92s/it]2025-08-19 22:00:39,172 - INFO - \n",
      "PyTorch experiment 63/72: {'hidden_sizes': [64], 'learning_rate': 0.01, 'dropout': 0.5, 'batch_size': 128, 'epochs': 100}\n",
      "2025-08-19 22:02:08,231 - INFO - Early stopping triggered at epoch 70/100 (patience=10)\n",
      "2025-08-19 22:02:08,233 - INFO - Best validation loss: 0.022841\n",
      "2025-08-19 22:02:08,234 - INFO - Restored model to best validation loss: 0.022841\n",
      "2025-08-19 22:02:08,234 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 22:02:08,564 - INFO - Comprehensive metrics saved for pytorch_mlp_63 (ID: 63)\n",
      "2025-08-19 22:02:08,883 - INFO - Comprehensive metrics saved for pytorch_mlp_63_train (ID: 63_train)\n",
      "2025-08-19 22:02:09,793 - INFO - PyTorch experiment 63/72 completed. CV val: 0.9819±0.0028, Test F1: 0.9904\n",
      "PyTorch experiments:  88%|████████▊ | 63/72 [1:38:07<14:02, 93.63s/it]2025-08-19 22:02:09,802 - INFO - \n",
      "PyTorch experiment 64/72: {'hidden_sizes': [64], 'learning_rate': 0.01, 'dropout': 0.5, 'batch_size': 128, 'epochs': 150}\n",
      "2025-08-19 22:03:38,347 - INFO - Early stopping triggered at epoch 39/150 (patience=10)\n",
      "2025-08-19 22:03:38,348 - INFO - Best validation loss: 0.032950\n",
      "2025-08-19 22:03:38,349 - INFO - Restored model to best validation loss: 0.032950\n",
      "2025-08-19 22:03:38,350 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 22:03:38,675 - INFO - Comprehensive metrics saved for pytorch_mlp_64 (ID: 64)\n",
      "2025-08-19 22:03:38,987 - INFO - Comprehensive metrics saved for pytorch_mlp_64_train (ID: 64_train)\n",
      "2025-08-19 22:03:39,901 - INFO - PyTorch experiment 64/72 completed. CV val: 0.9822±0.0046, Test F1: 0.9850\n",
      "PyTorch experiments:  89%|████████▉ | 64/72 [1:39:37<12:20, 92.57s/it]2025-08-19 22:03:39,911 - INFO - \n",
      "PyTorch experiment 65/72: {'hidden_sizes': [64], 'learning_rate': 0.1, 'dropout': 0.2, 'batch_size': 64, 'epochs': 100}\n",
      "2025-08-19 22:04:39,025 - INFO - Early stopping triggered at epoch 21/100 (patience=10)\n",
      "2025-08-19 22:04:39,027 - INFO - Best validation loss: 0.130863\n",
      "2025-08-19 22:04:39,028 - INFO - Restored model to best validation loss: 0.130863\n",
      "2025-08-19 22:04:39,029 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 22:04:39,363 - INFO - Comprehensive metrics saved for pytorch_mlp_65 (ID: 65)\n",
      "2025-08-19 22:04:39,681 - INFO - Comprehensive metrics saved for pytorch_mlp_65_train (ID: 65_train)\n",
      "2025-08-19 22:04:40,605 - INFO - PyTorch experiment 65/72 completed. CV val: 0.9554±0.0050, Test F1: 0.9603\n",
      "PyTorch experiments:  90%|█████████ | 65/72 [1:40:38<09:41, 83.01s/it]2025-08-19 22:04:40,615 - INFO - \n",
      "PyTorch experiment 66/72: {'hidden_sizes': [64], 'learning_rate': 0.1, 'dropout': 0.2, 'batch_size': 64, 'epochs': 150}\n",
      "2025-08-19 22:05:56,777 - INFO - Early stopping triggered at epoch 24/150 (patience=10)\n",
      "2025-08-19 22:05:56,778 - INFO - Best validation loss: 0.157198\n",
      "2025-08-19 22:05:56,779 - INFO - Restored model to best validation loss: 0.157198\n",
      "2025-08-19 22:05:56,780 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 22:05:57,094 - INFO - Comprehensive metrics saved for pytorch_mlp_66 (ID: 66)\n",
      "2025-08-19 22:05:57,432 - INFO - Comprehensive metrics saved for pytorch_mlp_66_train (ID: 66_train)\n",
      "2025-08-19 22:05:58,305 - INFO - PyTorch experiment 66/72 completed. CV val: 0.9534±0.0077, Test F1: 0.9472\n",
      "PyTorch experiments:  92%|█████████▏| 66/72 [1:41:56<08:08, 81.42s/it]2025-08-19 22:05:58,316 - INFO - \n",
      "PyTorch experiment 67/72: {'hidden_sizes': [64], 'learning_rate': 0.1, 'dropout': 0.2, 'batch_size': 128, 'epochs': 100}\n",
      "2025-08-19 22:06:54,416 - INFO - Early stopping triggered at epoch 21/100 (patience=10)\n",
      "2025-08-19 22:06:54,417 - INFO - Best validation loss: 0.104454\n",
      "2025-08-19 22:06:54,419 - INFO - Restored model to best validation loss: 0.104454\n",
      "2025-08-19 22:06:54,419 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 22:06:54,741 - INFO - Comprehensive metrics saved for pytorch_mlp_67 (ID: 67)\n",
      "2025-08-19 22:06:55,056 - INFO - Comprehensive metrics saved for pytorch_mlp_67_train (ID: 67_train)\n",
      "2025-08-19 22:06:56,036 - INFO - PyTorch experiment 67/72 completed. CV val: 0.9681±0.0060, Test F1: 0.9698\n",
      "PyTorch experiments:  93%|█████████▎| 67/72 [1:42:54<06:11, 74.31s/it]2025-08-19 22:06:56,045 - INFO - \n",
      "PyTorch experiment 68/72: {'hidden_sizes': [64], 'learning_rate': 0.1, 'dropout': 0.2, 'batch_size': 128, 'epochs': 150}\n",
      "2025-08-19 22:07:51,434 - INFO - Early stopping triggered at epoch 33/150 (patience=10)\n",
      "2025-08-19 22:07:51,435 - INFO - Best validation loss: 0.106444\n",
      "2025-08-19 22:07:51,437 - INFO - Restored model to best validation loss: 0.106444\n",
      "2025-08-19 22:07:51,438 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 22:07:51,752 - INFO - Comprehensive metrics saved for pytorch_mlp_68 (ID: 68)\n",
      "2025-08-19 22:07:52,088 - INFO - Comprehensive metrics saved for pytorch_mlp_68_train (ID: 68_train)\n",
      "2025-08-19 22:07:53,032 - INFO - PyTorch experiment 68/72 completed. CV val: 0.9650±0.0064, Test F1: 0.9773\n",
      "PyTorch experiments:  94%|█████████▍| 68/72 [1:43:51<04:36, 69.12s/it]2025-08-19 22:07:53,042 - INFO - \n",
      "PyTorch experiment 69/72: {'hidden_sizes': [64], 'learning_rate': 0.1, 'dropout': 0.5, 'batch_size': 64, 'epochs': 100}\n",
      "2025-08-19 22:08:44,771 - INFO - Early stopping triggered at epoch 15/100 (patience=10)\n",
      "2025-08-19 22:08:44,773 - INFO - Best validation loss: 0.193836\n",
      "2025-08-19 22:08:44,774 - INFO - Restored model to best validation loss: 0.193836\n",
      "2025-08-19 22:08:44,775 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 22:08:45,086 - INFO - Comprehensive metrics saved for pytorch_mlp_69 (ID: 69)\n",
      "2025-08-19 22:08:45,409 - INFO - Comprehensive metrics saved for pytorch_mlp_69_train (ID: 69_train)\n",
      "2025-08-19 22:08:46,282 - INFO - PyTorch experiment 69/72 completed. CV val: 0.9212±0.0058, Test F1: 0.9366\n",
      "PyTorch experiments:  96%|█████████▌| 69/72 [1:44:44<03:13, 64.36s/it]2025-08-19 22:08:46,292 - INFO - \n",
      "PyTorch experiment 70/72: {'hidden_sizes': [64], 'learning_rate': 0.1, 'dropout': 0.5, 'batch_size': 64, 'epochs': 150}\n",
      "2025-08-19 22:09:26,104 - INFO - Early stopping triggered at epoch 13/150 (patience=10)\n",
      "2025-08-19 22:09:26,105 - INFO - Best validation loss: 0.261147\n",
      "2025-08-19 22:09:26,106 - INFO - Restored model to best validation loss: 0.261147\n",
      "2025-08-19 22:09:26,106 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 22:09:26,338 - INFO - Comprehensive metrics saved for pytorch_mlp_70 (ID: 70)\n",
      "2025-08-19 22:09:27,451 - INFO - Comprehensive metrics saved for pytorch_mlp_70_train (ID: 70_train)\n",
      "2025-08-19 22:09:28,106 - INFO - PyTorch experiment 70/72 completed. CV val: 0.9331±0.0055, Test F1: 0.9199\n",
      "PyTorch experiments:  97%|█████████▋| 70/72 [1:45:26<01:55, 57.60s/it]2025-08-19 22:09:28,113 - INFO - \n",
      "PyTorch experiment 71/72: {'hidden_sizes': [64], 'learning_rate': 0.1, 'dropout': 0.5, 'batch_size': 128, 'epochs': 100}\n",
      "2025-08-19 22:09:55,656 - INFO - Early stopping triggered at epoch 18/100 (patience=10)\n",
      "2025-08-19 22:09:55,657 - INFO - Best validation loss: 0.171916\n",
      "2025-08-19 22:09:55,658 - INFO - Restored model to best validation loss: 0.171916\n",
      "2025-08-19 22:09:55,658 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 22:09:55,896 - INFO - Comprehensive metrics saved for pytorch_mlp_71 (ID: 71)\n",
      "2025-08-19 22:09:56,149 - INFO - Comprehensive metrics saved for pytorch_mlp_71_train (ID: 71_train)\n",
      "2025-08-19 22:09:56,882 - INFO - PyTorch experiment 71/72 completed. CV val: 0.9537±0.0094, Test F1: 0.9469\n",
      "PyTorch experiments:  99%|█████████▊| 71/72 [1:45:54<00:48, 48.95s/it]2025-08-19 22:09:56,891 - INFO - \n",
      "PyTorch experiment 72/72: {'hidden_sizes': [64], 'learning_rate': 0.1, 'dropout': 0.5, 'batch_size': 128, 'epochs': 150}\n",
      "2025-08-19 22:10:23,296 - INFO - Early stopping triggered at epoch 17/150 (patience=10)\n",
      "2025-08-19 22:10:23,297 - INFO - Best validation loss: 0.129948\n",
      "2025-08-19 22:10:23,298 - INFO - Restored model to best validation loss: 0.129948\n",
      "2025-08-19 22:10:23,299 - INFO - Model weights restored to best validation loss checkpoint\n",
      "2025-08-19 22:10:23,529 - INFO - Comprehensive metrics saved for pytorch_mlp_72 (ID: 72)\n",
      "2025-08-19 22:10:23,757 - INFO - Comprehensive metrics saved for pytorch_mlp_72_train (ID: 72_train)\n",
      "2025-08-19 22:10:24,473 - INFO - PyTorch experiment 72/72 completed. CV val: 0.9502±0.0094, Test F1: 0.9492\n",
      "PyTorch experiments: 100%|██████████| 72/72 [1:46:22<00:00, 88.65s/it]\n",
      "2025-08-19 22:10:24,481 - INFO - Completed 72 successful PyTorch experiments\n",
      "2025-08-19 22:10:24,714 - INFO - Comprehensive metrics saved for BEST_pytorch_model (ID: BEST)\n",
      "2025-08-19 22:10:24,717 - INFO - Best PyTorch model saved (Experiment 50) with score: 0.9938\n",
      "2025-08-19 22:10:24,731 - INFO - PyTorch results saved to pytorch_results_summary.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best PyTorch result (by CV score):\n",
      "CV val accuracy: 0.9938±0.0018\n",
      "Test accuracy: 0.9922\n",
      "Test F1-macro: 0.9911\n",
      "Test Precision-macro: 0.9929\n",
      "Test Recall-macro: 0.9895\n",
      "Parameters: hidden_sizes=[64], lr=0.001, dropout=0.2\n"
     ]
    }
   ],
   "source": [
    "# Enhanced PyTorch experiments with Cross-Validation and Comprehensive Metrics\n",
    "if use_pytorch:\n",
    "    pytorch_results = []\n",
    "    combos = list(product(*pytorch_param_grid.values()))\n",
    "    keys = list(pytorch_param_grid.keys())\n",
    "    \n",
    "    logger.info(f\"Starting {len(combos)} PyTorch experiments\")\n",
    "    if use_cross_validation:\n",
    "        logger.info(f\"Using {n_folds}-fold cross-validation (this will increase training time by ~{n_folds}x)\")\n",
    "    \n",
    "    run_counter = 0\n",
    "    best_test_acc = 0.0\n",
    "    best_pytorch_model = None\n",
    "    \n",
    "    # Prepare full dataset for cross-validation\n",
    "    X_full_t = torch.FloatTensor(X_full)\n",
    "    y_full_t = torch.LongTensor(y_full)\n",
    "    \n",
    "    for combo in tqdm(combos, desc=\"PyTorch experiments\"):\n",
    "        run_counter += 1\n",
    "        \n",
    "        try:\n",
    "            params = dict(zip(keys, combo))\n",
    "            logger.info(f\"\\nPyTorch experiment {run_counter}/{len(combos)}: {params}\")\n",
    "            \n",
    "            # MLflow run start\n",
    "            if use_mlflow:\n",
    "                try:\n",
    "                    # End any existing run before starting a new one\n",
    "                    if mlflow.active_run():\n",
    "                        mlflow.end_run()\n",
    "                    mlflow.start_run()\n",
    "                    mlflow.log_params(params)\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"MLflow initialization failed: {str(e)}\")\n",
    "                    use_mlflow = False  # Disable MLflow for this experiment\n",
    "            \n",
    "            # Cross-validation scores storage\n",
    "            cv_train_accs = []\n",
    "            cv_val_accs = []\n",
    "            cv_final_losses = []\n",
    "            \n",
    "            if use_cross_validation:\n",
    "                # Cross-validation loop\n",
    "                for fold, (train_idx, val_idx) in enumerate(cv_splits):\n",
    "                    logger.debug(f\"Training fold {fold + 1}/{n_folds}\")\n",
    "                    \n",
    "                    # Split data for this fold\n",
    "                    X_fold_train = X_full_t[train_idx]\n",
    "                    y_fold_train = y_full_t[train_idx]\n",
    "                    X_fold_val = X_full_t[val_idx]\n",
    "                    y_fold_val = y_full_t[val_idx]\n",
    "                    \n",
    "                    # Model setup for this fold\n",
    "                    input_size = X_full.shape[1]\n",
    "                    n_classes = len(np.unique(y_full))\n",
    "                    model = build_pytorch_model(\n",
    "                        input_size, \n",
    "                        params['hidden_sizes'], \n",
    "                        dropout=params['dropout'], \n",
    "                        n_classes=n_classes\n",
    "                    ).to(device)\n",
    "                    \n",
    "                    criterion = nn.CrossEntropyLoss()\n",
    "                    optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "                    \n",
    "                    # Data loader for this fold\n",
    "                    fold_train_ds = TensorDataset(X_fold_train, y_fold_train)\n",
    "                    fold_train_loader = DataLoader(fold_train_ds, batch_size=params['batch_size'], shuffle=True)\n",
    "                    \n",
    "                    # Training loop for this fold with early stopping\n",
    "                    fold_early_stopping = EarlyStopping(\n",
    "                        patience=EARLY_STOPPING_PATIENCE//2,  # Reduced patience for CV folds\n",
    "                        min_delta=EARLY_STOPPING_MIN_DELTA,\n",
    "                        verbose=False  # Less verbose for CV folds\n",
    "                    )\n",
    "                    \n",
    "                    for epoch in range(params['epochs']):\n",
    "                        model.train()\n",
    "                        epoch_losses = []\n",
    "                        \n",
    "                        for batch_idx, (xb, yb) in enumerate(fold_train_loader):\n",
    "                            xb = xb.to(device)\n",
    "                            yb = yb.to(device)\n",
    "                            \n",
    "                            optimizer.zero_grad()\n",
    "                            out = model(xb)\n",
    "                            loss = criterion(out, yb)\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            \n",
    "                            epoch_losses.append(loss.item())\n",
    "                        \n",
    "                        # Validation on fold validation set every epoch for early stopping\n",
    "                        model.eval()\n",
    "                        with torch.no_grad():\n",
    "                            fold_val_out = model(X_fold_val.to(device))\n",
    "                            fold_val_loss = criterion(fold_val_out, y_fold_val.to(device))\n",
    "                        \n",
    "                        # Early stopping check\n",
    "                        fold_early_stopping(fold_val_loss.item(), model)\n",
    "                        \n",
    "                        if fold_early_stopping.early_stop:\n",
    "                            logger.debug(f\"Fold {fold+1} early stopping at epoch {epoch+1}\")\n",
    "                            break\n",
    "                    \n",
    "                    # Restore best model for this fold\n",
    "                    if fold_early_stopping.restore_best_weights:\n",
    "                        fold_early_stopping.restore_best_model(model)\n",
    "                    \n",
    "                    # Evaluate this fold\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        # Training accuracy for this fold\n",
    "                        fold_train_out = model(X_fold_train.to(device))\n",
    "                        fold_train_pred = fold_train_out.argmax(dim=1).cpu().numpy()\n",
    "                        fold_train_acc = accuracy_score(y_fold_train.cpu().numpy(), fold_train_pred)\n",
    "                        \n",
    "                        # Validation accuracy for this fold\n",
    "                        fold_val_out = model(X_fold_val.to(device))\n",
    "                        fold_val_pred = fold_val_out.argmax(dim=1).cpu().numpy()\n",
    "                        fold_val_acc = accuracy_score(y_fold_val.cpu().numpy(), fold_val_pred)\n",
    "                        fold_val_loss = criterion(fold_val_out, y_fold_val.to(device)).item()\n",
    "                    \n",
    "                    cv_train_accs.append(fold_train_acc)\n",
    "                    cv_val_accs.append(fold_val_acc)\n",
    "                    cv_final_losses.append(fold_val_loss)\n",
    "                    \n",
    "                    logger.debug(f\"Fold {fold + 1}: train_acc={fold_train_acc:.4f}, val_acc={fold_val_acc:.4f}\")\n",
    "                \n",
    "                # Calculate cross-validation statistics\n",
    "                cv_train_mean = np.mean(cv_train_accs)\n",
    "                cv_train_std = np.std(cv_train_accs)\n",
    "                cv_val_mean = np.mean(cv_val_accs)\n",
    "                cv_val_std = np.std(cv_val_accs)\n",
    "                cv_loss_mean = np.mean(cv_final_losses)\n",
    "            \n",
    "            else:\n",
    "                # No cross-validation\n",
    "                cv_train_mean = cv_train_std = cv_val_mean = cv_val_std = cv_loss_mean = None\n",
    "            \n",
    "            # Train final model on original train/test split\n",
    "            model = build_pytorch_model(\n",
    "                X_train_s.shape[1], \n",
    "                params['hidden_sizes'], \n",
    "                dropout=params['dropout'], \n",
    "                n_classes=len(np.unique(y_train))\n",
    "            ).to(device)\n",
    "            \n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "            \n",
    "            train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "            train_loader = DataLoader(train_ds, batch_size=params['batch_size'], shuffle=True)\n",
    "            \n",
    "            # Setup logging for final model\n",
    "            log_dir = os.path.join(OUTDIR, f'tb_logs/run_{run_counter}')\n",
    "            writer = SummaryWriter(log_dir=log_dir)\n",
    "            \n",
    "            train_losses = []\n",
    "            val_losses = []\n",
    "            val_accuracies = []\n",
    "            start_time = datetime.now()\n",
    "            \n",
    "            # Training loop for final model with early stopping\n",
    "            early_stopping = EarlyStopping(\n",
    "                patience=EARLY_STOPPING_PATIENCE,\n",
    "                min_delta=EARLY_STOPPING_MIN_DELTA,\n",
    "                verbose=True\n",
    "            )\n",
    "            \n",
    "            for epoch in range(params['epochs']):\n",
    "                model.train()\n",
    "                epoch_losses = []\n",
    "                \n",
    "                for batch_idx, (xb, yb) in enumerate(train_loader):\n",
    "                    xb = xb.to(device)\n",
    "                    yb = yb.to(device)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    out = model(xb)\n",
    "                    loss = criterion(out, yb)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    epoch_losses.append(loss.item())\n",
    "                \n",
    "                avg_train_loss = np.mean(epoch_losses)\n",
    "                train_losses.append(avg_train_loss)\n",
    "                \n",
    "                # Validation every epoch for early stopping\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_out = model(X_test_t.to(device))\n",
    "                    val_loss = criterion(val_out, y_test_t.to(device))\n",
    "                    val_pred = val_out.argmax(dim=1).cpu().numpy()\n",
    "                    val_acc = accuracy_score(y_test, val_pred)\n",
    "                \n",
    "                val_losses.append(val_loss.item())\n",
    "                val_accuracies.append(val_acc)\n",
    "                \n",
    "                # Early stopping check\n",
    "                early_stopping(val_loss.item(), model)\n",
    "                \n",
    "                # Logging every 5 epochs or at early stop\n",
    "                if epoch % 5 == 0 or epoch == params['epochs'] - 1 or early_stopping.early_stop:\n",
    "                    # TensorBoard logging\n",
    "                    writer.add_scalar('Loss/train', avg_train_loss, epoch)\n",
    "                    writer.add_scalar('Loss/validation', val_loss.item(), epoch)\n",
    "                    writer.add_scalar('Accuracy/validation', val_acc, epoch)\n",
    "                    \n",
    "                    # MLflow logging\n",
    "                    if use_mlflow:\n",
    "                        mlflow.log_metric(\"train_loss\", avg_train_loss, step=epoch)\n",
    "                        mlflow.log_metric(\"val_loss\", val_loss.item(), step=epoch)\n",
    "                        mlflow.log_metric(\"val_accuracy\", val_acc, step=epoch)\n",
    "                    \n",
    "                    # System resource monitoring\n",
    "                    memory_usage = psutil.virtual_memory().percent\n",
    "                    if torch.cuda.is_available():\n",
    "                        gpu_memory = torch.cuda.memory_allocated() / 1024**3\n",
    "                        writer.add_scalar('System/gpu_memory_gb', gpu_memory, epoch)\n",
    "                    writer.add_scalar('System/memory_usage_percent', memory_usage, epoch)\n",
    "                \n",
    "                # Progress reporting\n",
    "                if (epoch + 1) % 20 == 0 or epoch == 0 or early_stopping.early_stop:\n",
    "                    logger.debug(f\"Epoch {epoch+1}/{params['epochs']}: train_loss={avg_train_loss:.4f}, val_loss={val_loss.item():.4f}\")\n",
    "                \n",
    "                # Early stopping break\n",
    "                if early_stopping.early_stop:\n",
    "                    logger.info(f\"Early stopping triggered at epoch {epoch+1}/{params['epochs']} (patience={EARLY_STOPPING_PATIENCE})\")\n",
    "                    logger.info(f\"Best validation loss: {early_stopping.val_loss_min:.6f}\")\n",
    "                    break\n",
    "            \n",
    "            # Restore best model if early stopping was used\n",
    "            if early_stopping.restore_best_weights:\n",
    "                early_stopping.restore_best_model(model)\n",
    "                logger.info(\"Model weights restored to best validation loss checkpoint\")\n",
    "            \n",
    "            # Final evaluation\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                out_train = model(X_train_t.to(device))\n",
    "                pred_train = out_train.argmax(dim=1).cpu().numpy()\n",
    "                out_test = model(X_test_t.to(device))\n",
    "                pred_test = out_test.argmax(dim=1).cpu().numpy()\n",
    "            \n",
    "            train_acc = accuracy_score(y_train, pred_train)\n",
    "            test_acc = accuracy_score(y_test, pred_test)\n",
    "            \n",
    "            end_time = datetime.now()\n",
    "            duration = (end_time - start_time).total_seconds()\n",
    "            \n",
    "            # Calculate comprehensive metrics\n",
    "            model_name = f\"pytorch_mlp_{run_counter}\"\n",
    "            test_metrics = calculate_comprehensive_metrics(\n",
    "                y_test, pred_test, model_name, run_counter, 'pytorch'\n",
    "            )\n",
    "            \n",
    "            train_metrics = calculate_comprehensive_metrics(\n",
    "                y_train, pred_train, f\"{model_name}_train\", f\"{run_counter}_train\", 'pytorch'\n",
    "            )\n",
    "            \n",
    "            # Save model\n",
    "            model_path = os.path.join(OUTDIR, 'pytorch_models', f'pytorch_model_{run_counter}.pth')\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'params': params,\n",
    "                'test_acc': test_acc,\n",
    "                'test_metrics': test_metrics,\n",
    "                'cv_val_mean': cv_val_mean if use_cross_validation else None,\n",
    "                'run': run_counter\n",
    "            }, model_path)\n",
    "            \n",
    "            # Track best model\n",
    "            score_for_comparison = cv_val_mean if use_cross_validation else test_acc\n",
    "            if score_for_comparison and score_for_comparison > best_test_acc:\n",
    "                best_test_acc = score_for_comparison\n",
    "                best_pytorch_model = {\n",
    "                    'model': model,\n",
    "                    'experiment_id': run_counter,\n",
    "                    'params': params,\n",
    "                    'test_metrics': test_metrics,\n",
    "                    'train_metrics': train_metrics,\n",
    "                    'model_path': model_path\n",
    "                }\n",
    "            \n",
    "            # Log cross-validation metrics to MLflow\n",
    "            if use_mlflow and use_cross_validation:\n",
    "                mlflow.log_metric(\"cv_train_mean\", cv_train_mean)\n",
    "                mlflow.log_metric(\"cv_train_std\", cv_train_std)\n",
    "                mlflow.log_metric(\"cv_val_mean\", cv_val_mean)\n",
    "                mlflow.log_metric(\"cv_val_std\", cv_val_std)\n",
    "                mlflow.log_metric(\"final_train_acc\", train_acc)\n",
    "                mlflow.log_metric(\"final_test_acc\", test_acc)\n",
    "            \n",
    "            # Store results\n",
    "            result = {\n",
    "                'run': run_counter,\n",
    "                'params': params,\n",
    "                'train_acc': train_acc,\n",
    "                'test_acc': test_acc,\n",
    "                'train_precision_macro': train_metrics['precision_macro'],\n",
    "                'train_recall_macro': train_metrics['recall_macro'],\n",
    "                'train_f1_macro': train_metrics['f1_macro'],\n",
    "                'test_precision_macro': test_metrics['precision_macro'],\n",
    "                'test_recall_macro': test_metrics['recall_macro'],\n",
    "                'test_f1_macro': test_metrics['f1_macro'],\n",
    "                'test_precision_weighted': test_metrics['precision_weighted'],\n",
    "                'test_recall_weighted': test_metrics['recall_weighted'],\n",
    "                'test_f1_weighted': test_metrics['f1_weighted'],\n",
    "                'cv_train_mean': cv_train_mean,\n",
    "                'cv_train_std': cv_train_std,\n",
    "                'cv_val_mean': cv_val_mean,\n",
    "                'cv_val_std': cv_val_std,\n",
    "                'cv_loss_mean': cv_loss_mean,\n",
    "                'final_train_loss': train_losses[-1] if train_losses else None,\n",
    "                'final_val_loss': val_losses[-1] if val_losses else None,\n",
    "                'best_val_loss': early_stopping.val_loss_min,\n",
    "                'early_stopped': early_stopping.early_stop,\n",
    "                'epochs_trained': len(train_losses),  # Actual epochs trained (may be less due to early stopping)\n",
    "                'early_stop_epoch': len(train_losses) if early_stopping.early_stop else None,\n",
    "                'duration_seconds': duration,\n",
    "                'timestamp': start_time.isoformat(),\n",
    "                'model_path': model_path\n",
    "            }\n",
    "            \n",
    "            pytorch_results.append(result)\n",
    "            \n",
    "            # Confusion matrix logging\n",
    "            cm = confusion_matrix(y_test, pred_test)\n",
    "            fig, ax = plt.subplots(figsize=(8, 6))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap='Blues')\n",
    "            ax.set_title(f'Confusion Matrix - Run {run_counter}')\n",
    "            ax.set_xlabel('Predicted')\n",
    "            ax.set_ylabel('Actual')\n",
    "            writer.add_figure('Confusion_Matrix', fig, global_step=run_counter)\n",
    "            plt.close(fig)\n",
    "            \n",
    "            # Training loss curve plot\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "            \n",
    "            ax1.plot(train_losses, label='Training Loss')\n",
    "            if val_losses:\n",
    "                # Since we now validate every epoch, epochs range is simply 0 to len(val_losses)\n",
    "                val_epochs_range = list(range(len(val_losses)))\n",
    "                ax1.plot(val_epochs_range, val_losses, label='Validation Loss', marker='o')\n",
    "            ax1.set_title(f\"Loss Curves - Run {run_counter}\")\n",
    "            ax1.set_xlabel('Epoch')\n",
    "            ax1.set_ylabel('Loss')\n",
    "            ax1.legend()\n",
    "            ax1.grid(True)\n",
    "            \n",
    "            if val_accuracies:\n",
    "                val_acc_epochs_range = list(range(len(val_accuracies)))\n",
    "                ax2.plot(val_acc_epochs_range, val_accuracies, label='Validation Accuracy', marker='o', color='green')\n",
    "                ax2.set_title(f\"Validation Accuracy - Run {run_counter}\")\n",
    "                ax2.set_xlabel('Epoch')\n",
    "                ax2.set_ylabel('Accuracy')\n",
    "                ax2.legend()\n",
    "                ax2.grid(True)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save plot\n",
    "            fname = f\"pytorch_metrics_run_{run_counter}.png\"\n",
    "            plt.savefig(os.path.join(OUTDIR, fname), dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            # Progress logging\n",
    "            if use_cross_validation:\n",
    "                logger.info(f\"PyTorch experiment {run_counter}/{len(combos)} completed. CV val: {cv_val_mean:.4f}±{cv_val_std:.4f}, Test F1: {test_metrics['f1_macro']:.4f}\")\n",
    "            else:\n",
    "                logger.info(f\"PyTorch experiment {run_counter}/{len(combos)} completed. Train acc: {train_acc:.4f}, Test F1: {test_metrics['f1_macro']:.4f}\")\n",
    "            \n",
    "            # Clean up\n",
    "            writer.close()\n",
    "            if use_mlflow:\n",
    "                mlflow.end_run()\n",
    "            \n",
    "            # Memory cleanup\n",
    "            del model\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"PyTorch experiment {run_counter} failed: {str(e)}\")\n",
    "            logger.error(traceback.format_exc())\n",
    "            if use_mlflow:\n",
    "                mlflow.end_run(status=\"FAILED\")\n",
    "            continue\n",
    "    \n",
    "    logger.info(f\"Completed {len(pytorch_results)} successful PyTorch experiments\")\n",
    "    \n",
    "    # Save best PyTorch model with special designation\n",
    "    if best_pytorch_model:\n",
    "        best_model_dir = os.path.join(OUTDIR, 'best_models')\n",
    "        os.makedirs(best_model_dir, exist_ok=True)\n",
    "        \n",
    "        # Save best model\n",
    "        best_model_path = os.path.join(best_model_dir, 'best_pytorch_model.pth')\n",
    "        torch.save({\n",
    "            'model_state_dict': best_pytorch_model['model'].state_dict(),\n",
    "            'params': best_pytorch_model['params'],\n",
    "            'test_metrics': best_pytorch_model['test_metrics'],\n",
    "            'run': best_pytorch_model['experiment_id']\n",
    "        }, best_model_path)\n",
    "        \n",
    "        # Save best model metrics with special naming\n",
    "        with torch.no_grad():\n",
    "            best_pred = best_pytorch_model['model'](X_test_t.to(device)).argmax(dim=1).cpu().numpy()\n",
    "        \n",
    "        best_test_metrics = calculate_comprehensive_metrics(\n",
    "            y_test, best_pred, 'BEST_pytorch_model', 'BEST', 'pytorch_best'\n",
    "        )\n",
    "        \n",
    "        # Save best model info\n",
    "        best_info = {\n",
    "            'experiment_id': best_pytorch_model['experiment_id'],\n",
    "            'params': best_pytorch_model['params'],\n",
    "            'metrics': best_test_metrics,\n",
    "            'model_path': best_model_path,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(best_model_dir, 'best_pytorch_model_info.json'), 'w') as f:\n",
    "            json.dump(best_info, f, indent=2)\n",
    "        \n",
    "        logger.info(f\"Best PyTorch model saved (Experiment {best_pytorch_model['experiment_id']}) with score: {best_test_acc:.4f}\")\n",
    "    \n",
    "    # Save PyTorch results\n",
    "    if pytorch_results:\n",
    "        pytorch_df = pd.DataFrame([\n",
    "            {\n",
    "                'run': r['run'],\n",
    "                'hidden_sizes': str(r['params']['hidden_sizes']),\n",
    "                'learning_rate': r['params']['learning_rate'],\n",
    "                'dropout': r['params']['dropout'],\n",
    "                'batch_size': r['params']['batch_size'],\n",
    "                'epochs': r['params']['epochs'],\n",
    "                'train_acc': r['train_acc'],\n",
    "                'test_acc': r['test_acc'],\n",
    "                'train_f1_macro': r['train_f1_macro'],\n",
    "                'test_f1_macro': r['test_f1_macro'],\n",
    "                'test_precision_macro': r['test_precision_macro'],\n",
    "                'test_recall_macro': r['test_recall_macro'],\n",
    "                'test_f1_weighted': r['test_f1_weighted'],\n",
    "                'cv_train_mean': r['cv_train_mean'],\n",
    "                'cv_train_std': r['cv_train_std'],\n",
    "                'cv_val_mean': r['cv_val_mean'],\n",
    "                'cv_val_std': r['cv_val_std'],\n",
    "                'cv_loss_mean': r['cv_loss_mean'],\n",
    "                'final_train_loss': r['final_train_loss'],\n",
    "                'final_val_loss': r['final_val_loss'],\n",
    "                'best_val_loss': r.get('best_val_loss', None),\n",
    "                'early_stopped': r.get('early_stopped', False),\n",
    "                'epochs_trained': r.get('epochs_trained', r['params']['epochs']),\n",
    "                'early_stop_epoch': r.get('early_stop_epoch', None),\n",
    "                'duration_seconds': r['duration_seconds'],\n",
    "                'timestamp': r['timestamp'],\n",
    "                'model_path': r['model_path']\n",
    "            } for r in pytorch_results\n",
    "        ])\n",
    "        pytorch_df.to_csv(os.path.join(OUTDIR, 'pytorch_results_summary.csv'), index=False)\n",
    "        logger.info(\"PyTorch results saved to pytorch_results_summary.csv\")\n",
    "        \n",
    "        # Display best results\n",
    "        if use_cross_validation:\n",
    "            best_pytorch = pytorch_df.loc[pytorch_df['cv_val_mean'].idxmax()]\n",
    "            print(f\"\\nBest PyTorch result (by CV score):\")\n",
    "            print(f\"CV val accuracy: {best_pytorch['cv_val_mean']:.4f}±{best_pytorch['cv_val_std']:.4f}\")\n",
    "            print(f\"Test accuracy: {best_pytorch['test_acc']:.4f}\")\n",
    "            print(f\"Test F1-macro: {best_pytorch['test_f1_macro']:.4f}\")\n",
    "            print(f\"Test Precision-macro: {best_pytorch['test_precision_macro']:.4f}\")\n",
    "            print(f\"Test Recall-macro: {best_pytorch['test_recall_macro']:.4f}\")\n",
    "            print(f\"Parameters: hidden_sizes={best_pytorch['hidden_sizes']}, lr={best_pytorch['learning_rate']}, dropout={best_pytorch['dropout']}\")\n",
    "        else:\n",
    "            best_pytorch = pytorch_df.loc[pytorch_df['test_acc'].idxmax()]\n",
    "            print(f\"\\nBest PyTorch result:\")\n",
    "            print(f\"Test accuracy: {best_pytorch['test_acc']:.4f}\")\n",
    "            print(f\"Test F1-macro: {best_pytorch['test_f1_macro']:.4f}\")\n",
    "            print(f\"Test Precision-macro: {best_pytorch['test_precision_macro']:.4f}\")\n",
    "            print(f\"Test Recall-macro: {best_pytorch['test_recall_macro']:.4f}\")\n",
    "            print(f\"Parameters: hidden_sizes={best_pytorch['hidden_sizes']}, lr={best_pytorch['learning_rate']}, dropout={best_pytorch['dropout']}\")\n",
    "\n",
    "else:\n",
    "    logger.info(\"PyTorch experiments skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plotting_results",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 09:14:53,253 - INFO - Starting final analysis and plotting of results\n",
      "2025-08-11 09:14:54,116 - INFO - Saved plot: pytorch_test_accuracy.png\n",
      "2025-08-11 09:14:54,117 - INFO - Final analysis and plotting complete.\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive Results Analysis with All Metrics\n",
    "logger.info(\"Starting comprehensive analysis and plotting of all metrics\")\n",
    "\n",
    "def create_comprehensive_performance_plots(df, model_type):\n",
    "    \"\"\"Create comprehensive performance plots for all metrics\"\"\"\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    if 'hidden_layer_sizes' in df.columns:\n",
    "        df['arch_str'] = df['hidden_layer_sizes'].apply(lambda x: str(x).replace(' ', ''))\n",
    "        x_col = 'arch_str'\n",
    "        hue_col = 'solver'\n",
    "    else:\n",
    "        df['arch_str'] = df['hidden_sizes'].apply(lambda x: str(x).replace(' ', ''))\n",
    "        x_col = 'arch_str'\n",
    "        hue_col = 'dropout'\n",
    "    \n",
    "    # Create a 2x2 subplot for different metrics\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 15))\n",
    "    fig.suptitle(f'{model_type} - Comprehensive Performance Analysis', fontsize=16)\n",
    "    \n",
    "    # Plot 1: Accuracy\n",
    "    sns.barplot(x=x_col, y='test_acc', hue=hue_col, data=df, ax=axes[0,0], palette='viridis')\n",
    "    axes[0,0].set_title('Test Accuracy')\n",
    "    axes[0,0].set_xlabel('Architecture')\n",
    "    axes[0,0].set_ylabel('Accuracy')\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    axes[0,0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Plot 2: F1-Score (Macro)\n",
    "    sns.barplot(x=x_col, y='test_f1_macro', hue=hue_col, data=df, ax=axes[0,1], palette='plasma')\n",
    "    axes[0,1].set_title('Test F1-Score (Macro)')\n",
    "    axes[0,1].set_xlabel('Architecture')\n",
    "    axes[0,1].set_ylabel('F1-Score')\n",
    "    axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    axes[0,1].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Plot 3: Precision (Macro)\n",
    "    sns.barplot(x=x_col, y='test_precision_macro', hue=hue_col, data=df, ax=axes[1,0], palette='cividis')\n",
    "    axes[1,0].set_title('Test Precision (Macro)')\n",
    "    axes[1,0].set_xlabel('Architecture')\n",
    "    axes[1,0].set_ylabel('Precision')\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    axes[1,0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Plot 4: Recall (Macro)\n",
    "    sns.barplot(x=x_col, y='test_recall_macro', hue=hue_col, data=df, ax=axes[1,1], palette='magma')\n",
    "    axes[1,1].set_title('Test Recall (Macro)')\n",
    "    axes[1,1].set_xlabel('Architecture')\n",
    "    axes[1,1].set_ylabel('Recall')\n",
    "    axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    axes[1,1].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'{model_type.lower()}_comprehensive_metrics.png'\n",
    "    plt.savefig(os.path.join(OUTDIR, filename), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    logger.info(f\"Saved comprehensive metrics plot: {filename}\")\n",
    "\n",
    "def create_cv_comparison_plots(df, model_type):\n",
    "    \"\"\"Create cross-validation comparison plots if CV was used\"\"\"\n",
    "    if not use_cross_validation:\n",
    "        return\n",
    "    \n",
    "    cv_col = 'cv_mean_acc' if model_type == 'Scikit-learn' else 'cv_val_mean'\n",
    "    if cv_col not in df.columns:\n",
    "        return\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    if 'hidden_layer_sizes' in df.columns:\n",
    "        df['arch_str'] = df['hidden_layer_sizes'].apply(lambda x: str(x).replace(' ', ''))\n",
    "        x_col = 'arch_str'\n",
    "        hue_col = 'solver'\n",
    "    else:\n",
    "        df['arch_str'] = df['hidden_sizes'].apply(lambda x: str(x).replace(' ', ''))\n",
    "        x_col = 'arch_str'\n",
    "        hue_col = 'dropout'\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # CV results with error bars\n",
    "    cv_std_col = cv_col.replace('mean', 'std')\n",
    "    if cv_std_col in df.columns:\n",
    "        # Group data for error bars\n",
    "        grouped = df.groupby([x_col, hue_col]).agg({\n",
    "            cv_col: 'mean',\n",
    "            cv_std_col: 'mean'\n",
    "        }).reset_index()\n",
    "        \n",
    "        sns.barplot(x=x_col, y=cv_col, hue=hue_col, data=grouped, ax=axes[0], palette='viridis')\n",
    "        \n",
    "        # Add error bars\n",
    "        for i, (_, row) in enumerate(grouped.iterrows()):\n",
    "            axes[0].errorbar(i, row[cv_col], yerr=row[cv_std_col], \n",
    "                           fmt='none', color='black', capsize=3, alpha=0.7)\n",
    "        \n",
    "        axes[0].set_title(f'{model_type} - Cross-Validation Results')\n",
    "        axes[0].set_xlabel('Architecture')\n",
    "        axes[0].set_ylabel('CV Accuracy')\n",
    "        axes[0].tick_params(axis='x', rotation=45)\n",
    "        axes[0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # CV vs Test correlation\n",
    "    axes[1].scatter(df[cv_col], df['test_acc'], alpha=0.7)\n",
    "    axes[1].plot([0, 1], [0, 1], 'r--', alpha=0.8)\n",
    "    correlation = df[cv_col].corr(df['test_acc'])\n",
    "    axes[1].set_xlabel('Cross-Validation Accuracy')\n",
    "    axes[1].set_ylabel('Test Set Accuracy')\n",
    "    axes[1].set_title(f'{model_type} CV vs Test Correlation (r={correlation:.3f})')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'{model_type.lower()}_cv_analysis.png'\n",
    "    plt.savefig(os.path.join(OUTDIR, filename), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    logger.info(f\"Saved CV analysis plot: {filename}\")\n",
    "\n",
    "# Create comprehensive plots for both model types\n",
    "if 'sklearn_df' in locals() and not sklearn_df.empty:\n",
    "    create_comprehensive_performance_plots(sklearn_df, 'Scikit-learn')\n",
    "    create_cv_comparison_plots(sklearn_df, 'Scikit-learn')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SCIKIT-LEARN COMPREHENSIVE RESULTS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total experiments: {len(sklearn_df)}\")\n",
    "    \n",
    "    # Best results summary\n",
    "    metrics_to_show = ['test_acc', 'test_f1_macro', 'test_precision_macro', 'test_recall_macro']\n",
    "    if use_cross_validation:\n",
    "        cv_best = sklearn_df.loc[sklearn_df['cv_mean_acc'].idxmax()]\n",
    "        print(f\"\\nBest model (by CV accuracy):\")\n",
    "        print(f\"  CV accuracy: {cv_best['cv_mean_acc']:.4f}±{cv_best['cv_std_acc']:.4f}\")\n",
    "        for metric in metrics_to_show:\n",
    "            print(f\"  {metric}: {cv_best[metric]:.4f}\")\n",
    "        print(f\"  Parameters: {cv_best['hidden_layer_sizes']}, {cv_best['solver']}, lr={cv_best['learning_rate_init']}\")\n",
    "    \n",
    "    # Overall statistics\n",
    "    print(f\"\\nOverall Performance Statistics:\")\n",
    "    for metric in metrics_to_show:\n",
    "        print(f\"  {metric}: {sklearn_df[metric].mean():.4f}±{sklearn_df[metric].std():.4f} (best: {sklearn_df[metric].max():.4f})\")\n",
    "\n",
    "if 'pytorch_df' in locals() and not pytorch_df.empty:\n",
    "    create_comprehensive_performance_plots(pytorch_df, 'PyTorch')\n",
    "    create_cv_comparison_plots(pytorch_df, 'PyTorch')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PYTORCH COMPREHENSIVE RESULTS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total experiments: {len(pytorch_df)}\")\n",
    "    \n",
    "    # Best results summary\n",
    "    metrics_to_show = ['test_acc', 'test_f1_macro', 'test_precision_macro', 'test_recall_macro']\n",
    "    if use_cross_validation:\n",
    "        cv_best = pytorch_df.loc[pytorch_df['cv_val_mean'].idxmax()]\n",
    "        print(f\"\\nBest model (by CV accuracy):\")\n",
    "        print(f\"  CV accuracy: {cv_best['cv_val_mean']:.4f}±{cv_best['cv_val_std']:.4f}\")\n",
    "        for metric in metrics_to_show:\n",
    "            print(f\"  {metric}: {cv_best[metric]:.4f}\")\n",
    "        print(f\"  Parameters: {cv_best['hidden_sizes']}, lr={cv_best['learning_rate']}, dropout={cv_best['dropout']}\")\n",
    "    \n",
    "    # Overall statistics  \n",
    "    print(f\"\\nOverall Performance Statistics:\")\n",
    "    for metric in metrics_to_show:\n",
    "        print(f\"  {metric}: {pytorch_df[metric].mean():.4f}±{pytorch_df[metric].std():.4f} (best: {pytorch_df[metric].max():.4f})\")\n",
    "\n",
    "# Model Comparison (if both models were run)\n",
    "if 'sklearn_df' in locals() and 'pytorch_df' in locals() and not sklearn_df.empty and not pytorch_df.empty:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL COMPARISON SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    comparison_metrics = ['test_acc', 'test_f1_macro', 'test_precision_macro', 'test_recall_macro']\n",
    "    \n",
    "    print(\"Best Performance Comparison:\")\n",
    "    for metric in comparison_metrics:\n",
    "        sklearn_best = sklearn_df[metric].max()\n",
    "        pytorch_best = pytorch_df[metric].max()\n",
    "        winner = \"Scikit-learn\" if sklearn_best > pytorch_best else \"PyTorch\"\n",
    "        print(f\"  {metric}: Sklearn={sklearn_best:.4f}, PyTorch={pytorch_best:.4f} → Winner: {winner}\")\n",
    "    \n",
    "    print(\"\\nAverage Performance Comparison:\")\n",
    "    for metric in comparison_metrics:\n",
    "        sklearn_avg = sklearn_df[metric].mean()\n",
    "        pytorch_avg = pytorch_df[metric].mean()\n",
    "        winner = \"Scikit-learn\" if sklearn_avg > pytorch_avg else \"PyTorch\"\n",
    "        print(f\"  {metric}: Sklearn={sklearn_avg:.4f}, PyTorch={pytorch_avg:.4f} → Winner: {winner}\")\n",
    "\n",
    "# Training time analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING TIME AND COMPUTATIONAL ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'sklearn_df' in locals() and not sklearn_df.empty:\n",
    "    sklearn_time = sklearn_df['duration_seconds']\n",
    "    print(f\"Scikit-learn:\")\n",
    "    print(f\"  Average time per experiment: {sklearn_time.mean():.2f}s\")\n",
    "    print(f\"  Total time: {sklearn_time.sum():.2f}s ({sklearn_time.sum()/60:.1f} minutes)\")\n",
    "\n",
    "if 'pytorch_df' in locals() and not pytorch_df.empty:\n",
    "    pytorch_time = pytorch_df['duration_seconds']\n",
    "    print(f\"PyTorch:\")\n",
    "    print(f\"  Average time per experiment: {pytorch_time.mean():.2f}s\")\n",
    "    print(f\"  Total time: {pytorch_time.sum():.2f}s ({pytorch_time.sum()/60:.1f} minutes)\")\n",
    "\n",
    "if use_cross_validation:\n",
    "    print(f\"\\nCross-validation impact:\")\n",
    "    print(f\"  Estimated {n_folds}x time increase due to CV\")\n",
    "    if 'sklearn_df' in locals():\n",
    "        print(f\"  Sklearn estimated time without CV: {sklearn_df['duration_seconds'].mean() / n_folds:.2f}s per experiment\")\n",
    "    if 'pytorch_df' in locals():\n",
    "        print(f\"  PyTorch estimated time without CV: {pytorch_df['duration_seconds'].mean() / n_folds:.2f}s per experiment\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FILES AND OUTPUTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(\"Generated files and directories:\")\n",
    "print(\"📁 experiment_outputs/\")\n",
    "print(\"  ├── 📁 sklearn_models/ - Individual sklearn models (.joblib)\")\n",
    "print(\"  ├── 📁 pytorch_models/ - Individual PyTorch models (.pth)\")\n",
    "print(\"  ├── 📁 best_models/ - Best models from each framework\")\n",
    "print(\"  ├── 📁 metrics/ - Comprehensive metrics for each model (.json)\")\n",
    "print(\"  ├── 📁 confusion_matrices/ - Confusion matrix plots (.png)\")\n",
    "print(\"  ├── 📁 tb_logs/ - TensorBoard logs (PyTorch only)\")\n",
    "print(\"  ├── 📄 sklearn_results_summary.csv - Sklearn experiment results\")\n",
    "print(\"  ├── 📄 pytorch_results_summary.csv - PyTorch experiment results\")\n",
    "print(\"  ├── 📄 experiment_config.yaml - Experiment configuration\")\n",
    "print(\"  └── 📄 *.png - Various performance plots\")\n",
    "\n",
    "logger.info(\"Comprehensive analysis complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e2d55a-e966-4a3c-b85c-d664f6d6495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Experiment Summary with All Metrics\n",
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE ML EXPERIMENT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n🔬 EXPERIMENT CONFIGURATION:\")\n",
    "print(f\"Cross-validation enabled: {use_cross_validation}\")\n",
    "if use_cross_validation:\n",
    "    print(f\"Number of folds: {n_folds}\")\n",
    "    print(f\"CV strategy: StratifiedKFold (maintains class distribution)\")\n",
    "\n",
    "print(f\"PyTorch experiments: {use_pytorch}\")\n",
    "print(f\"MLflow logging: {use_mlflow}\")\n",
    "\n",
    "print(f\"\\n\udcca COMPREHENSIVE METRICS CALCULATED:\")\n",
    "print(\"For each model experiment, the following metrics were calculated and saved:\")\n",
    "print(\"✅ Accuracy (train and test)\")\n",
    "print(\"✅ Precision (macro and weighted averages)\")\n",
    "print(\"✅ Recall (macro and weighted averages)\")\n",
    "print(\"✅ F1-Score (macro and weighted averages)\")\n",
    "print(\"✅ Per-class precision, recall, and F1-score\")\n",
    "print(\"✅ Confusion Matrix (numerical and visual)\")\n",
    "print(\"✅ Classification Report (detailed breakdown)\")\n",
    "\n",
    "if use_cross_validation:\n",
    "    print(\"✅ Cross-validation statistics (mean ± std for all metrics)\")\n",
    "\n",
    "print(f\"\\n📁 OUTPUT STRUCTURE:\")\n",
    "print(\"experiment_outputs/\")\n",
    "print(\"├── sklearn_models/          # All sklearn models (.joblib files)\")\n",
    "print(\"├── pytorch_models/          # All PyTorch models (.pth files)\")\n",
    "print(\"├── best_models/             # Best performing models\")\n",
    "print(\"│   ├── best_sklearn_model.joblib\")\n",
    "print(\"│   ├── best_pytorch_model.pth\")\n",
    "print(\"│   ├── best_sklearn_model_info.json\")\n",
    "print(\"│   └── best_pytorch_model_info.json\")\n",
    "print(\"├── metrics/                 # Comprehensive metrics for each model\")\n",
    "print(\"│   ├── sklearn_model_*_metrics.json\")\n",
    "print(\"│   ├── pytorch_model_*_metrics.json\")\n",
    "print(\"│   ├── *_classification_report.json\")\n",
    "print(\"│   └── BEST_*_metrics.json\")\n",
    "print(\"├── confusion_matrices/      # Confusion matrix plots\")\n",
    "print(\"│   ├── sklearn_model_*_confusion_matrix.png\")\n",
    "print(\"│   ├── pytorch_model_*_confusion_matrix.png\")\n",
    "print(\"│   └── *_best_confusion_matrix.png\")\n",
    "print(\"├── tb_logs/                 # TensorBoard logs (PyTorch)\")\n",
    "print(\"├── sklearn_results_summary.csv\")\n",
    "print(\"├── pytorch_results_summary.csv\")\n",
    "print(\"├── experiment_config.yaml\")\n",
    "print(\"└── Various performance plots (.png)\")\n",
    "\n",
    "print(f\"\\n\udcc8 PERFORMANCE EVALUATION:\")\n",
    "print(\"🎯 Model Selection Criteria:\")\n",
    "if use_cross_validation:\n",
    "    print(\"  - Primary: Cross-validation accuracy (most reliable)\")\n",
    "    print(\"  - Secondary: Test set performance for final evaluation\")\n",
    "    print(\"  - Consider: F1-score for imbalanced datasets\")\n",
    "    print(\"  - Stability: Low standard deviation in CV scores\")\n",
    "else:\n",
    "    print(\"  - Primary: Test set accuracy\")\n",
    "    print(\"  - Consider: F1-score, precision, and recall\")\n",
    "\n",
    "print(\"\\n🔍 METRICS INTERPRETATION GUIDE:\")\n",
    "print(\"📊 Accuracy: Overall correctness (TP+TN)/(TP+TN+FP+FN)\")\n",
    "print(\"📊 Precision: How many predicted positives were actually positive (TP/(TP+FP))\")\n",
    "print(\"📊 Recall: How many actual positives were correctly predicted (TP/(TP+FN))\")\n",
    "print(\"📊 F1-Score: Harmonic mean of precision and recall (2*P*R/(P+R))\")\n",
    "print(\"📊 Macro avg: Unweighted average across all classes\")\n",
    "print(\"📊 Weighted avg: Average weighted by class support\")\n",
    "\n",
    "print(f\"\\n⚡ COMPUTATIONAL PERFORMANCE:\")\n",
    "if use_cross_validation:\n",
    "    print(f\"Cross-validation overhead: ~{n_folds}x increase in training time\")\n",
    "    print(\"Benefits: More robust model selection, statistical confidence\")\n",
    "    print(\"Trade-off: Longer computation time for better reliability\")\n",
    "\n",
    "print(\"\\n🏆 BEST MODEL IDENTIFICATION:\")\n",
    "print(\"Best models are automatically identified and saved separately:\")\n",
    "print(\"- Saved with special 'BEST_' prefix in metrics files\")\n",
    "print(\"- Stored in dedicated 'best_models/' directory\")\n",
    "print(\"- Include complete parameter configuration and performance metrics\")\n",
    "\n",
    "print(f\"\\n\udd27 USAGE RECOMMENDATIONS:\")\n",
    "print(\"1. 📈 For model selection: Use CV metrics (more reliable)\")\n",
    "print(\"2. 📊 For reporting: Use test set metrics (unbiased estimate)\")\n",
    "print(\"3. 🎯 For imbalanced data: Focus on F1-score and per-class metrics\")\n",
    "print(\"4. 📉 For further analysis: Examine confusion matrices and classification reports\")\n",
    "print(\"5. 🔄 For reproducibility: All configurations saved in experiment_config.yaml\")\n",
    "\n",
    "print(f\"\\n📋 NEXT STEPS:\")\n",
    "print(\"✅ Load best models: Use joblib.load() for sklearn, torch.load() for PyTorch\")\n",
    "print(\"✅ Analyze metrics: Review JSON files in metrics/ directory\")\n",
    "print(\"✅ Visualize results: Check confusion matrices and performance plots\")\n",
    "print(\"✅ Compare models: Use the comprehensive summary above\")\n",
    "print(\"✅ Deploy: Best models are ready for production use\")\n",
    "\n",
    "if use_cross_validation:\n",
    "    print(f\"\\n📊 CROSS-VALIDATION INSIGHTS:\")\n",
    "    print(\"- CV provides estimate of model generalization performance\")\n",
    "    print(\"- Lower CV standard deviation indicates more stable model\")\n",
    "    print(\"- High correlation between CV and test scores validates methodology\")\n",
    "    print(\"- Use CV scores for hyperparameter selection, test scores for final evaluation\")\n",
    "\n",
    "print(f\"\\n🎉 EXPERIMENT STATUS: COMPLETED SUCCESSFULLY!\")\n",
    "print(\"All models trained, evaluated, and saved with comprehensive metrics.\")\n",
    "\n",
    "# Final model count summary\n",
    "total_models = 0\n",
    "if 'sklearn_df' in locals():\n",
    "    total_models += len(sklearn_df)\n",
    "    print(f\"✅ Scikit-learn models: {len(sklearn_df)}\")\n",
    "\n",
    "if 'pytorch_df' in locals():\n",
    "    total_models += len(pytorch_df)\n",
    "    print(f\"✅ PyTorch models: {len(pytorch_df)}\")\n",
    "\n",
    "print(f\"📊 Total models evaluated: {total_models}\")\n",
    "\n",
    "logger.info(\"All experiments completed successfully with comprehensive metrics!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_oralsmart_data_analysis)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

